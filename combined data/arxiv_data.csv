,Title,Abstract,Venue,Year,Reference_Count,Citation_Count,Influential_Citation_Count,Open_Access,TLDR,index,author_1_id,author_1_name,author_2_id,author_2_name,author_3_id,author_3_name,author_4_id,author_4_name,author_5_id,author_5_name,author_6_id,author_6_name,fieldsOfStudy,Publication_Type
0,Benchmark dataset of memes with text transcriptions for automatic detection of multi-modal misogynistic content,,Data in Brief,2021,12,8,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A benchmark dataset generated as part of a project for automatic identification of misogyny within online content, which focuses in particular on memes, is presented, composed of 800 memes collected from the most popular social media platforms and consulting websites dedicated to collection and creation of memes.'}",0,2032578,F. Gasparini,104163189,Giuliano Rizzi,51228436,Aurora Saibene,1847803,E. Fersini,,,,,"Medicine, Computer Science",JournalArticle
1,Wearing Many (Social) Hats: How Different Are Your Different Social Network Personae?,"
 
 This paper investigates when users create profiles in different social networks, whether they are redundant expressions of the same persona, or they are adapted to each platform. Using the personal webpages of 116,998 users on About.me, we identify and extract matched user profiles on several major social networks including Facebook, Twitter, LinkedIn, and Instagram. We find evidence for distinct site-specific norms, such as differences in the language used in the text of the profile self-description, and the kind of picture used as profile image. By learning a model that robustly identifies the platform given a user’s profile image (0.657–0.829 AUC) or self-description (0.608–0.847 AUC), we confirm that users do adapt their behaviour to individual platforms in an identifiable and learnable manner. However, different genders and age groups adapt their behaviour differently from each other, and these differences are, in general, consistent across different platforms. We show that differences in social profile construction correspond to differences in how formal or informal the platform is.
 
",International Conference on Web and Social Media,2017,50,26,3,True,"{'model': 'tldr@v2.0.0', 'text': 'It is shown that differences in social profile construction correspond to differences in how formal or informal the platform is, and different genders and age groups adapt their behaviour differently from each other, and these differences are, in general, consistent across different platforms.'}",1,36957299,Changtao Zhong,1818420,Hau-Wen Chang,2840779,Dmytro Karamshuk,145948198,Dongwon Lee,2440079,Nishanth R. Sastry,,,"Computer Science, Psychology",JournalArticle
2,When a Tweet is Actually Sexist. A more Comprehensive Classification of Different Online Harassment Categories and The Challenges in NLP,"Sexism is very common in social media and makes the boundaries of freedom tighter for feminist and female users. There is still no comprehensive classification of sexism attracting natural language processing techniques. Categorizing sexism in social media in the categories of hostile or benevolent sexism are so general that simply ignores the other types of sexism happening in these media. This paper proposes a more comprehensive and in-depth categories of online harassment in social media e.g. twitter into the following categories, ""Indirect harassment"", ""Information threat"", ""sexual harassment"", ""Physical harassment"" and ""Not sexist"" and address the challenge of labeling them along with presenting the classification result of the categories. It is preliminary work applying machine learning to learn the concept of sexism and distinguishes itself by looking at more precise categories of sexism in social media.",ArXiv,2019,17,18,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes a more comprehensive and in-depth categories of online harassment in social media e.g. twitter into the following categories, ""Indirect harassment,"" ""Information threat"", ""sexual harassment"", ""Physical harassment"" and ""Not sexist"".'}",2,10745415,Sima Sharifirad,1749003,S. Matwin,,,,,,,,,Computer Science,JournalArticle
3,#ILookLikeAnEngineer: Using Social Media Based Hashtag Activism Campaigns as a Lens to Better Understand Engineering Diversity Issues,"Each year, significant investment of time and resources is made to improve diversity within engineering across a range of federal and state agencies, private/not-for-profit organizations, and foundations. In spite of decades of investments, efforts have not yielded desired returns - participation by minorities continues to lag at a time when STEM workforce requirements are increasing. In recent years a new stream of data has emerged - online social networks, including Twitter, Facebook, and Instagram - that act as a key sensor of social behavior and attitudes of the public. Almost 87% of the American population now participates in some form of social media activity. Consequently, social networking sites have become powerful indicators of social action and social media data has shown significant promise for studying many issues including public health communication, political campaign, humanitarian crisis, and, activism. We argue that social media data can likewise be leveraged to better understand and improve engineering diversity. As a case study to illustrate the viability of the approach, we present findings from a campaign, #ILookLikeAnEngineer (using Twitter data - 19,354 original tweets and 29,529 retweets), aimed at increasing gender diversity in the engineering workplace. The campaign provided a continuous momentum to the overall effort to increase diversity and novel ways of connecting with relevant audience. Our analysis demonstrates that diversity initiatives related to STEM attract voices from various entities including individuals, large corporations, media outlets, and community interest groups.",ArXiv,2018,24,5,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is argued that social media data can likewise be leveraged to better understand and improve engineering diversity and presented findings from a campaign, #ILookLikeAnEngineer, aimed at increasing gender diversity in the engineering workplace.'}",3,145539521,Aqdas Malik,1710392,A. Johri,41015664,Rajat Handa,30775806,Habib Karbasian,7147418,Hemant Purohit,,,"Computer Science, Sociology",JournalArticle
4,The ComMA Dataset V0.2: Annotating Aggression and Bias in Multilingual Social Media Discourse,"In this paper, we discuss the development of a multilingual dataset annotated with a hierarchical, fine-grained tagset marking different types of aggression and the “context” in which they occur. The context, here, is defined by the conversational thread in which a specific comment occurs and also the “type” of discursive role that the comment is performing with respect to the previous comment. The initial dataset, being discussed here consists of a total 59,152 annotated comments in four languages - Meitei, Bangla, Hindi, and Indian English - collected from various social media platforms such as YouTube, Facebook, Twitter and Telegram. As is usual on social media websites, a large number of these comments are multilingual, mostly code-mixed with English. The paper gives a detailed description of the tagset being used for annotation and also the process of developing a multi-label, fine-grained tagset that has been used for marking comments with aggression and bias of various kinds including sexism (called gender bias in the tagset), religious intolerance (called communal bias in the tagset), class/caste bias and ethnic/racial bias. We also define and discuss the tags that have been used for marking the different discursive role being performed through the comments, such as attack, defend, etc. Finally, we present a basic statistical analysis of the dataset. The dataset is being incrementally made publicly available on the project website.",International Conference on Language Resources and Evaluation,2021,45,12,1,False,"{'model': 'tldr@v2.0.0', 'text': 'The paper gives a detailed description of the tagset being used for annotation and also the process of developing a multi-label, fine-grained tagset that has been used for marking comments with aggression and bias of various kinds including sexism, gender bias and religious intolerance.'}",4,2142831715,Ritesh Kumar,2141575906,Enakshi Nandi,108322921,Laishram Niranjana Devi,2121380947,S. Ratan,2108519705,Siddharth Singh,2119162354,Akash Bhagat,Computer Science,JournalArticle
5,Information We Can Extract About a User From 'One Minute Mobile Application Usage',"—Understanding human behavior is an important task and has applications in many domains such as targeted advertisement, health analytics, security, and entertainment, etc. For this purpose, designing a system for activity recognition (AR) is important. However, since every human can have different behaviors, understanding and analyzing common patterns be-come a challenging task. Since smartphones are easily available to every human being in the modern world, using them to track the human activities becomes possible. In this paper, we extracted different human activities using accelerometer, magnetometer, and gyroscope sensors of android smartphones by building an android mobile applications. Using different social media applications, such as Facebook, Instagram, Whatsapp, and Twitter, we extracted the raw sensor values along with the attributes of 29 subjects along with their attributes (class labels) such as age, gender, and left/right/both hands application usage. We extract features from the raw signals and use them to perform classiﬁcation using different machine learning (ML) algorithms. Using statistical analysis, we show the importance of different features towards the prediction of class labels. In the end, we use the trained ML model on our data to extract unknown features from a well known activity recognition data from UCI repository, which highlights the potential of privacy breach using ML models. This security analysis could help researchers in future to take appropriate steps to preserve the privacy of human subjects.",ArXiv,2022,32,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper extracted different human activities using accelerometer, magnetometer, and gyroscope sensors of android smartphones by building an android mobile applications and uses the trained ML model to extract unknown features from a well known activity recognition data from UCI repository, which highlights the potential of privacy breach using ML models.'}",5,150290745,Sarwan Ali,,,,,,,,,,,Computer Science,JournalArticle
6,Quantifying gender biases towards politicians on Reddit,"Despite attempts to increase gender parity in politics, global efforts have struggled to ensure equal female representation. This is likely tied to implicit gender biases against women in authority. In this work, we present a comprehensive study of gender biases that appear in online political discussion. To this end, we collect 10 million comments on Reddit in conversations about male and female politicians, which enables an exhaustive study of automatic gender bias detection. We address not only misogynistic language, but also other manifestations of bias, like benevolent sexism in the form of seemingly positive sentiment and dominance attributed to female politicians, or differences in descriptor attribution. Finally, we conduct a multi-faceted study of gender bias towards politicians investigating both linguistic and extra-linguistic cues. We assess 5 different types of gender bias, evaluating coverage, combinatorial, nominal, sentimental and lexical biases extant in social media language and discourse. Overall, we find that, contrary to previous research, coverage and sentiment biases suggest equal public interest in female politicians. Rather than overt hostile or benevolent sexism, the results of the nominal and lexical analyses suggest this interest is not as professional or respectful as that expressed about male politicians. Female politicians are often named by their first names and are described in relation to their body, clothing, or family; this is a treatment that is not similarly extended to men. On the now banned far-right subreddits, this disparity is greatest, though differences in gender biases still appear in the right and left-leaning subreddits. We release the curated dataset to the public for future studies.",PLoS ONE,2021,88,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'It is found that, contrary to previous research, coverage and sentiment biases suggest equal public interest in female politicians, however, the results of the nominal and lexical analyses suggest this interest is not as professional or respectful as that expressed about male politicians.'}",6,2146694845,S. Marjanovic,82563120,Karolina Stańczak,1736067,Isabelle Augenstein,,,,,,,"Computer Science, Medicine",JournalArticle
7,Thou shalt not hate: Countering Online Hate Speech,"Hate content in social media is ever increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. Lack of carefully curated data largely inhibits such understanding. In this paper, we create and release the first ever dataset for counterspeech using comments from YouTube. The data contains 13,924 manually annotated comments where the labels indicate whether a comment is a counterspeech or not. This data allows us to perform a rigorous measurement study characterizing the linguistic structure of counterspeech for the first time. This analysis results in various interesting insights such as: the counterspeech comments receive much more likes as compared to the noncounterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. Finally, we build a set of machine learning models that are able to automatically detect counterspeech in YouTube videos with an F1-score of 0.71. We also build multilabel models that can detect different types of counterspeech in a comment with an F1-score of 0.60.",International Conference on Web and Social Media,2018,42,98,10,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper creates and releases the first ever dataset for counterspeech using comments from YouTube, and performs a rigorous measurement study characterizing the linguistic structure of counterspeeches for the first time.'}",7,3362324,Binny Mathew,1414634347,Hardik Tharad,51208545,Subham Rajgaria,1387907445,Prajwal Singhania,34594216,S. Maity,51130504,Pawan Goyal,Computer Science,JournalArticle
8,The Feasibility of Algorithmic Detection and Decentralised Moderation for Protecting Women from Online Abuse,"I. ABSTRACT Online abuse is becoming an increasingly prevalent issue in modern day society, with 41% of Americans having experienced online harassment in some capacity in 2021 . People who identify as 1 women, in particular, can be subjected to a wide range of abusive behavior online, with gender-speci ﬁ c experiences cited broadly in recent literature across ﬁ elds such as blogging , politics and 2 3 journalism . 4 In response to this rise in abusive content, platforms have been found to largely employ ‘ individualistic moderation ’ approaches, aiming to protect users from harmful content through the screening and management of singular interactions or accounts . Yet, previous work performed by 5 the author of this paper has shown that in the cases of women in particular, these approaches can often be ine ﬀ ective; failing to protect users from multi-dimensional abuse spanning prolonged time periods, di ﬀ erent platforms and varying interaction types. In recognition of its increasing complexity, platforms are beginning to outsource content moderation to users in a new and decentralized approach. The goal of this research is to examine the feasibility of using multidimensional abuse indicators in a Twitter-based moderation algorithm aiming to protect women from female-targeted online abuse. This research outlines three indicators of multidimensional abuse, e xplores how these indicators can be extracted as features from Twitter data, and proposes a technical framework for deploying an end-to-end moderation algorithm using these features.",ArXiv,2023,8,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This research outlines three indicators of multidimensional abuse, outlines how these indicators can be extracted as features from Twitter data, and proposes a technical framework for deploying an end-to-end moderation algorithm using these features.'}",8,2076174695,Sarah Barrington,,,,,,,,,,,Computer Science,JournalArticle
9,A Unified Deep Learning Architecture for Abuse Detection,"Hate speech, offensive language, sexism, racism, and other types of abusive behavior have become a common phenomenon in many online social media platforms. In recent years, such diverse abusive behaviors have been manifesting with increased frequency and levels of intensity. Despite social media's efforts to combat online abusive behaviors this problem is still apparent. In fact, up to now, they have entered an arms race with the perpetrators, who constantly change tactics to evade the detection algorithms deployed by these platforms. Such algorithms, not disclosed to the public for obvious reasons, are typically custom-designed and tuned to detect only one specific type of abusive behavior, but usually miss other related behaviors. In the present paper, we study this complex problem by following a more holistic approach, which considers the various aspects of abusive behavior. We focus on Twitter, due to its popularity, and analyze user and textual properties from different angles of abusive posting behavior. We propose a deep learning architecture, which utilizes a wide variety of available metadata, and combines it with automatically-extracted hidden patterns within the text of the tweets, to detect multiple abusive behavioral norms which are highly inter-related. The proposed unified architecture is applied in a seamless and transparent fashion without the need for any change of the architecture but only training a model for each task (i.e., different types of abusive behavior). We test the proposed approach with multiple datasets addressing different abusive behaviors on Twitter. Our results demonstrate high performance across all datasets, with the AUC value to range from 92% to 98%.",Web Science Conference,2018,45,149,12,True,"{'model': 'tldr@v2.0.0', 'text': 'A deep learning architecture is proposed, which utilizes a wide variety of available metadata, and combines it with automatically-extracted hidden patterns within the text of the tweets, to detect multiple abusive behavioral norms which are highly inter-related.'}",9,35739523,Antigoni-Maria Founta,2550292,Despoina Chatzakou,1946641,N. Kourtellis,144728530,J. Blackburn,1741423,A. Vakali,2909360,I. Leontiadis,Computer Science,"Book, JournalArticle"
10,Gender and Racial Diversity in Commercial Brands' Advertising Images on Social Media,,Social Informatics,2019,57,3,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This work investigates gender and racial diversity of 85,957 advertising images shared by the 73 top international brands on Instagram and Facebook to give guidelines on how to build a fully automated watchdog for gender andracial diversity in online advertisements.'}",10,40660541,Jisun An,2592694,Haewoon Kwak,,,,,,,,,"Psychology, Sociology, Computer Science",JournalArticle
11,The incel lexicon: Deciphering the emergent cryptolect of a global misogynistic community,"Kelly Gothard, David Rushing Dewhurst, Joshua R. Minot, Jane Lydia Adams, Christopher M. Danforth, 3, 4 and Peter Sheridan Dodds 3, 4 Computational Story Lab, Vermont Complex Systems Center, MassMutual Center of Excellence for Complex Systems and Data Science, Vermont Advanced Computing Core, The University of Vermont, Burlington, VT 05401. Charles River Analytics, 625 Mount Auburn Street, Cambridge, MA 02138. Department of Mathematics & Statistics, University of Vermont, Burlington, VT 05401. Department of Computer Science, University of Vermont, Burlington, VT 05401. (Dated: May 26, 2021)",ArXiv,2021,37,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Kelly Gothard, David Rushing Dewhurst, Joshua R. Minot, Jane Lydia Adams, Christopher M. Danforth and Peter Sheridan Dodds 3, 4 Computational Story Lab, Vermont Complex Systems Center, MassMutual Center of Excellence for Complex Systems and Data Science.'}",11,1485310967,Kelly Gothard,17845906,D. R. Dewhurst,147115675,J. Minot,2116149176,J. L. Adams,2310860,C. Danforth,2660575,P. Dodds,Computer Science,JournalArticle
12,Understanding and Measuring Psychological Stress using Social Media,"A body of literature has demonstrated that users’ mental health conditions, such as depression and anxiety, can be predicted from their social media language. There is still a gap in the scientific understanding of how psychological stress is expressed on social media. Stress is one of the primary underlying causes and correlates of chronic physical illnesses and mental health conditions. In this paper, we explore the language of psychological stress with a dataset of 601 social media users, who answered the Perceived Stress Scale questionnaire and also consented to share their Facebook and Twitter data. Firstly, we find that stressed users post about exhaustion, losing control, increased self-focus and physical pain as compared to posts about breakfast, family-time, and travel by users who are not stressed. Secondly, we find that Facebook language is more predictive of stress than Twitter language. Thirdly, we demonstrate how the language based models thus developed can be adapted and be scaled to measure county-level trends. Since county-level language is easily available on Twitter using the Streaming API, we explore multiple domain adaptation algorithms to adapt user-level Facebook models to Twitter language. We find that domain-adapted and scaled social mediabased measurements of stress outperform sociodemographic variables (age, gender, race, education, and income), against ground-truth survey-based stress measurements, both at the user- and the county-level in the U.S. Twitter language that scores higher in stress is also predictive of poorer health, less access to facilities and lower socioeconomic status in counties. We conclude with a discussion of the implications of using social media as a new tool for monitoring stress levels of both individuals and counties.",International Conference on Web and Social Media,2018,67,75,5,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper finds that stressed users post about exhaustion, losing control, increased self-focus and physical pain as compared to posts about breakfast, family-time, and travel by users who are not stressed, and finds that Facebook language is more predictive of stress than Twitter language.'}",12,2731733,Sharath Chandra Guntuku,46843152,Anneke Buffone,2798221,Kokil Jaidka,2615635,J. Eichstaedt,1412391493,L. Ungar,,,Computer Science,"JournalArticle, Review"
13,Attention-based method for categorizing different types of online harassment language,,PKDD/ECML Workshops,2019,27,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'An attention-based approach for the detection of harassment in tweets and the Detection of different types of harassment as well is presented, based on the Recurrent Neural Networks and particularly the deep, classification specific attention mechanism.'}",13,2961780,Christos Karatsalos,1388734007,Yannis Panagiotakis,,,,,,,,,"Computer Science, Mathematics",JournalArticle
14,A Study of WhatsApp Usage Patterns and Prediction Models without Message Content,"Internet social networks have become a ubiquitous application allowing people to easily share text, pictures, and audio and video files. Popular networks include WhatsApp, Facebook, Reddit and LinkedIn. We present an extensive study of the usage of the WhatsApp social network, an Internet messaging application that is quickly replacing SMS messaging. In order to better understand people's use of the network, we provide an analysis of over 6 million messages from over 100 users, with the objective of building demographic prediction models using activity data. We performed extensive statistical and numerical analysis of the data and found significant differences in WhatsApp usage across people of different genders and ages. We also inputted the data into the Weka data mining package and studied models created from decision tree and Bayesian network algorithms. We found that different genders and age demographics had significantly different usage habits in almost all message and group attributes. We also noted differences in users' group behavior and created prediction models, including the likelihood a given group would have relatively more file attachments, if a group would contain a larger number of participants, a higher frequency of activity, quicker response times and shorter messages. We were successful in quantifying and predicting a user's gender and age demographic. Similarly, we were able to predict different types of group usage. All models were built without analyzing message content. We present a detailed discussion about the specific attributes that were contained in all predictive models and suggest possible applications based on these results.",ArXiv,2018,23,34,4,False,"{'model': 'tldr@v2.0.0', 'text': ""An extensive study of the usage of the WhatsApp social network, an Internet messaging application that is quickly replacing SMS messaging, is presented and quantifying and predicting a user's gender and age demographic is successful.""}",14,40110198,A. Rosenfeld,144163396,Sigalit Sina,1707363,D. Sarne,35382695,O. Avidov,1691597,Sarit Kraus,,,Computer Science,JournalArticle
15,"Women, politics and Twitter: Using machine learning to change the discourse","Including diverse voices in political decision-making strengthens our democratic institutions. Within the Canadian political system, there is gender inequality across all levels of elected government. Online abuse, such as hateful tweets, leveled at women engaged in politics contributes to this inequity, particularly tweets focusing on their gender. In this paper, we present ParityBOT: a Twitter bot which counters abusive tweets aimed at women in politics by sending supportive tweets about influential female leaders and facts about women in public life. ParityBOT is the first artificial intelligence-based intervention aimed at affecting online discourse for women in politics for the better. The goal of this project is to: $1$) raise awareness of issues relating to gender inequity in politics, and $2$) positively influence public discourse in politics. The main contribution of this paper is a scalable model to classify and respond to hateful tweets with quantitative and qualitative assessments. The ParityBOT abusive classification system was validated on public online harassment datasets. We conclude with analysis of the impact of ParityBOT, drawing from data gathered during interventions in both the $2019$ Alberta provincial and $2019$ Canadian federal elections.",ArXiv,2019,20,4,0,False,"{'model': 'tldr@v2.0.0', 'text': 'ParityBOT is the first artificial intelligence-based intervention aimed at affecting online discourse for women in politics for the better, and a scalable model to classify and respond to hateful tweets with quantitative and qualitative assessments is presented.'}",15,52228877,Lana Cuthbertson,121823762,Alex Kearney,103737902,R. Dawson,1429838082,Ashia Zawaduk,1429835137,Eve Cuthbertson,1429838829,Ann Gordon-Tighe,"Computer Science, Sociology",JournalArticle
16,Misogynistic Tweet Detection: Modelling CNN with Small Datasets,,Australasian Data Mining Conference,2018,30,18,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work has customised and regularised a Convolutional Neural Network architecture and shown that the word vectors pre-trained on a task-specific domain can be used to train a CNN model effectively when a small set of labelled data is available.'}",16,36231591,M. Bashar,143658054,R. Nayak,69373969,Nicolas Suzor,2128793175,Bridget Weir,,,,,Computer Science,JournalArticle
17,Improved two-stage hate speech classification for twitter based on Deep Neural Networks,"Hate speech is a form of online harassment that involves the use of abusive language, and it is commonly seen in social media posts. This sort of harassment mainly focuses on specific group characteristics such as religion, gender, ethnicity, etc and it has both societal and economic consequences nowadays. The automatic detection of abusive language in text postings has always been a difficult task, but it is lately receiving much interest from the scientific community. This paper addresses the important problem of discerning hateful content in social media. The model we propose in this work is an extension of an existing approach based on LSTM neural network architectures, which we appropriately enhanced and fine-tuned to detect certain forms of hatred language, such as racism or sexism, in a short text. The most significant enhancement is the conversion to a two-stage scheme consisting of Recurrent Neural Network (RNN) classifiers. The output of all One-vs-Rest (OvR) classifiers from the first stage are combined and used to train the second stage classifier, which finally determines the type of harassment. Our study includes a performance comparison of several proposed alternative methods for the second stage evaluated on a public corpus of 16k tweets, followed by a generalization study on another dataset. The reported results show the superior classification quality of the proposed scheme in the task of hate speech detection as compared to the current state-of-the-art.",ArXiv,2022,66,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'The model proposed is an extension of an existing approach based on LSTM neural network architectures, which is appropriately enhanced and fine-tuned to detect certain forms of hatred language in a short text, and shows the superior classification quality of the proposed scheme in the task of hate speech detection as compared to the current state-of-the-art.'}",17,3452522,Georgios K. Pitsilis,,,,,,,,,,,Computer Science,JournalArticle
18,#ContextMatters: Advantages and Limitations of Using Machine Learning to Support Women in Politics,"The United Nations identified gender equality as a Sustainable Development Goal in 2015, recognizing the underrepresentation of women in politics as a specific barrier to achieving gender equality. Political systems around the world experience gender inequality across all levels of elected government as fewer women run for office than men. This is due in part to online abuse, particularly on social media platforms like Twitter, where women seeking or in power tend to be targeted with more toxic maltreatment than their male counterparts. In this paper, we present reflections on ParityBOT—the first natural language processing-based intervention designed to affect online discourse for women in politics for the better, at scale. Deployed across elections in Canada, the United States and New Zealand, ParityBOT was used to analyse and classify more than 12 million tweets directed at women candidates and counter toxic tweets with supportive ones. From these elections we present three case studies highlighting the current limitations of, and future research and application opportunities for, using a natural language processing-based system to detect online toxicity, specifically with regards to contextually important microaggressions. We examine the rate of false negatives, where ParityBOT failed to pick up on insults directed at specific high profile women, which would be obvious to human users. We examine the unaddressed harms of microaggressions and the potential of yet unseen damage they cause for women in these communities, and for progress towards gender equality overall, in light of these technological blindspots. This work concludes with a discussion on the benefits of partnerships between nonprofit social groups and technology experts to develop responsible, socially impactful approaches to addressing online hate.",ArXiv,2021,62,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Reflections are presented on ParityBOT—the first natural language processing-based intervention designed to affect online discourse for women in politics for the better, at scale, and the rate of false negatives is examined.'}",18,2130349717,Jacqueline Comer,17266701,Sam Work,3422828,K. Mathewson,52228877,Lana Cuthbertson,2130467437,Kasey Machin,,,Computer Science,JournalArticle
19,K-MHaS: A Multi-label Hate Speech Detection Dataset in Korean Online News Comment,"Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class.",International Conference on Computational Linguistics,2022,26,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns and provides a multi- label classification using 1 to 4 labels, and handles subjectivity and intersectionality is introduced.'}",19,2119693533,Jean Lee,152997328,Taejun Lim,2116624870,Hee-Youn Lee,2182379492,Bogeun Jo,2182465849,Yangsok Kim,2182382891,Heegeun Yoon,Computer Science,"JournalArticle, Conference"
20,How is Your Mood When Writing Sexist tweets? Detecting the Emotion Type and Intensity of Emotion Using Natural Language Processing Techniques,"Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. While sexism has been considered as a category of hateful speech in the literature, there is no comprehensive definition and category of sexism attracting natural language processing techniques. Categorizing sexism as either benevolent or hostile sexism is so broad that it easily ignores the other categories of sexism on social media. Sharifirad S and Matwin S 2018 proposed a well-defined category of sexism including indirect harassment, information threat, sexual harassment and physical harassment, inspired from social science for the purpose of natural language processing techniques. In this article, we take advantage of a newly released dataset in SemEval-2018 task1: Affect in tweets, to show the type of emotion and intensity of emotion in each category. We train, test and evaluate different classification methods on the SemEval- 2018 dataset and choose the classifier with highest accuracy for testing on each category of sexist tweets to know the mental state and the affectual state of the user who tweets in each category. It is a nice avenue to explore because not all the tweets are directly sexist and they carry different emotions from the users. This is the first work experimenting on affect detection this in depth on sexist tweets. Based on our best knowledge they are all new contributions to the field; we are the first to demonstrate the power of such in-depth sentiment analysis on the sexist tweets.",ArXiv,2019,19,13,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This is the first work experimenting on affect detection this in depth on sexist tweets, and the first to demonstrate the power of such in-depth sentiment analysis on the sexist tweets.'}",20,10745415,Sima Sharifirad,17245142,B. Jafarpour,1749003,S. Matwin,,,,,,,"Computer Science, Mathematics",JournalArticle
21,What are Your Pronouns? Examining Gender Pronoun Usage on Twitter,"The increasing awareness of nonconforming gender identities puts discussions of gender inclusivity at the forefront. Using people’s preferred pronouns is a primary way to develop gender-inclusive language. This work presents the first empirical research on the self-disclosure of gender pronouns on social media. Leveraging a Twitter dataset with over 2 billion tweets collected over two years, we find that the public self-disclosure of gender pronouns is on the rise. The disclosure of gender pronouns is particularly popular among users employing she series pronouns, followed by he series pronouns, and a smaller but sizable amount of non-binary pronouns. By analyzing Twitter messages and users’ sharing activities, we identify the users who choose to disclose their gender pronouns and additionally distinguish users of various gender pronoun categories. Analyzing the relationship between social network exposure to gender pronouns and gender pronoun adoption, we show that those who frequently interact with users who disclose gender pronouns are also more likely to adopt gender pronouns in the future. This work carries implications for gender studies and initiates new research directions in gender inclusivity.",ArXiv,2022,92,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Analyzing the relationship between social network exposure to gender pronouns and gender pronoun adoption, it is shown that those who frequently interact with users who disclose gender pronouns are also more likely to adopt gender pronouns in the future.'}",21,102319456,Julie Jiang,2000893055,Emily Chen,3349623,Luca Luceri,2133453630,Goran Muri'c,1774514,Francesco Pierri,120076217,Ho-Chun Herbert Chang,Computer Science,JournalArticle
22,"Beyond the Boolean: How Programmers Ask About, Use, and Discuss Gender","Categorization via gender is omnipresent throughout society, and thus also computing; gender identity is often requested of users before they use software or web services. Despite this fact, no research has explored how software developers approach requesting gender disclosure from users. To understand how developers think about gender in software, we present an interview study with 15 software developers recruited from the freelancing platform Upwork as well as Twitter. We also collected and categorized 917 threads that contained keywords relevant to gender from programming-related sub-forums on the social media service Reddit. 16 posts that discussed approaches to gender disclosure were further analyzed. We found that while some developers have an understanding of inclusive gender options, programmers rarely consider when gender data is necessary or the way in which they request gender disclosure from users. Our findings have implications for programmers, software engineering educators, and the broader community concerned with inclusivity.",ArXiv,2023,99,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is found that while some developers have an understanding of inclusive gender options, programmers rarely consider when gender data is necessary or the way in which they request gender disclosure from users.'}",22,1887618805,Elijah Bouma-Sims,3224778,Y. Acar,,,,,,,,,Computer Science,JournalArticle
23,Gender Detection on Social Networks using Ensemble Deep Learning,,ArXiv,2020,56,11,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper addresses the problem in the context of gender detection through ensemble classification that employs multi-model deep learning architectures to generate specialized understanding from different feature spaces.'}",23,2060243,Kamran Kowsari,26408890,Mojtaba Heidarysafa,1452681258,Tolu Odukoya,2068547594,Philip Potter,1771388,Laura E. Barnes,2115530197,Donald E. Brown,"Computer Science, Mathematics",JournalArticle
24,Anatomy of a Rumour: Social media and the suicide of Sushant Singh Rajput,"The suicide of Indian actor Sushant Singh Rajput in the midst of the COVID-19 lockdown triggered a media frenzy of prime time coverage that lasted several months and became a political hot button issue. Using data from Twitter, YouTube, and an archive of debunked misinformation stories, we found two important patterns. First, that retweet rates on Twitter clearly suggest that commentators benefited from talking about the case, which got higher engagement than other topics. Second, that politicians, in particular, were instrumental in changing the course of the discourse by referring to the case as 'murder', rather than 'suicide'. In conclusion, we consider the effects of Rajput's outsider status as a small-town implant in the film industry within the broader narrative of systemic injustice, as well as the gendered aspects of mob justice that have taken aim at his former partner in the months since.",ArXiv,2020,4,7,1,False,"{'model': 'tldr@v2.0.0', 'text': ""The effects of Rajput's outsider status as a small-town implant in the film industry within the broader narrative of systemic injustice, as well as the gendered aspects of mob justice that have taken aim at his former partner in the months since are considered.""}",24,1752287104,Syeda Zainab Akbar,2109670297,Ankur Sharma,1475315063,Himani Negi,1725426765,Anmol Panda,2111720,J. Pal,,,"Sociology, Computer Science",JournalArticle
25,SemEval-2023 Task 10: Explainable Detection of Online Sexism,"Online sexism is a widespread and harmful phenomenon. Automated tools can assist the detection of sexism at scale. Binary detection, however, disregards the diversity of sexist content, and fails to provide clear explanations for why something is sexist. To address this issue, we introduce SemEval Task 10 on the Explainable Detection of Online Sexism (EDOS). We make three main contributions: i) a novel hierarchical taxonomy of sexist content, which includes granular vectors of sexism to aid explainability; ii) a new dataset of 20,000 social media comments with fine-grained labels, along with larger unlabelled datasets for model adaptation; and iii) baseline models as well as an analysis of the methods, results and errors for participant submissions to our task.",ArXiv,2023,81,1,1,False,"{'model': 'tldr@v2.0.0', 'text': 'A novel hierarchical taxonomy of sexist content is introduced, which includes granular vectors of sexism to aid explainability and a new dataset of 20,000 social media comments with fine-grained labels is introduced.'}",25,90729626,Hannah Rose Kirk,48275690,Wenjie Yin,2737827,Bertie Vidgen,2043232919,Paul Röttger,,,,,Computer Science,JournalArticle
26,DeL-haTE: A Deep Learning Tunable Ensemble for Hate Speech Detection,"Online hate speech on social media has become a fast-growing problem in recent times. Nefarious groups have developed large content delivery networks across several mainstream (Twitter and Facebook) and fringe outlets (Gab, 4chan, 8chan, etc.) to deliver cascades of hate messages directed both at individuals and communities. Thus addressing these issues has become a top priority for large-scale social media outlets. Three key challenges in automated detection and classification of hateful content are the lack of clearly labeled data, evolving vocabulary and lexicon - hashtags, emojis, etc - and the lack of baseline models for fringe outlets such as Gab. In this work, we propose a novel framework with three major contributions. (a) We engineer an ensemble of deep learning models that combines the strengths of state-of-the-art approaches, (b) we incorporate a tuning factor into this framework that leverages transfer learning to conduct automated hate speech classification on unlabeled datasets, like Gab, and (c) we develop a weak supervised learning methodology that allows our framework to train on unlabeled data. Our ensemble models achieve an 83% hate recall on the HON dataset, surpassing the performance of the state of the art deep models. We demonstrate that weak supervised training in combination with classifier tuning significantly increases model performance on unlabeled data from Gab, achieving a hate recall of 67%.",International Conference on Machine Learning and Applications,2020,22,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work engineer an ensemble of deep learning models that combines the strengths of state-of-the-art approaches, and incorporates a tuning factor into this framework that leverages transfer learning to conduct automated hate speech classification on unlabeled datasets, like Gab.'}",26,2060571043,Joshua Melton,144227173,A. Bagavathi,14317484,S. Krishnan,,,,,,,Computer Science,"JournalArticle, Conference"
27,“Subverting the Jewtocracy”: Online Antisemitism Detection Using Multimodal Deep Learning,"The exponential rise of online social media has enabled the creation, distribution, and consumption of information at an unprecedented rate. However, it has also led to the burgeoning of various forms of online abuse. Increasing cases of online antisemitism have become one of the major concerns because of its socio-political consequences. Unlike other major forms of online abuse like racism, sexism, etc., online antisemitism has not been studied much from a machine learning perspective. To the best of our knowledge, we present the first work in the direction of automated multimodal detection of online antisemitism. The task poses multiple challenges that include extracting signals across multiple modalities, contextual references, and handling multiple aspects of antisemitism. Unfortunately, there does not exist any publicly available benchmark corpus for this critical task. Hence, we collect and label two datasets with 3,102 and 3,509 social media posts from Twitter and Gab respectively. Further, we present a multimodal deep learning system that detects the presence of antisemitic content and its specific antisemitism category using text and images from posts. We perform an extensive set of experiments on the two datasets to evaluate the efficacy of the proposed system. Finally, we also present a qualitative analysis of our study.",Web Science Conference,2021,43,17,2,True,"{'model': 'tldr@v2.0.0', 'text': 'This work presents a multimodal deep learning system that detects the presence of antisemitic content and its specific antisemitism category using text and images from posts.'}",27,32556330,Mohit Chandra,1388051395,D. Pailla,2001006896,Himanshu Bhatia,2028782907,AadilMehdi J. Sanchawala,46722320,Manish Gupta,2045067,Manish Shrivastava,Computer Science,"JournalArticle, Book"
28,Large-Scale Sleep Condition Analysis Using Selfies from Social Media,,"International Conference on Social, Cultural, and Behavioral Modeling",2017,26,8,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper attempts to develop a novel way to predict individual’s sleep condition via scrutinizing facial cues as doctors would, and can predict a sleep-deprived fatigue rate based on a selfie provided by a subject.'}",28,2109627163,Xuefeng Peng,33642939,Jiebo Luo,6397825,C. Glenn,13171221,Jingyao Zhan,2108173502,Yuhan Liu,,,"Computer Science, Psychology",JournalArticle
29,"""Call me sexist, but..."" : Revisiting Sexism Detection Using Psychological Scales and Adversarial Samples","Research has focused on automated methods to effectively detect sexism online. Although overt sexism seems easy to spot, its subtle forms and manifold expressions are not. In this paper, we outline the different dimensions of sexism by grounding them in their implementation in psychological scales. From the scales, we derive a codebook for sexism in social media, which we use to annotate existing and novel datasets, surfacing their limitations in breadth and validity with respect to the construct of sexism. Next, we leverage the annotated datasets to generate adversarial examples, and test the reliability of sexism detection methods. Results indicate that current machine learning models pick up on a very narrow set of linguistic markers of sexism and do not generalize well to out-of-domain examples. Yet, including diverse data and adversarial examples at training time results in models that generalize better and that are more robust to artifacts of data collection. By providing a scale-based codebook and insights regarding the shortcomings of the state-of-the-art, we hope to contribute to the development of better and broader models for sexism detection, including reflections on theory-driven approaches to data collection.",International Conference on Web and Social Media,2020,54,15,1,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper outlines the different dimensions of sexism by grounding them in their implementation in psychological scales, and derives a scale-based codebook for sexism in social media, which is used to annotate existing and novel datasets, and to test the reliability of sexism detection methods.'}",29,3071381,Mattia Samory,2113780702,Indira Sen,150150570,Julian Kohne,1724463,Fabian Flöck,144065562,Claudia Wagner,,,Computer Science,JournalArticle
30,Unsupervised detection of diachronic word sense evolution,"Most words have several senses and connotations which evolve in time due to semantic shift, so that closely related words may gain different or even opposite meanings over the years. This evolution is very relevant to the study of language and of cultural changes, but the tools currently available for diachronic semantic analysis have significant, inherent limitations and are not suitable for real-time analysis. In this article, we demonstrate how the linearity of random vectors techniques enables building time series of congruent word embeddings (or semantic spaces) which can then be compared and combined linearly without loss of precision over any time period to detect diachronic semantic shifts. We show how this approach yields time trajectories of polysemous words such as amazon or apple, enables following semantic drifts and gender bias across time, reveals the shifting instantiations of stable concepts such as hurricane or president. This very fast, linear approach can easily be distributed over many processors to follow in real time streams of social media such as Twitter or Facebook; the resulting, time-dependent semantic spaces can then be combined at will by simple additions or subtractions.",ArXiv,2018,18,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This article demonstrates how the linearity of random vectors techniques enables building time series of congruent word embeddings (or semantic spaces) which can be compared and combined linearly without loss of precision over any time period to detect diachronic semantic shifts.'}",30,23185383,Jean-François Delpech,,,,,,,,,,,Computer Science,JournalArticle
31,Generic Multilayer Network Data Analysis with the Fusion of Content and Structure,"Multi-feature data analysis (e.g., on Facebook, LinkedIn) is challenging especially if one wants to do it efficiently and retain the flexibility by choosing features of interest for analysis. Features (e.g., age, gender, relationship, political view etc.) can be explicitly given from datasets, but also can be derived from content (e.g., political view based on Facebook posts). Analysis from multiple perspectives is needed to understand the datasets (or subsets of it) and to infer meaningful knowledge. For example, the influence of age, location, and marital status on political views may need to be inferred separately (or in combination). In this paper, we adapt multilayer network (MLN) analysis, a nontraditional approach, to model the Facebook datasets, integrate content analysis, and conduct analysis, which is driven by a list of desired application based queries. Our experimental analysis shows the flexibility and efficiency of the proposed approach when modeling and analyzing datasets with multiple features.",ArXiv,2019,34,9,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper adapts multilayer network (MLN) analysis, a nontraditional approach, to model the Facebook datasets, integrate content analysis, and conduct analysis, which is driven by a list of desired application based queries.'}",31,2399573,Xuan-Son Vu,48130919,Abhishek Santra,2503073,Sharma Chakravarthy,1630481449,Lili Jiang,,,,,Computer Science,JournalArticle
32,Analysing Cyberbullying using Natural Language Processing by Understanding Jargon in Social Media,,ArXiv,2021,21,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work explores binary classification by using a combination of datasets from various social media platforms that cover a wide range of cyberbullying such as sexism, racism, abusive, and hate-speech and applies a unique preprocessing technique by introducing a slang-abusive corpus.'}",32,2120034320,Bhumika Bhatia,2113856300,Anuj Verma,2079227751,Anjum,3126857,R. Katarya,,,,,Computer Science,JournalArticle
33,Hate Lingo: A Target-based Linguistic Analysis of Hate Speech in Social Media,"
 
 While social media empowers freedom of expression and individual voices, it also enables anti-social behavior, online harassment, cyberbullying, and hate speech. In this paper, we deepen our understanding of online hate speech by focusing on a largely neglected but crucial aspect of hate speech -- its target: either directed towards a specific person or entity, or generalized towards a group of people sharing a common protected characteristic. We perform the first linguistic and psycholinguistic analysis of these two forms of hate speech and reveal the presence of interesting markers that distinguish these types of hate speech. Our analysis reveals that Directed hate speech, in addition to being more personal and directed, is more informal, angrier, and often explicitly attacks the target (via name calling) with fewer analytic words and more words suggesting authority and influence. Generalized hate speech, on the other hand, is dominated by religious hate, is characterized by the use of lethal words such as murder, exterminate, and kill; and quantity words such as million and many. Altogether, our work provides a data-driven analysis of the nuances of online-hate speech that enables not only a deepened understanding of hate speech and its social implications, but also its detection.
 
",International Conference on Web and Social Media,2018,47,197,17,True,"{'model': 'tldr@v2.0.0', 'text': 'This work provides a data-driven analysis of the nuances of online-hate speech that enables not only a deepened understanding of hate speech and its social implications, but also its detection.'}",33,2165346,Mai ElSherief,144592382,Vivek Kulkarni,49141732,Dana Nguyen,1682479,William Yang Wang,1397933253,E. Belding-Royer,,,"Computer Science, Psychology",JournalArticle
34,Automatic Sexism Detection with Multilingual Transformer Models,". Sexism has become an increasingly signiﬁcant problem on social networks in recent years. The ﬁrst shared task on sEXism Identiﬁcation in Social neTworks (EXIST) at IberLEF 2021 is an international competition in the ﬁeld of Natural Language Processing (NLP) with the aim to automatically identify sexism in social media content by applying machine learning methods. Thereby sexism detection is formulated as a coarse (binary) classiﬁcation problem and a ﬁne-grained classiﬁcation task that distinguishes multiple types of sexist content (e.g., dominance, stereotyping, and objectiﬁcation). This paper presents the contribution of the AIT FHSTP team at the EXIST2021 benchmark for both tasks. To solve the task,s we applied two multilingual transformer models, one based on multilingual BERT and one based on XLM-R. Our approach uses two diﬀerent strategies to adapt the transformers to the detection of sexist content: ﬁrst, unsupervised pre-training with additional data and second, supervised ﬁne-tuning with additional and augmented data. For both tasks our best model is XLM-R with unsupervised pre-training on the EXIST data and additional datasets and ﬁne-tuning on the provided dataset. The best run for the binary classiﬁcation (task 1) achieves a macro F1-score of 0.7752 and scores 5 th rank in the benchmark; for the multiclass classiﬁcation (task 2) our best submission scores 6 th rank with a macro F1-score of 0.5589.",ArXiv,2021,16,5,0,False,"{'model': 'tldr@v2.0.0', 'text': 'The contribution of the AIT FHSTP team at the EXIST2021 benchmark for both tasks is presented, with the best model is XLM-R with unsupervised pre-training on the EXist data and additional datasets and ﬁne-tuning on the provided dataset.'}",34,2051453710,Mina Schütz,2112477139,Jaqueline Boeck,2112707326,Daria Liakhovets,31522269,D. Slijepcevic,51262302,Armin Kirchknopf,2112477178,Manuel Hecht,Computer Science,JournalArticle
35,Race and Religion in Online Abuse towards UK Politicians: Working Paper,"Against a backdrop of tensions related to EU membership, we find levels of online abuse toward UK MPs reach a new high. Race and religion have become pressing topics globally, and in the UK this interacts with ""Brexit"" and the rise of social media to create a complex social climate in which much can be learned about evolving attitudes. In 8 million tweets by and to UK MPs in the first half of 2019, religious intolerance scandals in the UK's two main political parties attracted significant attention. Furthermore, high profile ethnic minority MPs started conversations on Twitter about race and religion, the responses to which provide a valuable source of insight. We found a significant presence for disturbing racial and religious abuse. We also explore metrics relating to abuse patterns, which may affect its impact. We find ""burstiness"" of abuse doesn't depend on race or gender, but individual factors may lead to politicians having very different experiences online.",ArXiv,2019,44,11,1,False,"{'model': 'tldr@v2.0.0', 'text': 'Against a backdrop of tensions related to EU membership, it is found levels of online abuse toward UK MPs reach a new high and ""burstiness"" of abuse doesn\'t depend on race or gender, but individual factors may lead to politicians having very different experiences online.'}",35,2448400,Genevieve Gorrell,39954447,M. Bakir,48960199,M. Greenwood,2057116454,Ian Roberts,1723649,Kalina Bontcheva,,,"Political Science, Computer Science",JournalArticle
36,"AbuseAnalyzer: Abuse Detection, Severity and Target Prediction for Gab Posts","While extensive popularity of online social media platforms has made information dissemination faster, it has also resulted in widespread online abuse of different types like hate speech, offensive language, sexist and racist opinions, etc. Detection and curtailment of such abusive content is critical for avoiding its psychological impact on victim communities, and thereby preventing hate crimes. Previous works have focused on classifying user posts into various forms of abusive behavior. But there has hardly been any focus on estimating the severity of abuse and the target. In this paper, we present a first of the kind dataset with 7,601 posts from Gab which looks at online abuse from the perspective of presence of abuse, severity and target of abusive behavior. We also propose a system to address these tasks, obtaining an accuracy of ∼80% for abuse presence, ∼82% for abuse target prediction, and ∼65% for abuse severity prediction.",International Conference on Computational Linguistics,2020,25,8,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A first of the kind dataset with 7,601 posts from Gab is presented which looks at online abuse from the perspective of presence of abuse, severity and target of abusive behavior and a system to address these tasks is proposed.'}",36,32556330,Mohit Chandra,2143558183,Ashwin Pathak,1978150704,Eesha Dutta,1977275894,Paryul Jain,46722320,Manish Gupta,2045067,Manish Shrivastava,Computer Science,"JournalArticle, Conference"
37,A Simple Voting Mechanism for Online Sexist Content Identification,"This paper presents the participation of the MiniTrue team in the EXIST 2021 Challenge on the sexism detection in social media task for English and Spanish. Our approach combines the language models with a simple voting mechanism for the sexist label prediction. For this, three BERT based models and a voting function are used. Experimental results show that our final model with the voting function has achieved the best results among our four models, which means that our voting mechanism brings an extra benefit to our system. Nevertheless, we also observe that our system is robust to data sources and languages.",IberLEF@SEPLN,2021,16,1,0,False,"{'model': 'tldr@v2.0.0', 'text': None}",37,2089776239,Chao Feng,,,,,,,,,,,Computer Science,JournalArticle
38,Identifying Different Layers of Online Misogyny,",",ArXiv,2022,45,0,0,False,"{'model': 'tldr@v2.0.0', 'text': None}",38,1995243017,Wienke Strathern,2052137324,J. Pfeffer,,,,,,,,,Computer Science,JournalArticle
39,On Predicting Sociodemographic Traits and Emotions from Communications in Social Networks and Their Implications to Online Self-Disclosure,"Social media services such as Twitter and Facebook are virtual environments where people express their thoughts, emotions, and opinions and where they reveal themselves to their peers. We analyze a sample of 123,000 Twitter users and 25 million of their tweets to investigate the relation between the opinions and emotions that users express and their predicted psychodemographic traits. We show that the emotions that we express on online social networks reveal deep insights about ourselves. Our methodology is based on building machine learning models for inferring coarse-grained emotions and psychodemographic profiles from user-generated content. We examine several user attributes, including gender, income, political views, age, education, optimism, and life satisfaction. We correlate these predicted demographics with the emotional profiles emanating from user tweets, as captured by Ekman's emotion classification. We find that some users tend to express significantly more joy and significantly less sadness in their tweets, such as those predicted to be in a relationship, with children, or with a higher than average annual income or educational level. Users predicted to be women tend to be more opinionated, whereas those predicted to be men tend to be more neutral. Finally, users predicted to be younger and liberal tend to project more negative opinions and emotions. We discuss the implications of our findings to online privacy concerns and self-disclosure behavior.","Cyberpsychology, Behavior, and Social Networking",2015,74,67,5,False,"{'model': 'tldr@v2.0.0', 'text': 'It is found that some users tend to express significantly more joy and significantly less sadness in their tweets, such as those predicted to be in a relationship, with children, or with a higher than average annual income or educational level.'}",39,143683394,Svitlana Volkova,1698412,Yoram Bachrach,,,,,,,,,"Psychology, Medicine, Computer Science",JournalArticle
40,Demographic and Structural Characteristics to Rationalize Link Formation in Online Social Networks,"Recent years have seen tremendous growth of many online social networks such as Facebook, Linked In and My Space. People connect to each other through these networks forming large social communities providing researchers rich datasets to understand, model and predict social interactions and behaviors. New contacts in these networks can be formed either due to an individual's demographic profile such as age group, gender, geographic location or due to network's structural dynamics such as triadic closure and preferential attachment, or a combination of both demographic and structural characteristics. A number of network generation models have been proposed in the last decade to explain the structure, evolution and processes taking place in different types of networks, and notably social networks. Network generation models studied in the literature primarily consider structural properties, and in some cases an individual's demographic profile in the formation of new social contacts. These models do not present a mechanism to combine both structural and demographic characteristics for the formation of new links. In this paper, we propose a new network generation algorithm which incorporates both these characteristics to model growth of a network. We use different publicly available Facebook datasets as benchmarks to demonstrate the correctness of the proposed network generation model.",International Conference on Signal-Image Technology and Internet-Based Systems,2013,55,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A new network generation algorithm is proposed which incorporates both structural and demographic characteristics to model growth of a network and uses different publicly available Facebook datasets as benchmarks to demonstrate the correctness of the proposed network generation model.'}",40,1800026,Mohammad Qasim Pasta,21210280,Z. Jan,6120512,Faraz Zaidi,3347169,C. Rozenblat,,,,,Computer Science,"JournalArticle, Conference"
41,Cyberbullying Detection Using Deep Neural Network from Social Media Comments in Bangla Language,"Cyberbullying or Online harassment detection on social media for various major languages is currently being given a good amount of focus by researchers worldwide. Being the seventh most speaking language in the world and increasing usage of online platform among the Bengali speaking people urge to find effective detection technique to handle the online harassment. In this paper, we have proposed binary and multiclass classification model using hybrid neural network for bully expression detection in Bengali language. We have used 44,001 users’ comments from popular public Facebook pages, which fall into five classes Non-bully, Sexual, Threat, Troll and Religious. We have examined the performance of our proposed models from different perspective. Our binary classification model gives 87.91% accuracy, whereas introducing ensemble technique after neural network for multiclass classification, we got 85% accuracy. Index Terms Online Harassment, Bully Detection, Sentiment Analysis, Natural Language Processing, Neural Network, Bangla Language Processing",ArXiv,2021,30,3,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper has proposed binary and multiclass classification model using hybrid neural network for bully expression detection in Bengali language and examined the performance of the proposed models from different perspective.'}",41,2109417020,Md Faisal Ahmed,2047832126,Zalish Mahmud,2047832070,Zarin Tasnim Biash,2047832085,Ahmed Ann Noor Ryen,2055285123,Arman Hossain,10676418,Faisal Bin Ashraf,Computer Science,JournalArticle
42,Analyzing gender inequality through large-scale Facebook advertising data,"Significance We present the Facebook Gender Divide, an inexpensive, real-time instrument for measuring gender differences in Facebook access and activity in 217 countries. The Facebook Gender Divide captures standard indicators of Internet penetration and gender equality indices in education, health, and economic opportunity. We find that the tendency of countries to approach economic gender equality is negatively associated with a high Facebook Gender Divide. Our results suggest that online social networks, while suffering gender imbalance, may lower information access barriers for women and narrow the economic gender gap. Online social media are information resources that can have a transformative power in society. While the Web was envisioned as an equalizing force that allows everyone to access information, the digital divide prevents large amounts of people from being present online. Online social media, in particular, are prone to gender inequality, an important issue given the link between social media use and employment. Understanding gender inequality in social media is a challenging task due to the necessity of data sources that can provide large-scale measurements across multiple countries. Here, we show how the Facebook Gender Divide (FGD), a metric based on aggregated statistics of more than 1.4 billion users in 217 countries, explains various aspects of worldwide gender inequality. Our analysis shows that the FGD encodes gender equality indices in education, health, and economic opportunity. We find gender differences in network externalities that suggest that using social media has an added value for women. Furthermore, we find that low values of the FGD are associated with increases in economic gender equality. Our results suggest that online social networks, while suffering evident gender imbalance, may lower the barriers that women have to access to informational resources and help to narrow the economic gender gap.",Proceedings of the National Academy of Sciences,2018,51,54,3,True,"{'model': 'tldr@v2.0.0', 'text': 'The Facebook Gender Divide, an inexpensive, real-time instrument for measuring gender differences in Facebook access and activity in 217 countries, is presented and shows that the FGD encodes gender equality indices in education, health, and economic opportunity.'}",42,2082309897,David García,8070800,Y. Kassa,145518428,Ángel Cuevas,145512647,Manuel Cebrian,4410019,Esteban Moro Egido,1705156,I. Rahwan,"Computer Science, Medicine, Sociology",JournalArticle
43,"Women's Solidarity and Social Media: Sisterhood Concept in #LasRespondonas, a Facebook group in Peru","Women in Peru are exposed daily to gender violence and exclusion. Several feminist groups have used social media to share information, debate, denounce, organize, and provide help to victims. This contribution analyzes the meaning of female solidarity, sisterhood or sororidad, as a feminist political concept among members of one feminist Facebook group. We reviewed the how various feminist and sisterhood concepts clustered together in the group communications by reviewing group publications and comments as far as interviewing key former and current members. The sisterhood concept was found to be central to feminist practice.",ArXiv,2021,50,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'The meaning of female solidarity, sisterhood or sororidad, as a feminist political concept among members of one feminist Facebook group is analyzed and the sisterhood concept was found to be central to feminist practice.'}",43,3486015,J. Bossio,2060009557,I. Diez,,,,,,,,,Computer Science,"JournalArticle, Review"
44,TIB-VA at SemEval-2022 Task 5: A Multimodal Architecture for the Detection and Classification of Misogynous Memes,"The detection of offensive, hateful content on social media is a challenging problem that affects many online users on a daily basis. Hateful content is often used to target a group of people based on ethnicity, gender, religion and other factors. The hate or contempt toward women has been increasing on social platforms. Misogynous content detection is especially challenging when textual and visual modalities are combined to form a single context, e.g., an overlay text embedded on top of an image, also known as meme. In this paper, we present a multimodal architecture that combines textual and visual features to detect misogynous memes. The proposed architecture is evaluated in the SemEval-2022 Task 5: MAMI - Multimedia Automatic Misogyny Identification challenge under the team name TIB-VA. We obtained the best result in the Task-B where the challenge is to classify whether a given document is misogynous and further identify the following sub-classes: shaming, stereotype, objectification, and violence.",International Workshop on Semantic Evaluation,2022,18,1,1,False,"{'model': 'tldr@v2.0.0', 'text': 'A multimodal architecture that combines textual and visual features to detect misogynous memes is presented and the best result is obtained in the Task-B where the challenge is to classify whether a given document is misogynous and further identify the following sub-classes: shaming, stereotype, objectification, and violence.'}",44,2079305,Sherzod Hakimov,39866663,Gullal S. Cheema,1738703,R. Ewerth,,,,,,,Computer Science,JournalArticle
45,Inferring User Gender from User Generated Visual Content on a Deep Semantic Space,"In this paper we address the task of gender classification on picture sharing social media networks such as Instagram and Flickr. We aim to infer the gender of an user given only a small set of the images shared in its profile. We make the assumption that user's images contain a collection of visual elements that implicitly encode discriminative patterns that allow inferring its gender, in a language independent way. This information can then be used in personalisation and recommendation. Our main hypothesis is that semantic visual features are more adequate for discriminating high-level classes. The gender detection task is formalised as: given an user's profile, represented as a bag of images, we want to infer the gender of the user. Social media profiles can be noisy and contain confounding factors, therefore we classify bags of user-profile‘s images to provide a more robust prediction. Experiments using a dataset from the picture sharing social network Instagram show that the use of multiple images is key to improve detection performance. Moreover, we verify that deep semantic features are more suited for gender detection than low-level image representations. The methods proposed can infer the gender with precision scores higher than 0.825, and the best performing method achieving 0.911 precision.",European Signal Processing Conference,2018,19,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper addresses the task of gender classification on picture sharing social media networks such as Instagram and Flickr, and proves that deep semantic features are more suited for gender detection than low-level image representations.'}",45,3442611,David Semedo,144431718,João Magalhães,143713019,Flávio Martins,,,,,,,Computer Science,"JournalArticle, Conference"
46,HateBR: A Large Expert Annotated Corpus of Brazilian Instagram Comments for Offensive Language and Hate Speech Detection,"Due to the severity of the social media offensive and hateful comments in Brazil, and the lack of research in Portuguese, this paper provides the first large-scale expert annotated corpus of Brazilian Instagram comments for hate speech and offensive language detection. The HateBR corpus was collected from the comment section of Brazilian politicians’ accounts on Instagram and manually annotated by specialists, reaching a high inter-annotator agreement. The corpus consists of 7,000 documents annotated according to three different layers: a binary classification (offensive versus non-offensive comments), offensiveness-level classification (highly, moderately, and slightly offensive), and nine hate speech groups (xenophobia, racism, homophobia, sexism, religious intolerance, partyism, apology for the dictatorship, antisemitism, and fatphobia). We also implemented baseline experiments for offensive language and hate speech detection and compared them with a literature baseline. Results show that the baseline experiments on our corpus outperform the current state-of-the-art for the Portuguese language.",International Conference on Language Resources and Evaluation,2021,47,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper provides the first large-scale expert annotated corpus of Brazilian Instagram comments for hate speech and offensive language detection, and implements baseline experiments for offensive language and hate speech detection and compared them with a literature baseline.'}",46,2055384062,F. Vargas,2054854198,Isabelle Carvalho,34572250,F. Góes,1774467,T. Pardo,1869561,Fabrício Benevenuto,,,Computer Science,JournalArticle
47,"White, man, and highly followed: gender and race inequalities in Twitter","Social media is considered a democratic space in which people connect and interact with each other regardless of their gender, race, or any other demographic factor. Despite numerous efforts that explore demographic factors in social media, it is still unclear whether social media perpetuates old inequalities from the offline world. In this paper, we attempt to identify gender and race of Twitter users located in U.S. using advanced image processing algorithms from Face++. Then, we investigate how different demographic groups (i.e. male/female, Asian/Black/White) connect with other. We quantify to what extent one group follow and interact with each other and the extent to which these connections and interactions reflect in inequalities in Twitter. Our analysis shows that users identified as White and male tend to attain higher positions in Twitter, in terms of the number of followers and number of times in user's lists. We hope our effort can stimulate the development of new theories of demographic information in the online space.",International Conference on Wirtschaftsinformatik,2017,49,40,3,True,"{'model': 'tldr@v2.0.0', 'text': 'Gender and race of Twitter users located in U.S. are identified using advanced image processing algorithms from Face++ to investigate how different demographic groups connect with other and whether these connections and interactions reflect in inequalities in Twitter.'}",47,145791827,Johnnatan Messias,1790849,Pantelis Vikatos,1869561,Fabrício Benevenuto,,,,,,,"Computer Science, Psychology, Sociology","JournalArticle, Book"
48,How Biased is the Population of Facebook Users? Comparing the Demographics of Facebook Users with Census Data to Generate Correction Factors,"Censuses and representative sampling surveys around the world are key sources of data to guide government investments and public policies. However, these sources are very expensive to obtain and are collected relatively infrequently. Over the last decade, there has been growing interest in the use of data from social media to complement more traditional data sources. However, social media users are not representative of the general population. Thus, analyses based on social media data require statistical adjustments, like post-stratification, in order to remove the bias and make solid statistical claims. These adjustments are possible only when we have information about the frequency of demographic groups using social media. These data, when compared with official statistics, enable researchers to produce appropriate statistical correction factors. In this paper, we leverage the Facebook advertising platform to compile the equivalent of an aggregate-level census of Facebook users. Our compilation includes the population distribution for seven demographic attributes such as gender, political leaning, and educational attainment at different geographic levels for the U.S. (country, state, and city). By comparing the Facebook counts with official reports provided by the U.S. Census and Gallup, we found very high correlations, especially for political leaning and race. We also identified instances where official statistics may be underestimating population counts as in the case of immigration. We use the information collected to calculate bias correction factors for all computed attributes in order to evaluate the extent to which different demographic groups are more or less represented on Facebook, and to derive the actual distributions for specific audiences of interest. We provide the first comprehensive analysis for assessing biases in Facebook users across several dimensions. This information can be used to generate bias-adjusted population estimates and demographic counts in a timely way and at fine geographic granularity in between data releases of official statistics.",Web Science Conference,2020,31,39,2,True,"{'model': 'tldr@v2.0.0', 'text': 'A first comprehensive analysis for assessing biases in Facebook users across several dimensions is provided, which can be used to generate bias-adjusted population estimates and demographic counts in a timely way and at fine geographic granularity in between data releases of official statistics.'}",48,2411946,Filipe Nunes Ribeiro,1869561,Fabrício Benevenuto,2140221,E. Zagheni,,,,,,,"Computer Science, Sociology, Geography","Book, JournalArticle, Review"
49,Hate Speech Dataset from a White Supremacy Forum,"Hate speech is commonly defined as any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic. Due to the massive rise of user-generated web content on social media, the amount of hate speech is also steadily increasing. Over the past years, interest in online hate speech detection and, particularly, the automation of this task has continuously grown, along with the societal impact of the phenomenon. This paper describes a hate speech dataset composed of thousands of sentences manually labelled as containing hate speech or not. The sentences have been extracted from Stormfront, a white supremacist forum. A custom annotation tool has been developed to carry out the manual labelling task which, among other things, allows the annotators to choose whether to read the context of a sentence before labelling it. The paper also provides a thoughtful qualitative and quantitative study of the resulting dataset and several baseline experiments with different classification models. The dataset is publicly available.",Workshop on Abusive Language Online,2018,32,228,26,True,"{'model': 'tldr@v2.0.0', 'text': 'A custom annotation tool has been developed to carry out the manual labelling task which, among other things, allows the annotators to choose whether to read the context of a sentence before labelling it.'}",49,51436367,Ona de Gibert,143801369,Naiara Pérez,2336021,Aitor García-Pablos,1791107,Montse Cuadros,,,,,"Computer Science, Psychology",JournalArticle
50,A Streaming Machine Learning Framework for Online Aggression Detection on Twitter,"The rise of online aggression on social media is evolving into a major point of concern. Several machine and deep learning approaches have been proposed recently for detecting various types of aggressive behavior. However, social media are fast paced, generating an increasing amount of content, while aggressive behavior evolves over time. In this work, we introduce the first, practical, real-time framework for detecting aggression on Twitter via embracing the streaming machine learning paradigm. Our method adapts its ML classifiers in an incremental fashion as it receives new annotated examples and is able to achieve the same (or even higher) performance as batch-based ML models, with over 90% accuracy, precision, and recall. At the same time, our experimental analysis on real Twitter data reveals how our framework can easily scale to accommodate the entire Twitter Firehose (of 778 million tweets per day) with only 3 commodity machines. Finally, we show that our framework is general enough to detect other related behaviors such as sarcasm, racism, and sexism in real time.",2020 IEEE International Conference on Big Data (Big Data),2020,42,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work introduces the first, practical, real-time framework for detecting aggression on Twitter via embracing the streaming machine learning paradigm, and shows that the framework is general enough to detect other related behaviors such as sarcasm, racism, and sexism in real time.'}",50,2013116,H. Herodotou,2550292,Despoina Chatzakou,1946641,N. Kourtellis,,,,,,,Computer Science,"JournalArticle, Conference"
51,"Online Abuse of UK MPs in 2015 and 2017: Perpetrators, Targets, and Topics","Concerns have reached the mainstream about how social media are affecting political outcomes. One trajectory for this is the exposure of politicians to online abuse. In this paper we use 1.4 million tweets from the months before the 2015 and 2017 UK general elections to explore the abuse directed at politicians. This collection allows us to look at abuse broken down by both party and gender and aimed at specific Members of Parliament. It also allows us to investigate the characteristics of those who send abuse and their topics of interest. Results show that in both absolute and proportional terms, abuse increased substantially in 2017 compared with 2015. Abusive replies are somewhat less directed at women and those not in the currently governing party. Those who send the abuse may be issue-focused, or they may repeatedly target an individual. In the latter category, accounts are more likely to be throwaway. Those sending abuse have a wide range of topical triggers, including borders and terrorism.",ArXiv,2018,31,8,1,False,"{'model': 'tldr@v2.0.0', 'text': '1.4 million tweets from the months before the 2015 and 2017 UK general elections are used to explore the abuse directed at politicians, broken down by both party and gender and aimed at specific Members of Parliament.'}",51,2448400,Genevieve Gorrell,48960199,M. Greenwood,2057116454,Ian Roberts,2144272,D. Maynard,1723649,Kalina Bontcheva,,,Computer Science,JournalArticle
52,Social media emotion macroscopes reflect emotional experiences in society at large,"Social media generate data on human behaviour at large scales and over long periods of time, posing a complementary approach to traditional methods in the social sciences1. Millions of texts from social media can be processed with computational methods to study emotions2,3 over time and across regions4,5. However, recent research has shown weak correlations between social media emotions and affect questionnaires at the individual level6,7 and between static regional aggregates of social media emotion and subjective well-being at the population level8, questioning the validity of social media data to study emotions. Yet, to date, no research has tested the validity of social media emotion macroscopes to track the temporal evolution of emotions at the level of a whole society. Here we present a pre-registered prediction study that shows how gender-rescaled time series of Twitter emotional expression at the national level substantially correlate with aggregates of self-reported emotions in a weekly representative survey in the United Kingdom. A follow-up exploratory analysis shows a high prevalence of third-person references in emotionally-charged tweets, indicating that social media data provide a way of social sensing the emotions of others9 rather than just the emotional experiences of users. These results show that, despite the issues that social media have in terms of representativeness10 and algorithmic confounding11, the combination of advanced text analysis methods with user demographic information in social media emotion macroscopes can provide measures that are informative of the general population beyond social media users. In our digital society, new technologies for social interaction are playing a key role in capturing and shaping our emotional experiences. Affect plays an central role in several important phenomena12, including affective polarization across political identities13, 14, emotional components in misinformation15, and sentiment in online attention and engagement16. At the same time, social technologies generate data on social interaction that has the potential to capture emotional expression at new scales and resolutions. This has motivated applications of social media data to affective research questions such as mental health17, emotional well-being8, anxiety7, collective emotions18, and emotion regulation19. An especially powerful approach is the implementation of emotion macroscopes that can aggregate affective information at large scales and fast temporal resolutions, often relying on text analysis4 or mental health tracker data20. However, social media data is not designed for behaviour research, bringing concerns about algorithmic and preformative behaviour issues1, 11, as well as sampling biases that make social media users not representative of the population at large in terms of demographics and other relevant attributes10. Testing the validity of social media emotion macroscopes as a measurement of aggregates of emotional experiences has remained an elusive task due to three challenges: scarcity of frequent representative surveys of emotions, the technical barriers to analyze large-scale longitudinal geo-located data from social media, and the low precision of emotion detection methods from social media text. Here we address these three challenges in a pre-registered validation study of social media macroscopes of several emotional states. We use a comprehensive dataset of social media text from the United Kingdom and apply both established and advanced text analysis methods to measure emotion aggregates. Results are then compared with two years of emotion data from a representative survey in the UK. We present a pre-registered study testing that Twitter aggregated emotion timelines positively correlate with weekly emotion reports when applying dictionary-based methods and taking gender into account (more details about pre-registration in the Supplementary Information). The first part of our pre-registration describes a test of our hypotheses for historical data up to October 2020. The second part of the pre-registration postulates the same hypotheses and analysis as a prediction for a future ar X iv :2 10 7. 13 23 6v 1 [ cs .S I] 2 8 Ju l 2 02 1 time period. This way we test the generalizability of our results across time, making a proper prediction rather than doing retrodictive data analysis alone21. Our analysis covers the period between June 2019 and June 2021, including a total of more than 1.5 Billion tweets posted by users in the United Kingdom (see Materials and Methods for more information). We designed the study to test two approaches to emotion detection from text: the most popular dictionary-based method with emotion word lists in English22, and a state-of-the-art supervised classifier that we trained against a large corpus of tweets with annotated emotions2 (see Methods). The fraction of tweets posted by men is above 60%, in line with the higher visibility of men on Twitter23. Because of this, gender-agnostic measures have the risk of overweighting male voices on Twitter. This can be a source of systematic error given the known gender differences in emotional experiences24–26. We use gender information about the users in our sample to calculate gender-rescaled emotional expression indices that are more representative of the population of the UK. The measurements of sadness in the survey and on Twitter are consistently correlated between historical and predicted periods of our pre-registration, as shown in Figure 1. The dictionary approach achieves substantial positive correlations (0.69 in the historical period and 0.672 in the prediction period) as well the supervised method (0.636 in the historical period and 0.653 in the prediction period). Similarly, for the case of scared in the survey versus anxiety or fear in Twitter, illustrated in Figure 1, shows strong correlations in the historical period (0.78 for dictionary method and 0.793 for supervised method). As preregistered, the dictionary method is positively correlated in the prediction period with a coefficient of 0.471, but the supervised method has a weaker correlation close to 0.30. A summary and statistical details of these correlations are reported on Table 1.",ArXiv,2021,41,3,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A pre-registered prediction study shows how gender-rescaled time series of Twitter emotional expression at the national level substantially correlate with aggregates of self-reported emotions in a weekly representative survey in the United Kingdom, and testing that Twitter aggregated emotion timelines positively correlate with weekly emotion reports when applying dictionary-based methods and taking gender into account.'}",52,2082309728,David García,103932770,Max Pellert,23724710,J. Lasser,2072307744,H. Metzler,,,,,Computer Science,"JournalArticle, Review"
53,"""And We Will Fight For Our Race!"" A Measurement Study of Genetic Testing Conversations on Reddit and 4chan","Progress in genomics has enabled the emergence of a booming market for “direct-to-consumer” genetic testing. Nowadays, companies like 23andMe and AncestryDNA provide affordable health, genealogy, and ancestry reports, and have already tested tens of millions of customers. At the same time, alt- and far-right groups have also taken an interest in genetic testing, using them to attack minorities and prove their genetic “purity.” In this paper, we present a measurement study shedding light on how genetic testing is being discussed on Web communities in Reddit and 4chan. We collect 1.3M comments posted over 27 months on the two platforms, using a set of 280 keywords related to genetic testing. We then use NLP and computer vision tools to identify trends, themes, and topics of discussion. Our analysis shows that genetic testing attracts a lot of attention on Reddit and 4chan, with discussions often including highly toxic language expressed through hateful, racist, and misogynistic comments. In particular, on 4chan's politically incorrect board (/pol/), content from genetic testing conversations involves several alt-right personalities and openly antisemitic rhetoric, often conveyed through memes. Finally, we find that discussions build around user groups, from technology enthusiasts to communities promoting fringe political views.",International Conference on Web and Social Media,2019,82,50,1,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper presents a measurement study shedding light on how genetic testing is being discussed on Web communities in Reddit and 4chan, using NLP and computer vision tools to identify trends, themes, and topics of discussion.'}",53,30450280,Alexandros Mittos,3447293,Savvas Zannettou,144728530,J. Blackburn,1728207,Emiliano De Cristofaro,,,,,"Computer Science, Sociology",JournalArticle
54,A comparison of online hate on reddit and 4chan: a case study of the 2020 US election,"The rapid integration of the Internet into our daily lives has led to many benefits but also to a number of new, wide-spread threats such as online hate, trolling, bullying, and generally aggressive behaviours. While research has traditionally explored online hate, in particular, on one platform, the reality is that such hate is a phenomenon that often makes use of multiple online networks. In this article, we seek to advance the discussion into online hate by harnessing a comparative approach, where we make use of various Natural Language Processing (NLP) techniques to computationally analyse hateful content from Reddit and 4chan relating to the 2020 US Presidential Elections. Our findings show how content and posting activity can differ depending on the platform being used. Through this, we provide initial comparison into the platform-specific behaviours of online hate, and how different platforms can serve specific purposes. We further provide several avenues for future research utilising a cross-platform approach so as to gain a more comprehensive understanding of the global hate ecosystem.",ACM Symposium on Applied Computing,2022,13,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This article makes use of various Natural Language Processing (NLP) techniques to computationally analyse hateful content from Reddit and 4chan relating to the 2020 US Presidential Elections, and shows how content and posting activity can differ depending on the platform being used.'}",54,1910550048,Fatima Zahrah,1803701,Jason R. C. Nurse,143914330,M. Goldsmith,,,,,,,Computer Science,"JournalArticle, Book"
55,Using Sociolinguistic Variables to Reveal Changing Attitudes Towards Sexuality and Gender,"Individuals signal aspects of their identity and beliefs through linguistic choices. Studying these choices in aggregate allows us to examine large-scale attitude shifts within a population. Here, we develop computational methods to study word choice within a sociolinguistic lexical variable—alternate words used to express the same concept—in order to test for change in the United States towards sexuality and gender. We examine two variables: i) referents to significant others, such as the word “partner” and ii) referents to an indefinite person, both of which could optionally be marked with gender. The linguistic choices in each variable allow us to study increased rates of acceptances of gay marriage and gender equality, respectively. In longitudinal analyses across Twitter and Reddit over 87M messages, we demonstrate that attitudes are changing but that these changes are driven by specific demographics within the United States. Further, in a quasi-causal analysis, we show that passages of Marriage Equality Acts in different states are drivers of linguistic change.",Conference on Empirical Methods in Natural Language Processing,2021,99,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'It is demonstrated that attitudes are changing but that these changes are driven by specific demographics within the United States, and it is shown that passages of Marriage Equality Acts in different states are drivers of linguistic change.'}",55,12782016,Sky CH-Wang,3046220,David Jurgens,,,,,,,,,Computer Science,"JournalArticle, Conference"
56,A Multimodal Dataset of Images and Text to Study Abusive Language,"In order to study online hate speech, the availability of datasets containing the linguistic phenomena of interest are of crucial importance. However, when it comes to specific target groups, for example teenagers, collecting such data may be problematic due to issues with consent and privacy restrictions. Furthermore, while text-only datasets of this kind have been widely used, limitations set by image-based social media platforms like Instagram make it difficult for researchers to experiment with multimodal hate speech data. We therefore developed CREENDER, an annotation tool that has been used in school classes to create a multimodal dataset of images and abusive comments, which we make freely available under Apache 2.0 license. The corpus, with Italian comments, has been analysed from different perspectives, to investigate whether the subject of the images plays a role in triggering a comment. We find that users judge the same images in different ways, although the presence of a person in the picture increases the probability to get an offensive comment.",Italian Conference on Computational Linguistics,2020,26,9,1,True,"{'model': 'tldr@v2.0.0', 'text': 'CREENDER, an annotation tool that has been used in school classes to create a multimodal dataset of images and abusive comments, finds that users judge the same images in different ways, although the presence of a person in the picture increases the probability to get an offensive comment.'}",56,2179409,Alessio Palmero Aprosio,2644577,S. Menini,1809243,Sara Tonelli,,,,,,,Computer Science,JournalArticle
57,Using Sentiment Induction to Understand Variation in Gendered Online Communities,"We analyze gendered communities defined in three different ways: text, users, and sentiment. Differences across these representations reveal facets of communities' distinctive identities, such as social group, topic, and attitudes. Two communities may have high text similarity but not user similarity or vice versa, and word usage also does not vary according to a clearcut, binary perspective of gender. Community-specific sentiment lexicons demonstrate that sentiment can be a useful indicator of words' social meaning and community values, especially in the context of discussion content and user demographics. Our results show that social platforms such as Reddit are active settings for different constructions of gender.",ArXiv,2018,46,7,1,False,"{'model': 'tldr@v2.0.0', 'text': ""The results show that social platforms such as Reddit are active settings for different constructions of gender, and sentiment lexicons demonstrate that sentiment can be a useful indicator of words' social meaning and community values, especially in the context of discussion content and user demographics.""}",57,15983089,Li Lucy,32163938,Julia Mendelsohn,,,,,,,,,"Sociology, Computer Science",JournalArticle
58,A Unified Seeding Framework,"Online social networks have become a crucial medium to disseminate the latest political, commercial, and social information. Users with high visibility are often selected as seeds to spread information and affect their adoption in target groups. We study how gender differences and similarities can impact the information spreading process. Using a large-scale Instagram dataset and a small-scale Facebook dataset, we first conduct a multi-faceted analysis taking the interaction type, directionality and frequency into account. To this end, we explore a variety of existing and new single and multihop centrality measures. Our analysis unveils that males and females interact differently depending on the interaction types, e.g., likes or comments, and they feature different support and promotion patterns. We complement prior work showing that females do not reach top visibility (often referred to as the glass ceiling effect) jointly factoring in the connectivity and interaction intensity, both of which were previously mainly discussed independently. Inspired by these observations, we propose a novel seeding framework, called Disparity Seeding, which aims at maximizing spread while reaching a target user group, e.g., a certain percentage of females -- promoting the influence of under-represented groups. Disparity Seeding ranks influential users with two gender-aware measures, the Target HI-index and the Embedding index. Extensive simulations comparing Disparity Seeding with target-agnostic algorithms show that Disparity Seeding meets the target percentage while effectively maximizing the spread. Disparity Seeding can be generalized to counter different types of inequality, e.g., race, and proactively promote minorities in the society.",,2020,0,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A novel seeding framework, called Disparity Seeding, which aims at maximizing spread while reaching a target user group, e.g., a certain percentage of females -- promoting the influence of under-represented groups is proposed.'}",58,31062368,Yansong Teng,2115401036,Hsi-Wen Chen,1731140,De-Nian Yang,1684515,Y. Pignolet,2118549044,Ting-Wei Li,14672072,L. Chen,Computer Science,
59,"A Framework for Generating Annotated Social Media Corpora with Demographics, Stance, Civility, and Topicality","In this paper we introduce a framework for annotating a social media text corpora for various categories. Since, social media data is generated via individuals, it is important to annotate the text for the individuals demographic attributes to enable a socio-technical analysis of the corpora. Furthermore, when analyzing a large data-set we can often annotate a small sample of data and then train a prediction model using this sample to annotate the full data for the relevant categories. We use a case study of a Facebook comment corpora on student loan discussion which was annotated for gender, military affiliation, age-group, political leaning, race, stance, topicalilty, neoliberlistic views and civility of the comment. We release three datasets of Facebook comments for further research at: https://github.com/socialmediaie/StudentDebtFbComments",SSRN Electronic Journal,2020,12,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper introduces a framework for annotating a social media text corpora for various categories and uses a case study of a Facebook comment corpora on student loan discussion which was annotated for gender, military affiliation, age-group, political leaning, race, stance, topicalilty, neoliberlistic views and civility of the comment.'}",59,2777543,Shubhanshu Mishra,121624530,Daniel A. Collier,,,,,,,,,"Psychology, Computer Science",JournalArticle
60,A Weakly Supervised Approach for Classifying Stance in Twitter Replies,"Conversations on social media (SM) are increasingly being used to investigate social issues on the web, such as online harassment and rumor spread. For such issues, a common thread of research uses adversarial reactions, e.g., replies pointing out factual inaccuracies in rumors. Though adversarial reactions are prevalent in online conversations, inferring those adverse views (or stance) from the text in replies is difficult and requires complex natural language processing (NLP) models. Moreover, conventional NLP models for stance mining need labeled data for supervised learning. Getting labeled conversations can itself be challenging as conversations can be on any topic, and topics change over time. These challenges make learning the stance a difficult NLP problem. In this research, we first create a new stance dataset comprised of three different topics by labeling both users’ opinions on the topics (as in pro/con) and users’ stance while replying to others’ posts (as in favor/oppose). As we find limitations with supervised approaches, we propose a weakly-supervised approach to predict the stance in Twitter replies. Our novel method allows using a smaller number of hashtags to generate weak labels for Twitter replies. Compared to supervised learning, our method improves the mean F1-macro by 8% on the hand-labeled dataset without using any hand-labeled examples in the training set. We further show the applicability of our proposed method on COVID 19 related conversations on Twitter.",ArXiv,2021,35,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This research proposes a weakly-supervised approach to predict the stance in Twitter replies using a smaller number of hashtags to generate weak labels for Twitter replies, and improves the mean F1-macro by 8% on the hand-labeled dataset without using any hand- labeled examples in the training set.'}",60,49596134,Sumeet Kumar,1415520972,R. Villa-Cox,47375751,M. Babcock,1702030,Kathleen M. Carley,,,,,Computer Science,JournalArticle
61,Gender Politics in the 2016 U.S. Presidential Election: A Computer Vision Approach,,"International Conference on Social, Cultural, and Behavioral Modeling",2016,31,10,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper introduces computer vision to the study of gender politics and presents an image-driven method that can measure the effects of gender in an accurate and timely manner.'}",61,2153604061,Yu Wang,2115387758,Yang Feng,33642939,Jiebo Luo,,,,,,,"Computer Science, Sociology",JournalArticle
62,Using social media to measure demographic responses to natural disaster: Insights from a large-scale Facebook survey following the 2019 Australia Bushfires,"In this paper we explore a novel method for collecting survey data following a natural disaster and then combine this data with device-derived mobility information to explore demographic outcomes. Using social media as a survey platform for measuring demographic outcomes, especially those that are challenging or expensive to field for, is increasingly of interest to the demographic community. Recent work by Schneider and Harknett (2019) explores the use of Facebook targeted advertisements to collect data on low-income shift workers in the United States. Other work has addressed immigrant assimilation (Stewart et al, 2019), world fertility (Ribeiro et al, 2020), and world migration stocks (Zagheni et al, 2017). We build on this work by introducing a rapid-response survey of post-disaster demographic and economic outcomes fielded through the Facebook app itself. We use these survey responses to augment app-derived mobility data that comprises Facebook Displacement Maps to assess the validity of and drivers underlying those observed behavioral trends. This survey was deployed following the 2019 Australia bushfires to better understand how these events displaced residents. In doing so we are able to test a number of key hypotheses around displacement and demographics. In particular, we uncover several gender differences in key areas, including in displacement decision-making and timing, and in access to protective equipment such as smoke masks. We conclude with a brief discussion of research and policy implications.",ArXiv,2020,20,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A novel method for collecting survey data following a natural disaster is explored and several gender differences in key areas are uncovered, including in displacement decision-making and timing, and in access to protective equipment such as smoke masks, are uncovered.'}",62,50263206,P. Maas,2485727,Zack W. Almquist,3440020,Eugenia Giraudy,35106864,J. Schneider,,,,,"Geography, Computer Science","JournalArticle, Review"
63,Characterizing Twitter Users Who Engage in Adversarial Interactions against Political Candidates,"Social media provides a critical communication platform for political figures, but also makes them easy targets for harassment. In this paper, we characterize users who adversarially interact with political figures on Twitter using mixed-method techniques. The analysis is based on a dataset of 400 thousand users' 1.2 million replies to 756 candidates for the U.S. House of Representatives in the two months leading up to the 2018 midterm elections. We show that among moderately active users, adversarial activity is associated with decreased centrality in the social graph and increased attention to candidates from the opposing party. When compared to users who are similarly active, highly adversarial users tend to engage in fewer supportive interactions with their own party's candidates and express negativity in their user profiles. Our results can inform the design of platform moderation mechanisms to support political figures countering online harassment.",International Conference on Human Factors in Computing Systems,2020,99,27,2,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper characterize users who adversarially interact with political figures on Twitter using mixed-method techniques and shows that among moderately active users, adversarial activity is associated with decreased centrality in the social graph and increased attention to candidates from the opposing party.'}",63,2162375,Yiqing Hua,1687465,Mor Naaman,1707461,T. Ristenpart,,,,,,,"Computer Science, Psychology","Book, JournalArticle, Conference"
64,Discovering Users Topic of Interest from Tweet,"Nowadays social media has become one of the largest gatherings of people in online. There are many ways for the industries to promote their products to the public through advertising. The variety of advertisement is increasing dramatically. Businessmen are so much dependent on the advertisement that significantly it really brought out success in the market and hence practiced by major industries. Thus, companies are trying hard to draw the attention of customers on social networks through online advertisement. One of the most popular social media is Twitter which is popular for short text sharing named Tweet. People here create their profile with basic information. To ensure the advertisements are shown to relative people, Twitter targets people based on language, gender, interest, follower, device, behavior, tailored audiences, keyword, and geography targeting. Twitter generates interest sets based on their activities on Twitter. What our framework does is that it determines the topic of interest from a given list of Tweets if it has any. This process is called Entity Intersect Categorizing Value (EICV). Each category topic generates a set of words or phrases related to that topic. An entity set is created from processing tweets by keyword generation and Twitters data using Twitter API. Value of entities is matched with the set of categories. If they cross a threshold value, it results in the category which matched the desired interest category. For smaller amounts of data sizes, the results show that our framework performs with higher accuracy rate.",International Journal of Computer Science & Information Technology (IJCSIT),2018,14,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This framework determines the topic of interest from a given list of Tweets if it has any and creates an entity set from processing tweets by keyword generation and Twitters data using Twitter API, called EICV.'}",64,9148379,M. Hossen,40901215,Md. Ali Faiad,40893469,Md. Shahnur Azad Chowdhury,39839552,Md. Sajjatul Islam,,,,,Computer Science,JournalArticle
65,Professional Gender Gaps Across US Cities,"
 
 Gender imbalances in work environments have been a long-standing concern. Identifying the existence of such imbalances is key to designing policies to help overcome them. In this work, we study gender trends in employment across various dimensions in the United States. This is done by analyzing anonymous, aggregate statistics that were extracted from LinkedIn's advertising platform. The data contain the number of male and female LinkedIn users with respect to (i) location, (ii) age, (iii) industry and (iv) certain skills. We studied which of these categories correlate the most with high relative male or female presence on LinkedIn. In addition to examining the summary statistics of the LinkedIn data, we model the gender balance as a function of the different employee features using linear regression. Our results suggest that the gender gap, as measured using LinkedIn data, varies across all feature types, but the differences are most profound among industries and skills. A high correlation between gender ratios of people in our LinkedIn data set, and data provided by the US Bureau of Labor Statistics, serves as external validation for our results.
 
",International Conference on Web and Social Media,2018,18,16,1,True,"{'model': 'tldr@v2.0.0', 'text': 'The results suggest that the gender gap varies across all feature types, but the differences are most profound among industries and skills.'}",65,35597551,Karri Haranko,2140221,E. Zagheni,1699369,Venkata Rama Kiran Garimella,1684687,Ingmar Weber,,,,,"Computer Science, Psychology, Geography",JournalArticle
66,Proactively Reducing the Hate Intensity of Online Posts via Hate Speech Normalization,"Curbing online hate speech has become the need of the hour; however, a blanket ban on such activities is infeasible for several geopolitical and cultural reasons. To reduce the severity of the problem, in this paper, we introduce a novel task, hate speech normalization, that aims to weaken the intensity of hatred exhibited by an online post. The intention of hate speech normalization is not to support hate but instead to provide the users with a stepping stone towards non-hate while giving online platforms more time to monitor any improvement in the user's behavior. To this end, we manually curated a parallel corpus - hate texts and their normalized counterparts (a normalized text is less hateful and more benign). We introduce NACL, a simple yet efficient hate speech normalization model that operates in three stages - first, it measures the hate intensity of the original sample; second, it identifies the hate span(s) within it; and finally, it reduces hate intensity by paraphrasing the hate spans. We perform extensive experiments to measure the efficacy of NACL via three-way evaluation (intrinsic, extrinsic, and human-study). We observe that NACL outperforms six baselines - NACL yields a score of 0.1365 RMSE for the intensity prediction, 0.622 F1-score in the span identification, and 82.27 BLEU and 80.05 perplexity for the normalized text generation. We further show the generalizability of NACL across other platforms (Reddit, Facebook, Gab). An interactive prototype of NACL was put together for the user study. Further, the tool is being deployed in a real-world setting at Wipro AI as a part of its mission to tackle harmful content on online platforms.",Knowledge Discovery and Data Mining,2022,50,0,0,True,"{'model': 'tldr@v2.0.0', 'text': 'NACL, a simple yet efficient hate speech normalization model that operates in three stages - first, it measures the hate intensity of the original sample; second, it identifies the hate span(s) within it; and finally, it reduces hate intensity by paraphrasing the hate spans.'}",66,36715403,Sarah Masud,2103384516,Manjot Bedi,2168771748,Mohammad Aflah Khan,46815454,Md. Shad Akhtar,144054829,Tanmoy Chakraborty,,,Computer Science,"JournalArticle, Book, Conference"
67,Gender Asymmetries in Reality and Fiction: The Bechdel Test of Social Media,"
 
 The subjective nature of gender inequality motivates the analysis and comparison of data from real and fictional human interaction. We present a computational extension of the Bechdel test: A popular tool to assess if a movie contains a male gender bias, by looking for two female characters who discuss about something besides a man. We provide the tools to quantify Bechdel scores for both genders, and we measure them in movie scripts and large datasets of dialogues between users of MySpace and Twitter. Comparing movies and users of social media, we find that movies and Twitter conversations have a consistent male bias, which does not appear when analyzing MySpace. Furthermore, the narrative of Twitter is closer to the movies that do not pass the Bechdel test than to those that pass it. We link the properties of movies and the users that share trailers of those movies. Our analysis reveals some particularities of movies that pass the Bechdel test: Their trailers are less popular, female users are more likely to share them than male users, and users that share them tend to interact less with male users. Based on our datasets, we define gender independence measurements to analyze the gender biases of a society, as manifested through digital traces of online behavior. Using the profile information of Twitter users, we find larger gender independence for urban users in comparison to rural ones. Additionally, the asymmetry between genders is larger for parents and lower for students. Gender asymmetry varies across US states, increasing with higher average income and latitude. This points to the relation between gender inequality and social, economical, and cultural factors of a society, and how gender roles exist in both fictional narratives and public online dialogues.
 
",International Conference on Web and Social Media,2014,41,44,3,True,"{'model': 'tldr@v2.0.0', 'text': 'Comparing movies and users of social media, it is found that movies and Twitter conversations have a consistent male bias, which does not appear when analyzing MySpace, and gender independence measurements are defined to analyze the gender biases of a society, as manifested through digital traces of online behavior.'}",67,144240725,David García,1684687,Ingmar Weber,1699369,Venkata Rama Kiran Garimella,,,,,,,"Psychology, Computer Science, Physics",JournalArticle
68,#greysanatomy vs. #yankees: Demographics and Hashtag Use on Twitter,"
 
 Demographics, in particular, gender, age, and race, are a key predictor of human behavior. Despite the significant effect that demographics plays, most scientific studies using online social media do not consider this factor, mainly due to the lack of such information. In this work, we use state-of-the-art face analysis software to infer gender, age, and race from profile images of 350K Twitter users from New York. For the period from November 1, 2014 to October 31, 2015, we study which hashtags are used by different demographic groups. Though we find considerable overlap for the most popular hashtags, there are also many group-specific hashtags.
 
",International Conference on Web and Social Media,2016,25,57,2,True,"{'model': 'tldr@v2.0.0', 'text': 'This work uses state-of-the-art face analysis software to infer gender, age, and race from profile images of 350K Twitter users from New York for the period from November 1, 2014 to October 31, 2015.'}",68,40660541,Jisun An,1684687,Ingmar Weber,,,,,,,,,"Computer Science, Psychology",JournalArticle
69,Quantifying How Hateful Communities Radicalize Online Users,"—While online social media offers a way for ignored or stiﬂed voices to be heard, it also allows users a platform to spread hateful speech. Such speech usually originates in fringe communities, yet it can spill over into mainstream channels. In this paper, we measure the impact of joining fringe hateful communities in terms of hate speech propagated to the rest of the social network. We leverage data from Reddit to assess the effect of joining one type of echo chamber: a digital community of like-minded users exhibiting hateful behavior. We measure members’ usage of hate speech outside the studied community before and after they become active participants. Using Interrupted Time Series (ITS) analysis as a causal inference method, we gauge the spillover effect, in which hateful language from within a certain community can spread outside that community by using the level of out-of-community hate word usage as a proxy for learned hate. We investigate four different Reddit sub-communities (subreddits) covering three areas of hate speech: racism, misogyny and fat-shaming. In all three cases we ﬁnd an increase in hate speech outside the originating community, implying that joining such community leads to a spread of hate speech throughout the platform. Moreover, users are found to pick up this new hateful speech for months after initially joining the community. We show that the harmful speech does not remain contained within the community. Our results provide new evidence of the harmful effects of echo chambers and the potential beneﬁt of moderating them to reduce adoption of hateful speech.",ArXiv,2022,39,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'The spillover effect, in which hateful language from within a certain community can spread outside that community by using the level of out-of-community hate word usage as a proxy for learned hate, is gauged.'}",69,2133452483,Matheus Schmitz,37936069,K. Burghardt,2138610191,Goran Muric,,,,,,,"Computer Science, Mathematics",JournalArticle
70,A large-scale crowdsourced analysis of abuse against women journalists and politicians on Twitter,"We report the first, to the best of our knowledge, hand-in-hand collaboration between human rights activists and machine learners, leveraging crowd-sourcing to study online abuse against women on Twitter. On a technical front, we carefully curate an unbiased yet low-variance dataset of labeled tweets, analyze it to account for the variability of abuse perception, and establish baselines, preparing it for release to community research efforts. On a social impact front, this study provides the technical backbone for a media campaign aimed at raising public and deciders' awareness and elevating the standards expected from social media companies.",ArXiv,2019,19,22,3,False,"{'model': 'tldr@v2.0.0', 'text': 'This study carefully curates an unbiased yet low-variance dataset of labeled tweets, analyzes it to account for the variability of abuse perception, and establishes baselines, preparing it for release to community research efforts.'}",70,69477096,Laure Delisle,1815080,Freddie Kalaitzis,2095464491,Krzysztof Majewski,144496810,A. D. Berker,122996092,M. Marin,3248702,Julien Cornebise,"Computer Science, Mathematics",JournalArticle
71,Predicting Hate Intensity of Twitter Conversation Threads,"Tweets are the most concise form of communication in online social media, wherein a single tweet has the potential to make or break the discourse of the conversation. Online hate speech is more accessible than ever, and stifling its propagation is of utmost importance for social media companies and users for congenial communication. Most of the research barring a recent few has focused on classifying an individual tweet regardless of the tweet thread/context leading up to that point. One of the classical approaches to curb hate speech is to adopt a reactive strategy after the hate speech postage. The ex-post facto strategy results in neglecting subtle posts that do not show the potential to instigate hate speech on their own but may portend in the subsequent discussion ensuing in the post’s replies. In this paper, we propose DRAGNET++, which aims to predict the intensity of hatred that a tweet can bring in through its reply chain in the future. It uses the semantic and propagating structure of the tweet threads to maximize the contextual information leading up to and the fall of hate intensity at each subsequent tweet. We explore three publicly available Twitter datasets – Anti-Racism contains the reply tweets of a collection of social media discourse on racist remarks during US political and Covid-19 background; Anti-Social presents a dataset of 40 million tweets amidst the COVID-19 pandemic on anti-social behaviours with custom annotations; and Anti-Asian presents Twitter datasets collated based on anti-Asian behaviours during COVID-19 pandemic. All the curated datasets consist of structural graph information of the Tweet threads. We show that DRAGNET++ outperforms all the state-of-the-art baselines significantly. It beats the best baseline by an 11% margin on the Person correlation coefficient and a decrease of 25% on RMSE for the Anti-Racism dataset with a similar performance on the other two datasets. social",ArXiv,2022,72,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'DRAGNET++ is proposed, which aims to predict the intensity of hatred that a tweet can bring in through its reply chain in the future, and uses the semantic and propagating structure of the tweet threads to maximize the contextual information leading up to and the fall of hate intensity at each subsequent tweet.'}",71,2106768657,Qing Meng,2151858197,Tharun Suresh,38656724,R. Lee,144054829,Tanmoy Chakraborty,,,,,Computer Science,JournalArticle
72,Fine-grained mining of illicit drug use patterns using social multimedia data from instagram,"According to NSDUH (National Survey on Drug Use and Health), 20 million Americans consumed drugs in the past few 30 days. Combating illicit drug use is of great interest to public health and law enforcement agencies. Despite of the importance, most of the existing studies on drug uses rely on surveys. Surveys on sensitive topics such as drug use may not be answered truthfully by the people taking them. Selecting a representative sample to survey is another major challenge. In this paper, we explore the possibility of using big multimedia data, including both images and text, from social media in order to discover drug use patterns at fine granularity with respect to demographics. Instagram posts are searched and collected by drug related terms by analyzing the hashtags supplied with each post. A large and dynamic dictionary of frequent drug related slangs is used to find these posts. User demographics are extracted using robust face image analysis algorithms. These posts are then mined to find common trends with regard to the time and location they are posted, and further in terms of age and gender of the drug users. Furthermore, by studying the accounts followed by the users of drug related posts, we extract common interests shared by drug users.",2016 IEEE International Conference on Big Data (Big Data),2016,35,12,2,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper explores the possibility of using big multimedia data, including both images and text, from social media in order to discover drug use patterns at fine granularity with respect to demographics, and extracts common interests shared by drug users.'}",72,47943149,Yiheng Zhou,3393393,Numair Sani,33642939,Jiebo Luo,,,,,,,"Business, Computer Science","JournalArticle, Conference, Review"
73,A Computational Approach to Understand Mental Health from Reddit: Knowledge-aware Multitask Learning Framework,"Analyzing gender is critical to study mental health (MH) support in CVD (cardiovascular disease). The existing studies on using social media for extracting MH symptoms consider symptom detection and tend to ignore user context, disease, or gender. The current study aims to design and evaluate a system to capture how MH symptoms associated with CVD are expressed differently with the gender on social media. We observe that the reliable detection of MH symptoms expressed by persons with heart disease in user posts is challenging because of the co-existence of (dis)similar MH symptoms in one post and due to variation in the description of symptoms based on gender. We collect a corpus of 150k items (posts and comments) annotated using the subreddit labels and transfer learning approaches. We propose GeM, a novel task-adaptive multi-task learning approach to identify the MH symptoms in CVD patients based on gender. Specifically, we adopt a knowledge-assisted RoBERTa based bi-encoder model to capture CVD-related MH symptoms. Moreover, it enhances the reliability for differentiating the gender language in MH symptoms when compared to the state-of-art language models. Our model achieves high (statistically significant) performance and predicts four labels of MH issues and two gender labels, which outperforms RoBERTa, improving the recall by 2.14% on the symptom identification task and by 2.55% on the gender identification task.",International Conference on Web and Social Media,2022,58,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'GeM, a novel task-adaptive multi-task learning approach to identify the MH symptoms in CVD patients based on gender is proposed, which adopts a knowledge-assisted RoBERTa based bi-encoder model to capture CVD-related MH symptoms and enhances the reliability for differentiating the gender language in MH symptoms when compared to the state-of-art language models.'}",73,46189109,Usha Lokala,2191418397,Aseem Srivastava,2061341707,T. Dastidar,144054829,Tanmoy Chakraborty,2159553413,Md Shad Akthar,1952327,M. Panahiazar,Computer Science,JournalArticle
74,Countering Online Hate Speech: An NLP Perspective,"Online hate speech has caught everyone's attention from the news related to the COVID-19 pandemic, US elections, and worldwide protests. Online toxicity - an umbrella term for online hateful behavior, manifests itself in forms such as online hate speech. Hate speech is a deliberate attack directed towards an individual or a group motivated by the targeted entity's identity or opinions. The rising mass communication through social media further exacerbates the harmful consequences of online hate speech. While there has been significant research on hate-speech identification using Natural Language Processing (NLP), the work on utilizing NLP for prevention and intervention of online hate speech lacks relatively. This paper presents a holistic conceptual framework on hate-speech NLP countering methods along with a thorough survey on the current progress of NLP for countering online hate speech. It classifies the countering techniques based on their time of action, and identifies potential future research areas on this topic.",ArXiv,2021,76,10,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A holistic conceptual framework on hate-speech NLP countering methods along with a thorough survey on the current progress of NLP for countering online hate speech are presented.'}",74,2046903043,Mudit Chaudhary,39720336,Chandni Saxena,145199941,H. Meng,,,,,,,Computer Science,"JournalArticle, Review"
75,User Profiling Using Hinge-loss Markov Random Fields,"A variety of approaches have been proposed to automatically infer the profiles of users from their digital footprint in social media. Most of the proposed approaches focus on mining a single type of information, while ignoring other sources of available user-generated content (UGC). In this paper, we propose a mechanism to infer a variety of user characteristics, such as, age, gender and personality traits, which can then be compiled into a user profile. To this end, we model social media users by incorporating and reasoning over multiple sources of UGC as well as social relations. Our model is based on a statistical relational learning framework using Hinge-loss Markov Random Fields (HL-MRFs), a class of probabilistic graphical models that can be defined using a set of first-order logical rules. We validate our approach on data from Facebook with more than 5k users and almost 725k relations. We show how HL-MRFs can be used to develop a generic and extensible user profiling framework by leveraging textual, visual, and relational content in the form of status updates, profile pictures and Facebook page likes. Our experimental results demonstrate that our proposed model successfully incorporates multiple sources of information and outperforms competing methods that use only one source of information or an ensemble method across the different sources for modeling of users in social media.",ArXiv,2020,31,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes a mechanism to infer a variety of user characteristics, such as, age, gender and personality traits, which can be compiled into a user profile, which outperforms competing methods that use only one source of information or an ensemble method across the different sources for modeling of users in social media.'}",75,2086602,G. Farnadi,1746034,L. Getoor,100781843,Marie-Francine Moens,4502624,M. D. Cock,,,,,"Computer Science, Mathematics",JournalArticle
76,Understanding the Political Ideology of Legislators from Social Media Images,"In this paper, we seek to understand how politicians use images to express ideological rhetoric through Facebook images posted by members of the U.S. House and Senate. In the era of social media, politics has become saturated with imagery, a potent and emotionally salient form of political rhetoric which has been used by politicians and political organizations to influence public sentiment and voting behavior for well over a century. To date, however, little is known about how images are used as political rhetoric. Using deep learning techniques to automatically predict Republican or Democratic party affiliation solely from the Facebook photographs of the members of the 114th U.S. Congress, we demonstrate that predicted class probabilities from our model function as an accurate proxy of the political ideology of images along a left–right (liberal–conservative) dimension. After controlling for the gender and race of politicians, our method achieves an accuracy of 59.28% from single photographs and 82.35% when aggregating scores from multiple photographs (up to 150) of the same person. To better understand image content distinguishing liberal from conservative images, we also perform in-depth content analyses of the photographs. Our findings suggest that conservatives tend to use more images supporting status quo political institutions and hierarchy maintenance, featuring individuals from dominant social groups, and displaying greater happiness than liberals.",International Conference on Web and Social Media,2019,52,35,3,True,"{'model': 'tldr@v2.0.0', 'text': 'Using deep learning techniques to automatically predict Republican or Democratic party affiliation solely from the Facebook photographs of the members of the 114th U.S. Congress, it is demonstrated that predicted class probabilities from the model function as an accurate proxy of the political ideology of images along a left-right (liberal-conservative) dimension.'}",76,2066152579,Nan Xi,2113508764,Di Ma,1414796571,Marcus Liou,1398679323,Zachary C. Steinert-Threlkeld,39656686,Jason Anastasopoulos,1834047,Jungseock Joo,"Computer Science, Mathematics, Sociology",JournalArticle
77,Inferring Human Traits From Facebook Statuses,,Social Informatics,2018,87,7,1,True,"{'model': 'tldr@v2.0.0', 'text': ""This paper explores the use of language models to predict 20 human traits from users' Facebook status updates, and uses performance and extracted features to analyze models built on social media.""}",77,2073108780,A. Cutler,1692670,B. Kulis,,,,,,,,,"Psychology, Computer Science",JournalArticle
78,Distributional Semantics Approach to Detect Intent in Twitter Conversations on Sexual Assaults,"The recent surge in women reporting sexual assault and harassment (e.g., #metoo campaign) has highlighted a longstanding societal crisis. This injustice is partly due to a culture of discrediting women who report such crimes and also, rape myths (e.g., 'women lie about rape'). Social web can facilitate the further proliferation of deceptive beliefs and culture of rape myths through intentional messaging by malicious actors. This multidisciplinary study investigates Twitter posts related to sexual assaults and rape myths for characterizing the types of malicious intent, which leads to the beliefs on discrediting women and rape myths. Specifically, we first propose a novel malicious intent typology for social media using the guidance of social construction theory from policy literature that includes Accusational, Validational, or Sensational intent categories. We then present and evaluate a malicious intent classification model for a Twitter post using semantic features of the intent senses learned with the help of convolutional neural networks. Lastly, we analyze a Twitter dataset of four months using the intent classification model to study narrative contexts in which malicious intents are expressed and discuss their implications for gender violence policy design.",International Conference on Wirtschaftsinformatik,2018,35,11,1,True,"{'model': 'tldr@v2.0.0', 'text': 'This multidisciplinary study investigates Twitter posts related to sexual assaults andrape myths for characterizing the types of malicious intent, which leads to the beliefs on discrediting women and rape myths.'}",78,1571603655,Rahul Pandey,7147418,Hemant Purohit,3451346,B. Stabile,48171546,Aubrey Grant,,,,,"Computer Science, Psychology","JournalArticle, Conference"
79,"Identifying Diversity, Equity, Inclusion, and Accessibility (DEIA) Indicators for Transportation Systems using Social Media Data: The Case of New York City during Covid-19 Pandemic","The adoption of transportation policies that prioritized highway expansion over public transportation has disproportionately impacted minorities and low-income people by restricting their access to social and economic opportunities and thus resulting in residential segregation. Policymakers, transportation researchers, planners, and practitioners have started acknowledging the need to build a diverse, equitable, inclusive, and accessible (DEIA) transportation system. Traditionally, this has been done through survey-based approaches that are time-consuming and expensive. While there is recent attention on leveraging social media data in transportation, the literature is inconclusive regarding the use of social media data as a viable alternative to traditional sources to identify the latent DEIA indicators based on public reactions and perspectives on social media. This study utilized large-scale Twitter data covering eight counties around the New York City (NYC) area during the initial phase of the Covid-19 lockdown to address this research gap. Natural language processing techniques were used to identify transportation-related major DEIA issues for residents living around NYC by analyzing their relevant tweet conversations. The study revealed that citizens, who had negative sentiments toward the DEIA of their local transportation system, broadly discussed racism, income, unemployment, gender, ride dependency, transportation modes, and dependent groups. Analyzing the socio-demographic information based on census tracts, the study also observed that areas with a higher percentage of low-income, female, Hispanic, and Latino populations share more concerns about transportation DEIA on Twitter.",ArXiv,2022,72,1,0,False,,79,2188985700,Fariha Nazneen Rista,2168246875,Khondhaker Al Momin,10174923,A. M. Sadri,,,,,,,Computer Science,"JournalArticle, Review"
80,2020 U.S. presidential election in swing states: Gender differences in Twitter conversations,,Int. J. Inf. Manag. Data Insights,2021,85,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'There exists a significant difference between female and male users for more than 70% of topics out of the topics, such as tax, climate change, and the COVID-19 pandemic.'}",80,145428860,A. Karami,2150067127,Spring B. Clark,2124123558,Anderson Mackenzie,2124208355,Dorathea Lee,2152183824,Michael Zhu,2122961090,Hannah R. Boyajieff,Computer Science,JournalArticle
81,Understanding the Hoarding Behaviors during the COVID-19 Pandemic using Large Scale Social Media Data,"The COVID-19 pandemic has affected people’s lives around the world on an unprecedented scale. We intend to investigate hoarding behaviors in response to the pandemic using large-scale social media data. First, we collect hoarding-related tweets shortly after the outbreak of the coronavirus. Next, we analyze the hoarding and anti-hoarding patterns of over 42,000 unique Twitter users in the United States from March 1 to April 30, 2020, and dissect the hoarding-related tweets by age, gender, and geographic location. We find the percentage of women in both hoarding and anti-hoarding groups is higher than that of the general Twitter user population. Furthermore, using topic modeling, we investigate the opinions expressed towards the hoarding behavior by categorizing these topics according to demographic and geographic groups. We also calculate the anxiety scores for the hoarding and anti-hoarding related tweets using a lexical approach. By comparing their anxiety scores with the baseline Twitter anxiety score, we reveal further insights. The LIWC anxiety mean for the hoarding-related tweets is significantly higher than the baseline Twitter anxiety mean. Interestingly, beer has the highest calculated anxiety score compared to other hoarded items mentioned in the tweets.",2021 IEEE International Conference on Big Data (Big Data),2020,29,5,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work collects hoarding-related tweets shortly after the outbreak of the coronavirus, analyzes the hoarding and anti-hoarding patterns of over 42,000 unique Twitter users in the United States from March 1 to April 30, 2020, and investigates the opinions expressed towards the hoarded behavior by categorizing these topics according to demographic and geographic groups.'}",81,120069724,Xupin Zhang,1486450921,Hanjia Lyu,33642939,Jiebo Luo,,,,,,,"Computer Science, Psychology","JournalArticle, Conference"
82,Detection of Hate Speech using BERT and Hate Speech Word Embedding with Deep Model,"The enormous amount of data being generated on the web and social media has increased the demand for detecting online hate speech. Detecting hate speech will reduce their negative impact and influence on others. A lot of effort in the Natural Language Processing (NLP) domain aimed to detect hate speech in general or detect specific hate speech such as religion, race, gender, or sexual orientation. Hate communities tend to use abbreviations, intentional spelling mistakes, and coded words in their communication to evade detection, adding more challenges to hate speech detection tasks. Thus, word representation will play an increasingly pivotal role in detecting hate speech. This paper investigates the feasibility of leveraging domain-specific word embedding in Bidirectional LSTM based deep model to automatically detect/classify hate speech. Furthermore, we investigate the use of the transfer learning language model (BERT) on hate speech problem as a binary classification task. The experiments showed that domainspecific word embedding with the Bidirectional LSTM based deep model achieved a 93% f1-score while BERT achieved up to 96% f1-score on a combined balanced dataset from available hate speech datasets.",Applied Artificial Intelligence,2021,43,3,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper investigates the feasibility of leveraging domain-specific word embedding in Bidirectional LSTM based deep model to automatically detect/classify hate speech and investigates the use of the transfer learning language model (BERT) on hate speech problem as a binary classification task.'}",82,2139559735,Hind S. Alatawi,2712846,Areej M. Alhothali,2582903,Kawthar Moria,,,,,,,Computer Science,JournalArticle
83,"Hate Speech in the Political Discourse on Social Media: Disparities Across Parties, Gender, and Ethnicity","Social media has become an indispensable channel for political communication. However, the political discourse is increasingly characterized by hate speech, which affects not only the reputation of individual politicians but also the functioning of society at large. In this work, we empirically analyze how the amount of hate speech in replies to posts from politicians on Twitter depends on personal characteristics, such as their party affiliation, gender, and ethnicity. For this purpose, we employ Twitter’s Historical API to collect every tweet posted by members of the 117th U. S. Congress for an observation period of more than six months. Additionally, we gather replies for each tweet and use machine learning to predict the amount of hate speech they embed. Subsequently, we implement hierarchical regression models to analyze whether politicians with certain characteristics receive more hate speech. We find that tweets are particularly likely to receive hate speech in replies if they are authored by (i) persons of color from the Democratic party, (ii) white Republicans, and (iii) women. Furthermore, our analysis reveals that more negative sentiment (in the source tweet) is associated with more hate speech (in replies). However, the association varies across parties: negative sentiment attracts more hate speech for Democrats (vs. Republicans). Altogether, our empirical findings imply significant differences in how politicians are treated on social media depending on their party affiliation, gender, and ethnicity.",The Web Conference,2022,59,8,0,True,"{'model': 'tldr@v2.0.0', 'text': 'It is found that tweets are particularly likely to receive hate speech in replies if they are authored by persons of color from the Democratic party, white Republicans, and women, and that negative sentiment attracts more hate speech for Democrats (vs. Republicans).'}",83,71138662,K. Solovev,3254663,Nicolas Pröllochs,,,,,,,,,Computer Science,"JournalArticle, Book, Conference"
84,She's Reddit: A source of statistically significant gendered interest information?,,Information Processing & Management,2018,113,21,0,True,"{'model': 'tldr@v2.0.0', 'text': 'Although the method reveals statistically significant gender differences in interests for topics that are extensively discussed on Reddit, it cannot give definitive causes, and imitation and sharing within the site mean that additional checking is needed to verify the results.'}",84,1701298,M. Thelwall,47938267,E. Stuart,,,,,,,,,"Psychology, Computer Science",JournalArticle
85,Debiasing Career Recommendations with Neural Fair Collaborative Filtering,"A growing proportion of human interactions are digitized on social media platforms and subjected to algorithmic decision-making, and it has become increasingly important to ensure fair treatment from these algorithms. In this work, we investigate gender bias in collaborative-filtering recommender systems trained on social media data. We develop neural fair collaborative filtering (NFCF), a practical framework for mitigating gender bias in recommending career-related sensitive items (e.g. jobs, academic concentrations, or courses of study) using a pre-training and fine-tuning approach to neural collaborative filtering, augmented with bias correction techniques. We show the utility of our methods for gender de-biased career and college major recommendations on the MovieLens dataset and a Facebook dataset, respectively, and achieve better performance and fairer behavior than several state-of-the-art models.",The Web Conference,2021,59,26,2,True,"{'model': 'tldr@v2.0.0', 'text': 'Neural fair collaborative filtering (NFCF) is developed, a practical framework for mitigating gender bias in recommending career-related sensitive items using a pre-training and fine-tuning approach to neural collaborative filtering, augmented with bias correction techniques.'}",85,153940606,Rashidul Islam,52028519,Kamrun Keya,1844229,Ziqian Zeng,145620432,Shimei Pan,40289577,James R. Foulds,,,Computer Science,"Book, JournalArticle, Conference"
86,Explore Spatiotemporal and Demographic Characteristics of Human Mobility via Twitter: A Case Study of Chicago,,ArXiv,2015,70,173,10,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper investigates the spatiotemporal characteristics of human mobility with a particular focus on the impact of demography, and finds that, although the human mobility measures of different demographic groups generally follow the generic laws, the demographic information significantly affects the urban human mobility patterns.'}",86,2963267,Feixiong Luo,2388635,G. Cao,2838432,K. Mulligan,2144439585,Xiang Li,,,,,"Computer Science, Geography, Physics",JournalArticle
87,Mitigating Biases in Toxic Language Detection through Invariant Rationalization,"Automatic detection of toxic language plays an essential role in protecting social media users, especially minority groups, from verbal abuse. However, biases toward some attributes, including gender, race, and dialect, exist in most training datasets for toxicity detection. The biases make the learned models unfair and can even exacerbate the marginalization of people. Considering that current debiasing methods for general natural language understanding tasks cannot effectively mitigate the biases in the toxicity detectors, we propose to use invariant rationalization (InvRat), a game-theoretic framework consisting of a rationale generator and a predictor, to rule out the spurious correlation of certain syntactic patterns (e.g., identity mentions, dialect) to toxicity labels. We empirically show that our method yields lower false positive rate in both lexical and dialectal attributes than previous debiasing methods.",WOAH,2021,28,5,0,True,"{'model': 'tldr@v2.0.0', 'text': 'InvRat is proposed, a game-theoretic framework consisting of a rationale generator and a predictor, to rule out the spurious correlation of certain syntactic patterns to toxicity labels and yields lower false positive rate in both lexical and dialectal attributes than previous debiasing methods.'}",87,2475831,Yung-Sung Chuang,2111853746,Mingye Gao,1944274,Hongyin Luo,145898106,James R. Glass,1706104,Hung-yi Lee,2144862809,Yun-Nung Chen,Computer Science,JournalArticle
88,Degree based Classification of Harmful Speech using Twitter Data,"Harmful speech has various forms and it has been plaguing the social media in different ways. If we need to crackdown different degrees of hate speech and abusive behavior amongst it, the classification needs to be based on complex ramifications which needs to be defined and hold accountable for, other than racist, sexist or against some particular group and community. This paper primarily describes how we created an ontological classification of harmful speech based on degree of hateful intent and used it to annotate twitter data accordingly. The key contribution of this paper is the new dataset of tweets we created based on ontological classes and degrees of harmful speech found in the text. We also propose supervised classification system for recognizing these respective harmful speech classes in the texts hence. This serves as a preliminary work to lay down foundation on defining different classes of harmful speech and subsequent work will be done in making it’s automatic detection more robust and efficient.",TRAC@COLING 2018,2018,15,32,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper primarily describes how it created an ontological classification of harmful speech based on degree of hateful intent and used it to annotate twitter data accordingly and proposed supervised classification system for recognizing these respective harmful speech classes in the texts.'}",88,1734248546,Sanjana Sharma,50575184,Saksham Agrawal,2045067,Manish Shrivastava,,,,,,,Computer Science,JournalArticle
89,A Sentiment-Aware Contextual Model for Real-Time Disaster Prediction Using Twitter Data,"The massive amount of data generated by social media present a unique opportunity for disaster analysis. As a leading social platform, Twitter generates over 500 million Tweets each day. Due to its real-time characteristic, more agencies employ Twitter to track disaster events to make a speedy rescue plan. However, it is challenging to build an accurate predictive model to identify disaster Tweets, which may lack sufficient context due to the length limit. In addition, disaster Tweets and regular ones can be hard to distinguish because of word ambiguity. In this paper, we propose a sentiment-aware contextual model named SentiBERT-BiLSTM-CNN for disaster detection using Tweets. The proposed learning pipeline consists of SentiBERT that can generate sentimental contextual embeddings from a Tweet, a Bidirectional long short-term memory (BiLSTM) layer with attention, and a 1D convolutional layer for local feature extraction. We conduct extensive experiments to validate certain design choices of the model and compare our model with its peers. Results show that the proposed SentiBERT-BiLSTM-CNN demonstrates superior performance in the F1 score, making it a competitive model in Tweets-based disaster prediction.",Future Internet,2021,57,6,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A sentiment-aware contextual model named SentiBERT-BiLSTM-CNN for disaster detection using Tweets demonstrates superior performance in the F1 score, making it a competitive model in Tweets-based disaster prediction.'}",89,2110103761,Guizhe Song,2610330,Degen Huang,,,,,,,,,Computer Science,JournalArticle
90,Does terrorism trigger online hate speech? On the association of events and time series,"Hate speech is ubiquitous on the Web. Recently, the offline causes that contribute to online hate speech have received increasing attention. A recurring question is whether the occurrence of extreme events offline systematically triggers bursts of hate speech online, indicated by peaks in the volume of hateful social media posts. Formally, this question translates into measuring the association between a sparse event series and a time series. We propose a novel statistical methodology to measure, test and visualize the systematic association between rare events and peaks in a time series. In contrast to previous methods for causal inference or independence tests on time series, our approach focuses only on the timing of events and peaks, and no other distributional characteristics. We follow the framework of event coincidence analysis (ECA) that was originally developed to correlate point processes. We formulate a discrete-time variant of ECA and derive all required distributions to enable analyses of peaks in time series, with a special focus on serial dependencies and peaks over multiple thresholds. The analysis gives rise to a novel visualization of the association via quantile-trigger rate plots. We demonstrate the utility of our approach by analyzing whether Islamist terrorist attacks in Western Europe and North America systematically trigger bursts of hate speech and counter-hate speech on Twitter.",Annals of Applied Statistics,2020,68,6,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The utility of the proposed novel statistical methodology is demonstrated by analyzing whether Islamist terrorist attacks in Western Europe and North America systematically trigger bursts of hate speech and counter-hate speech on Twitter.'}",90,72144770,Erik Scharwachter,2061778353,E. Muller,,,,,,,,,"Mathematics, Computer Science",
91,The impact of social media presence and board member composition on new venture success: Evidences from VC-backed U.S. startups,,ArXiv,2020,85,16,0,True,"{'model': 'tldr@v2.0.0', 'text': 'It is found that startups with more venture capitalists on the board and whose board members are active on Twitter attract additional funding over the years, though they do not generate additional sales.'}",91,39711148,P. Gloor,2315246,A. F. Colladon,2393636,F. Grippa,,B. M. Hadley,1827543,S. Woerner,,,"Computer Science, Economics, Business",JournalArticle
92,Characterizing (Un)moderated Textual Data in Social Systems,"Despite the valuable social interactions that online media promote, these systems provide space for speech that would be potentially detrimental to different groups of people. The moderation of content imposed by many social media has motivated the emergence of a new social system for free speech named Gab, which lacks moderation of content. This article characterizes and compares moderated textual data from Twitter with a set of unmoderated data from Gab. In particular, we analyze distinguishing characteristics of moderated and unmoderated content in terms of linguistic features, evaluate hate speech and its different forms in both environments. Our work shows that unmoderated content presents different psycholinguistic features, more negative sentiment and higher toxicity. Our findings support that unmoderated environments may have proportionally more online hate speech. We hope our analysis and findings contribute to the debate about hate speech and benefit systems aiming at deploying hate speech detection approaches.",International Conference on Advances in Social Networks Analysis and Mining,2020,27,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work characterizes and compares moderated textual data from Twitter with a set of unmoderated data from Gab, and analyzes distinguishing characteristics of moderated and un moderated content in terms of linguistic features, to evaluate hate speech and its different forms in both environments.'}",92,35053058,Lucas Lima,144278875,Júlio Cesar dos Reis,40594032,P. Melo,1781883,Fabricio Murai,1869561,Fabrício Benevenuto,,,"Computer Science, Psychology","Book, JournalArticle, Conference"
93,Countering hate on social media: Large scale classification of hate and counter speech,"Hateful rhetoric is plaguing online discourse, fostering extreme societal movements and possibly giving rise to real-world violence. A potential solution to this growing global problem is citizen-generated counter speech where citizens actively engage with hate speech to restore civil non-polarized discourse. However, its actual effectiveness in curbing the spread of hatred is unknown and hard to quantify. One major obstacle to researching this question is a lack of large labeled data sets for training automated classifiers to identify counter speech. Here we use a unique situation in Germany where self-labeling groups engaged in organized online hate and counter speech. We use an ensemble learning algorithm which pairs a variety of paragraph embeddings with regularized logistic regression functions to classify both hate and counter speech in a corpus of millions of relevant tweets from these two groups. Our pipeline achieves macro F1 scores on out of sample balanced test sets ranging from 0.76 to 0.97—accuracy in line and even exceeding the state of the art. We then use the classifier to discover hate and counter speech in more than 135,000 fully-resolved Twitter conversations occurring from 2013 to 2018 and study their frequency and interaction. Altogether, our results highlight the potential of automated methods to evaluate the impact of coordinated counter speech in stabilizing conversations on social media.",Workshop on Abusive Language Online,2020,47,31,3,True,"{'model': 'tldr@v2.0.0', 'text': 'An ensemble learning algorithm is used which pairs a variety of paragraph embeddings with regularized logistic regression functions to classify both hate and counter speech in a corpus of millions of relevant tweets from these two groups in Germany.'}",93,49017964,Joshua Garland,35169961,K. Zahedi,2232853,Jean-Gabriel Young,1387936232,Laurent Hébert-Dufresne,2611075,M. Galesic,,,Computer Science,JournalArticle
94,Predicting Gender and Political Affiliation Using Mobile Payment Data,"We explore the understudied area of social payments to evaluate whether or not we can predict the gender and political affiliation of Venmo users based on the content of their Venmo transactions. Latent attribute detection has been successfully applied in the domain of studying social media. However, there remains a dearth of previous work using data other than Twitter. There is also a continued need for studies which explore mobile payments spaces like Venmo, which remain understudied due to the lack of data access. We hypothesize that using methods similar to latent attribute analysis with Twitter data, machine learning algorithms will be able to predict gender and political affiliation of Venmo users with a moderate degree of accuracy. We collected crowdsourced training data that correlates participants' political views with their public Venmo transaction history through the paid Prolific service. Additionally, we collected 21 million public Venmo transactions from recently active users to use for gender classification. We then ran the collected data through a TF-IDF vectorizer and used that to train a support vector machine (SVM). After hyperparameter training and additional feature engineering, we were able to predict user's gender with a high level of accuracy (.91) and had modest success predicting user's political orientation (.63).",ArXiv,2023,33,1,0,False,"{'model': 'tldr@v2.0.0', 'text': ""This work explores the understudied area of social payments to evaluate whether or not it can predict the gender and political affiliation of Venmo users based on the content of their Venmo transactions and is able to predict user's gender with a high level of accuracy and had modest success predicting user's political orientation.""}",94,2206163594,Ben Stobaugh,37460521,D. Murthy,,,,,,,,,Computer Science,JournalArticle
95,Quantifying Algorithmic Biases over Time,"Algorithms now permeate multiple aspects of human lives and multiple recent results have reported that these algorithms may have biases pertaining to gender, race, and other demographic characteristics. The metrics used to quantify such biases have still focused on a static notion of algorithms. However, algorithms evolve over time. For instance, Tay (a conversational bot launched by Microsoft) was arguably not biased at its launch but quickly became biased, sexist, and racist over time. We suggest a set of intuitive metrics to study the variations in biases over time and present the results for a case study for genders represented in images resulting from a Twitter image search for #Nurse and #Doctor over a period of 21 days. Results indicate that biases vary significantly over time and the direction of bias could appear to be different on different days. Hence, one-shot measurements may not suffice for understanding algorithmic bias, thus motivating further work on studying biases in algorithms over time.",ArXiv,2019,10,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A set of intuitive metrics are suggested to study the variations in biases over time and a case study for genders represented in images resulting from a Twitter image search for #Nurse and #Doctor over a period of 21 days indicates that biases vary significantly over time.'}",95,144724775,Vivek K. Singh,2053821307,I. Singh,,,,,,,,,Computer Science,JournalArticle
96,How Diverse Users and Activities Trigger Connective Action via Social Media: Lessons from the Twitter Hashtag Campaign #ILookLikeAnEngineer,"We present a study that examines how a social media activism campaign aimed at improving gender diversity within engineering gained and maintained momentum in its early period. We examined over 50,000 Tweets posted over the first ~75 days of the #ILookLikeAnEngineer campaign and found that diverse participation - of types of users - increased activity at crucial moments. We categorize these triggers into four types: 1) Event-Driven: Alignment of the campaign with offline events related to the issue (Diversity SFO, Disrupt, etc.); 2) Media-Driven: News coverage of the events in the media (TechCrunch, CNN, BBC, etc.); 3) Industry-Driven: Web participation in the campaign by large organizations (Microsoft, Tesla, GE, Cisco, etc.); and 4) Personality-Driven: Alignment of the events with popular and/or known personalities (e.g. Isis Anchalee; Michelle Sun; Ada Lovelace.) This study illustrates how one mechanism - triggering - supports connective action in social media campaign.",Hawaii International Conference on System Sciences,2018,44,21,1,True,"{'model': 'tldr@v2.0.0', 'text': 'A study that examines how a social media activism campaign aimed at improving gender diversity within engineering gained and maintained momentum in its early period found that diverse participation - of types of users - increased activity at crucial moments.'}",96,1710392,A. Johri,30775806,Habib Karbasian,145539521,Aqdas Malik,41015664,Rajat Handa,7147418,Hemant Purohit,,,"Computer Science, Political Science, Sociology",JournalArticle
97,Sexism detection: The first corpus in Algerian dialect with a code-switching in Arabic/ French and English,"In this paper, an approach for hate speech detection against women in Arabic community on social media (e.g. Youtube) is proposed. In the literature, similar works have been presented for other languages such as English. However, to the best of our knowledge, not much work has been conducted in the Arabic language. A new hate speech corpus (Arabic_fr_en) is developed using three different annotators. For corpus validation, three different machine learning algorithms are used, including deep Convolutional Neural Network (CNN), long short-term memory (LSTM) network and Bi-directional LSTM (Bi-LSTM) network. Simulation results demonstrate the best performance of the CNN model, which achieved F1-score up to 86% for the unbalanced corpus as compared to LSTM and Bi-LSTM.",ArXiv,2021,62,4,0,False,"{'model': 'tldr@v2.0.0', 'text': 'An approach for hate speech detection against women in Arabic community on social media (e.g. Youtube) is proposed and the best performance of the CNN model is demonstrated, which achieved F1-score up to 86% for the unbalanced corpus as compared to LSTM and Bi-LSTM.'}",97,51217514,I. Guellil,2064500,Ahsan Adeel,50742466,F. Azouaou,2103425978,Mohamed Boubred,2064606799,Yousra Houichi,2064606826,Akram Abdelhaq Moumna,Computer Science,JournalArticle
98,A BERT-Based Transfer Learning Approach for Hate Speech Detection in Online Social Media,,International Workshop on Complex Networks & Their Applications,2019,27,188,17,True,"{'model': 'tldr@v2.0.0', 'text': 'This study introduces a novel transfer learning approach based on an existing pre-trained language model called BERT (Bidirectional Encoder Representations from Transformers) and investigates the ability of BERT at capturing hateful context within social media content by using new fine-tuning methods based on transfer learning.'}",98,2639305,Marzieh Mozafari,2633697,R. Farahbakhsh,145107973,N. Crespi,,,,,,,Computer Science,JournalArticle
99,Demographics in Social Media Data for Public Health Research: Does it matter?,"Social media data provides propitious opportunities for public health research. However, studies suggest that disparities may exist in the representation of certain populations (e.g., people of lower socioeconomic status). To quantify and address these disparities in population representation, we need demographic information, which is usually missing from most social media platforms. Here, we propose an ensemble approach for inferring demographics from social media data. 
Several methods have been proposed for inferring demographic attributes such as, age, gender and race/ethnicity. However, most of these methods require large volumes of data, which makes their application to large scale studies challenging. We develop a scalable approach that relies only on user names to predict gender. We develop three separate classifiers trained on data containing the gender labels of 7,953 Twitter users from Kaggle.com. Next, we combine predictions from the individual classifiers using a stacked generalization technique and apply the ensemble classifier to a dataset of 36,085 geotagged foodborne illness related tweets from the United States. 
Our ensemble approach achieves an accuracy, precision, recall, and F1 score of 0.828, 0.851, 0.852 and 0.837, respectively, higher than the individual machine learning approaches. The ensemble classifier also covers any user with an alphanumeric name, while the data matching approach, which achieves an accuracy of 0.917, only covers 67% of users. Application of our method to reports of foodborne illness in the United States highlights disparities in tweeting by gender and shows that counties with a high volume of foodborne-illness related tweets are heavily overrepresented by female Twitter users.",ArXiv,2017,56,18,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Application of this proposed ensemble approach for inferring demographics from social media data highlights disparities in tweeting by gender and shows that counties with a high volume of foodborne-illness related tweets are heavily overrepresented by female Twitter users.'}",99,7363052,N. Cesare,4985351,Christan Earl Grant,145799916,J. Hawkins,144252495,J. Brownstein,2332684,E. Nsoesie,,,"Computer Science, Political Science",JournalArticle
100,The Secret Lives of Names?: Name Embeddings from Social Media,"Your name tells a lot about you: your gender, ethnicity and so on. It has been shown that name embeddings are more effective in representing names than traditional substring features. However, our previous name embedding model is trained on private email data and are not publicly accessible. In this paper, we explore learning name embeddings from public Twitter data. We argue that Twitter embeddings have two key advantages: (i) they can and will be publicly released to support research community. (ii) even with a smaller training corpus, Twitter embeddings achieve similar performances on multiple tasks comparing to email embeddings. As a test case to show the power of name embeddings, we investigate the modeling of lifespans. We find it interesting that adding name embeddings can further improve the performances of models using demographic features, which are traditionally used for lifespan modeling. Through residual analysis, we observe that fine-grained groups (potentially reflecting socioeconomic status) are the latent contributing factors encoded in name embeddings. These were previously hidden to demographic models, and may help to enhance the predictive power of a wide class of research studies.",Knowledge Discovery and Data Mining,2019,39,16,1,True,"{'model': 'tldr@v2.0.0', 'text': 'It is argued that Twitter embeddings have two key advantages: (i) they can and will be publicly released to support research community, and (ii) even with a smaller training corpus, Twitterembeddings achieve similar performances on multiple tasks comparing to email embeddins.'}",100,2049963,Junting Ye,1721948,S. Skiena,,,,,,,,,Computer Science,"JournalArticle, Book, Conference"
101,"Kek, Cucks, and God Emperor Trump: A Measurement Study of 4chan's Politically Incorrect Forum and Its Effects on the Web","
 
 The discussion-board site 4chan has been part of the Internet's dark underbelly since its inception, and recent political events have put it increasingly in the spotlight. In particular, /pol/, the “Politically Incorrect'” board, has been a central figure in the outlandish 2016 US election season, as it has often been linked to the alt-right movement and its rhetoric of hate and racism. However, 4chan remains relatively unstudied by the scientific community: little is known about its user base, the content it generates, and how it affects other parts of the Web. In this paper, we start addressing this gap by analyzing /pol/ along several axes, using a dataset of over 8M posts we collected over two and a half months. First, we perform a general characterization, showing that /pol/ users are well distributed around the world and that 4chan's unique features encourage fresh discussions. We also analyze content, finding, for instance, that YouTube links and hate speech are predominant on /pol/. Overall, our analysis not only provides the first measurement study of /pol/, but also insight into online harassment and hate speech trends in social media.
 
",International Conference on Web and Social Media,2016,33,201,13,True,"{'model': 'tldr@v2.0.0', 'text': 'Overall, this analysis provides the first measurement study of /pol/, but also insight into online harassment and hate speech trends in social media.'}",101,2354072,G. Hine,3391180,J. Onaolapo,1728207,Emiliano De Cristofaro,1946641,N. Kourtellis,2909360,I. Leontiadis,7451997,Riginos Samaras,"Computer Science, Physics, Sociology",JournalArticle
102,Monitoring Gender Gaps via LinkedIn Advertising Estimates: the case study of Italy,"Women remain underrepresented in the labour market. Although significant advancements are being made to increase female participation in the workforce, the gender gap is still far from being bridged. We contribute to the growing literature on gender inequalities in the labour market, evaluating the potential of the LinkedIn estimates to monitor the evolution of the gender gaps sustainably, complementing the official data sources. In particular, assessing the labour market patterns at a subnational level in Italy. Our findings show that the LinkedIn estimates accurately capture the gender disparities in Italy regarding sociodemographic attributes such as gender, age, geographic location, seniority, and industry category. At the same time, we assess data biases such as the digitalisation gap, which impacts the representativity of the workforce in an imbalanced manner, confirming that women are under-represented in Southern Italy. Additionally to confirming the gender disparities to the official census, LinkedIn estimates are a valuable tool to provide dynamic insights; we showed an immigration flow of highly skilled women, predominantly from the South. Digital surveillance of gender inequalities with detailed and timely data is particularly significant to enable policymakers to tailor impactful campaigns.",ArXiv,2023,44,0,0,False,,102,2211331758,Margherita Berte,145519038,Kyriaki Kalimeri,2504674,D. Paolotti,,,,,,,Computer Science,JournalArticle
103,A Benchmark Dataset for Learning to Intervene in Online Hate Speech,"Countering online hate speech is a critical yet challenging task, but one which can be aided by the use of Natural Language Processing (NLP) techniques. Previous research has primarily focused on the development of NLP methods to automatically and effectively detect online hate speech while disregarding further action needed to calm and discourage individuals from using hate speech in the future. In addition, most existing hate speech datasets treat each post as an isolated instance, ignoring the conversational context. In this paper, we propose a novel task of generative hate speech intervention, where the goal is to automatically generate responses to intervene during online conversations that contain hate speech. As a part of this work, we introduce two fully-labeled large-scale hate speech intervention datasets collected from Gab and Reddit. These datasets provide conversation segments, hate speech labels, as well as intervention responses written by Mechanical Turk Workers. In this paper, we also analyze the datasets to understand the common intervention strategies and explore the performance of common automatic response generation methods on these new datasets to provide a benchmark for future research.",Conference on Empirical Methods in Natural Language Processing,2019,32,99,14,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper introduces two fully-labeled large-scale hate speech intervention datasets collected from Gab and Reddit and analyzes the datasets to understand the common intervention strategies and explore the performance of common automatic response generation methods.'}",103,144130537,Jing Qian,78850252,Anna Bethke,3097158,Yinyin Liu,1397933253,E. Belding-Royer,1682479,William Yang Wang,,,Computer Science,"JournalArticle, Conference"
104,Gender and Racial Fairness in Depression Research using Social Media,"Multiple studies have demonstrated that behaviors expressed on online social media platforms can indicate the mental health state of an individual. The widespread availability of such data has spurred interest in mental health research, using several datasets where individuals are labeled with mental health conditions. While previous research has raised concerns about possible biases in models produced from this data, no study has investigated how these biases manifest themselves with regards to demographic groups in data, such as gender and racial/ethnic groups. Here, we analyze the fairness of depression classifiers trained on Twitter data with respect to gender and racial demographic groups. We find that model performance differs for underrepresented groups, and we investigate sources of these biases beyond data representation. Our study results in recommendations on how to avoid these biases in future research.",Conference of the European Chapter of the Association for Computational Linguistics,2021,62,14,2,True,"{'model': 'tldr@v2.0.0', 'text': 'This study analyzes the fairness of depression classifiers trained on Twitter data with respect to gender and racial demographic groups to find that model performance differs for underrepresented groups, and investigates sources of these biases beyond data representation.'}",104,119589376,Carlos Alejandro Aguirre,51320356,Keith Harrigian,1478928280,Mark Dredze,,,,,,,Computer Science,"JournalArticle, Conference"
105,A User Modeling Pipeline for Studying Polarized Political Events in Social Media,,ICWE Workshops,2018,23,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A user modeling pipeline to analyze discussions and opinions shared on social media regarding polarized political events, which noticed that in general Twitter was more representative of the users opposing the referendum than the ones in favor.'}",105,31592734,Robert L. Napoli,2532309,A. Ertugrul,1710630,A. Bozzon,2112146631,M. Brambilla,,,,,Computer Science,JournalArticle
106,Understanding Patterns of Users Who Repost Censored Posts on Weibo,"In this study, we focus on understanding patterns of users whose repost contents would later be censored on weibo, a counterpart of Twitter in China as a social media platform. Little is known about the way regulations and censorship work in this indigenous platform and what role it plays in affecting users’ expression of ideas. We collect over a million reposts from over 18,000 users and investigate the patterns of users whose reposts contain content that is no longer visible to the public, from the perspective of user location, device, gender, social capital as well as certified status. We find that user characteristics play an important role in affecting behaviors on Weibo.",ArXiv,2021,5,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is found that user characteristics play an important role in affecting behaviors on Weibo, from the perspective of user location, device, gender, social capital as well as certified status.'}",106,2046976455,Yichi Qian,2056632860,Feng Yuan,1486450921,Hanjia Lyu,33642939,Jiebo Luo,,,,,Computer Science,JournalArticle
107,Online Harassment in Majority Contexts: Examining Harms and Remedies across Countries,"Online harassment is a global problem. This article examines perceptions of harm and preferences for remedies associated with online harassment with nearly 4000 participants in 14 countries around the world. The countries in this work reflect a range of identities and values, with a focus on those outside of North American and European contexts. Results show that perceptions of harm are higher among participants from all countries studied compared to the United States. Non-consensual sharing of sexual photos is consistently rated as harmful in all countries, while insults and rumors are perceived as more harmful in non-U.S. countries, especially harm to family reputation. Lower trust in other people and lower trust in sense of safety in one’s neighborhood correlate with increased perceptions of harm of online harassment. In terms of remedies, participants in most countries prefer monetary compensation, apologies, and publicly revealing offender’s identities compared to the U.S. Social media platform design and policy must consider regional values and norms, which may depart from U.S. centric-approaches.",ArXiv,2023,105,0,0,False,,107,1844852,S. Schoenebeck,48205842,Amna Batool,113239740,Gi-Chul Do,2203244437,Sylvia Darling,34489132,Gabriel Grill,40074624,Daricia Wilkinson,Computer Science,JournalArticle
108,Catching up with trends: The changing landscape of political discussions on twitter in 2014 and 2019,"The advent of 4G increased the usage of internet in India, which took a huge number of discussions online. Online Social Networks (OSNs) are the center of these discussions. During elections, political discussions constitute a significant portion of the trending topics on these networks. Politicians and political parties catch up with these trends, and social media then becomes a part of their publicity agenda. We cannot ignore this trend in any election, be it the U.S, Germany, France, or India. Twitter is a major platform where we observe these trends. In this work, we examine the magnitude of political discussions on twitter by contrasting the platform usage on levels like gender, political party, and geography, in 2014 and 2019 Indian General Elections. In a further attempt to understand the strategies followed by political parties, we compare twitter usage by Bharatiya Janata Party (BJP) and Indian National Congress (INC) in 2019 General Elections in terms of how efficiently they make use of the platform. We specifically analyze the handles of politicians who emerged victorious. We then proceed to compare political handles held by frontmen of BJP and INC: Narendra Modi (@narendramodi) and Rahul Gandhi (@RahulGandhi) using parameters like ""following"", ""tweeting habits"", ""sources used to tweet"", along with text analysis of tweets. With this work, we also introduce a rich dataset covering a majority of tweets made during the election period in 2014 and 2019.",ArXiv,2019,23,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This work examines the magnitude of political discussions on twitter by contrasting the platform usage on levels like gender, political party, and geography, in 2014 and 2019 Indian General Elections, and compares political handles held by frontmen of BJP and INC.'}",108,2736436,Avinash Tulasi,153332778,Kanay Gupta,1387971395,Omkar Gurjar,1387971393,Sathvik Sanjeev Buggana,1387971422,Paras Mehan,3170352,Arun Balaji Buduru,"Geography, Computer Science",JournalArticle
109,Learning multi-faceted representations of individuals from heterogeneous evidence using neural networks,"Inferring latent attributes of people online is an important social computing task, but requires integrating the many heterogeneous sources of information available on the web. We propose learning individual representations of people using neural nets to integrate rich linguistic and network evidence gathered from social media. The algorithm is able to combine diverse cues, such as the text a person writes, their attributes (e.g. gender, employer, education, location) and social relations to other people. We show that by integrating both textual and network evidence, these representations offer improved performance at four important tasks in social media inference on Twitter: predicting (1) gender, (2) occupation, (3) location, and (4) friendships for users. Our approach scales to large datasets and the learned representations can be used as general features in and have the potential to benefit a large number of downstream tasks including link prediction, community detection, or probabilistic reasoning over social networks.",ArXiv,2015,94,33,2,False,"{'model': 'tldr@v2.0.0', 'text': 'This work proposes learning individual representations of people using neural nets to integrate rich linguistic and network evidence gathered from social media to benefit a large number of downstream tasks including link prediction, community detection, or probabilistic reasoning over social networks.'}",109,49298465,Jiwei Li,1863425,Alan Ritter,1746807,Dan Jurafsky,,,,,,,Computer Science,JournalArticle
110,Deciphering the 2016 U.S. Presidential Campaign in the Twitter Sphere: A Comparison of the Trumpists and Clintonists,"
 
 In this paper, we study follower demographics of Donald Trump and Hillary Clinton, the two leading candidates in the 2016 U.S. presidential race. We build a unique dataset US2016, which includes the number of followers for each candidate from September 17, 2015 to December 22, 2015. US2016 also includes the geographical location of these followers, the number of their own followers and, very importantly, the profile image of each follower. We use individuals' number of followers and profile images to analyze four dimensions of follower demographics: social status, gender, race and age. Our study shows that in terms of social influence, the Trumpists are more polarized than the Clintonists: they tend to have either a lot of influence or little influence. We also find that compared with the Clintonists, the Trumpists are more likely to be either very young or very old. Our study finds no gender affinity effect for Clinton in the Twitter sphere, but we do find that the Clintonists are more racially diverse.
 
",International Conference on Web and Social Media,2016,13,69,1,True,"{'model': 'tldr@v2.0.0', 'text': 'The study of follower demographics of Donald Trump and Hillary Clinton, the two leading candidates in the 2016 U.S. presidential race, builds a unique dataset US2016, which includes the number of followers for each candidate from September 17, 2015 to December 22, 2015 and finds that the Clintonists are more racially diverse.'}",110,2153604061,Yu Wang,3092578,Y. Li,33642939,Jiebo Luo,,,,,,,"Computer Science, Sociology",JournalArticle
111,"What's kooking?: characterizing India's emerging social network, Koo","Social media has grown exponentially in a short period, coming to the forefront of communications and online interactions. Despite their rapid growth, social media platforms have been unable to scale to different languages globally and remain inaccessible to many. In this paper, we characterize Koo, a multilingual micro-blogging site that rose in popularity in 2021, as an Indian alternative to Twitter. We collected a dataset of 4.07 million users, 163.12 million follower-following relationships, and their content and activity across 12 languages. We study the user demographic along the lines of language, location, gender, and profession. The prominent presence of Indian languages in the discourse on Koo indicates the platform's success in promoting regional languages. We observe Koo's follower-following network to be much denser than Twitter's, comprising of closely-knit linguistic communities. An N-gram analysis of posts on Koo shows a #KooVsTwitter rhetoric, revealing the debate comparing the two platforms. Our characterization highlights the dynamics of the multilingual social network and its diverse Indian user base.",International Conference on Advances in Social Networks Analysis and Mining,2021,26,1,0,True,"{'model': 'tldr@v2.0.0', 'text': ""This paper characterize Koo, a multilingual micro-blogging site that rose in popularity in 2021, as an Indian alternative to Twitter, and observes Koo's follower-following network to be much denser than Twitter's, comprising of closely-knit linguistic communities.""}",111,1390547809,A. Singh,145196266,Chirag Jain,2047003791,Jivitesh Jain,2087017305,R. Jain,2047006125,Shradha Sehgal,2126538830,Tanisha Pandey,Computer Science,"Book, JournalArticle"
112,"People Lie, Actions Don't! Modeling Infodemic Proliferation Predictors among Social Media Users",,Technology and Society,2021,54,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This study identifies practical factors to be conjunctly utilized in the development of fake news detection algorithms and concludes that sentiment polarity and gender can significantly identify fake news.'}",112,2087907197,Chahat Raj,2080447,P. Meel,,,,,,,,,Computer Science,JournalArticle
113,Characterizing Fan Behavior to Study Para Social Breakups,"Celebrity and fandom have been studied extensively in real life. However, with more and more celebrities using social media, the dynamics of interaction between celebrities and fans has changed. Using data from a set of 57,000 fans for the top followed celebrities on Twitter, we define a wide range of features based on their Twitter activity. Using factor analysis we find the most important factors that underlie fan behavior. Using these factors, we conduct analysis on (i) understanding fan behavior by gender \& age, and (ii) para-social breakup behavior. We find that (i) fandom is a social phenomenon, (ii) female fans are often more devoted and younger fans are more active & social, and (iii) the most devoted fans are more likely to be involved in a para-social breakup. Our findings confirm existing research on para-social interactions. Given the scale of our study and dependence on non-reactive data, our paper opens new avenues for research in para-social interactions.",ArXiv,2017,15,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is found that fandom is a social phenomenon, female fans are often more devoted and younger fans are more active & social, and the most devotedFans are more likely to be involved in a para-social breakup.'}",113,1699369,Venkata Rama Kiran Garimella,50065291,Jonathan Cohen,1684687,Ingmar Weber,,,,,,,Computer Science,JournalArticle
114,Rihanna versus Bollywood: Twitter Influencers and the Indian Farmers' Protest,"A tweet from popular entertainer and businesswoman, Rihanna, bringing attention to farmers’ protests around Delhi set off heightened activity on Indian social media. An immediate consequence was the weighing in by Indian politicians, entertainers, media and other influencers on the issue. In this paper, we use data from Twitter and an archive of debunked misinformation stories to understand some of the patterns around influencer engagement with a political issue. We found that more followed influencers were less likely to come out in support of the tweet. We also find that the later engagement of major influencers on the side of the government’s position shows suggestion’s of collusion. Irrespective of their position on the issue, influencers who engaged saw a significant rise in their following after their tweets. While a number of tweets thanked Rihanna for raising awareness on the issue, she was systematically trolled on the grounds of her gender, race, nationality and religion. Finally, we observed how misinformation existing prior to the tweet set up the grounds for alternative narratives that emerged.",ArXiv,2021,3,4,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is found that more followed influencers were less likely to come out in support of the tweet and the later engagement of major influencers on the side of the government’s position shows suggestion of collusion.'}",114,41072903,Dibyendu Mishra,1752287104,Syeda Zainab Akbar,2047999838,Arshia Arya,151203958,Saloni Dash,2047998583,Rynaa Grover,2111720,J. Pal,Computer Science,JournalArticle
115,"""Facebook Promotes More Harassment"": Social Media Ecosystem, Skill and Marginalized Hijra Identity in Bangladesh",,Proc. ACM Hum. Comput. Interact.,2021,0,13,2,False,,115,51922395,Fayika Farhat Nova,32861190,M. A. DeVito,51004414,Pratyasha Saha,1996862702,Kazi Shohanur Rashid,2003548322,Shashwata Roy Turzo,2159124819,Sadia Afrin,Computer Science,JournalArticle
116,Demographic Confounding Causes Extreme Instances of Lifestyle Politics on Facebook,"Lifestyle politics emerge when activities that have no substantive relevance to ideology become politically aligned and polarized. Homophily and social influence are able generate these fault lines on their own; however, social identities from demographics may serve as coordinating mechanisms through which lifestyle politics are mobilized are spread. Using a dataset of 137,661,886 observations from 299,327 Facebook interests aggregated across users of different racial/ethnic, education, age, gender, and income demographics, we find that the most extreme instances of lifestyle politics are those which are highly confounded by demographics such as race/ethnicity (e.g., Black artists and performers). After adjusting political alignment for demographic effects, lifestyle politics decreased by 27.36% toward the political “center” and demographically confounded interests were no longer among the most polarized interests. Instead, after demographic deconfounding, we found that the most liberal interests included electric cars, Planned Parenthood, and liberal satire while the most conservative interests included the Republican Party and conservative commentators. We validate our measures of political alignment and lifestyle politics using the General Social Survey and find similar demographic entanglements with lifestyle politics existed before social media such as Facebook were ubiquitous, giving us strong confidence that our results are not due to echo chambers or filter bubbles. Likewise, since demographic characteristics exist prior to ideological values, we argue that the demographic confounding we observe is causally responsible for the extreme instances of lifestyle politics that we find among the aggregated interests. We conclude our paper by relating our results to Simpson’s paradox, cultural omnivorousness, and network autocorrelation.",ArXiv,2022,37,0,0,False,"{'model': 'tldr@v2.0.0', 'text': ""It is argued that the demographic confounding the authors observe is causally responsible for the extreme instances of lifestyle politics that are found among the aggregated interests and related to Simpson's paradox, cultural omnivorousness, and network autocorrelation.""}",116,117423453,A. Ruch,2145064785,Yujia Zhang,3367849,Michael Macy,,,,,,,"Computer Science, Physics","JournalArticle, Review"
117,Hate speech detection and racial bias mitigation in social media based on BERT model,"Disparate biases associated with datasets and trained classifiers in hateful and abusive content identification tasks have raised many concerns recently. Although the problem of biased datasets on abusive language detection has been addressed more frequently, biases arising from trained classifiers have not yet been a matter of concern. In this paper, we first introduce a transfer learning approach for hate speech detection based on an existing pre-trained language model called BERT (Bidirectional Encoder Representations from Transformers) and evaluate the proposed model on two publicly available datasets that have been annotated for racism, sexism, hate or offensive content on Twitter. Next, we introduce a bias alleviation mechanism to mitigate the effect of bias in training set during the fine-tuning of our pre-trained BERT-based model for hate speech detection. Toward that end, we use an existing regularization method to reweight input samples, thereby decreasing the effects of high correlated training set’ s n-grams with class labels, and then fine-tune our pre-trained BERT-based model with the new re-weighted samples. To evaluate our bias alleviation mechanism, we employed a cross-domain approach in which we use the trained classifiers on the aforementioned datasets to predict the labels of two new datasets from Twitter, AAE-aligned and White-aligned groups, which indicate tweets written in African-American English (AAE) and Standard American English (SAE), respectively. The results show the existence of systematic racial bias in trained classifiers, as they tend to assign tweets written in AAE from AAE-aligned group to negative classes such as racism, sexism, hate, and offensive more often than tweets written in SAE from White-aligned group. However, the racial bias in our classifiers reduces significantly after our bias alleviation mechanism is incorporated. This work could institute the first step towards debiasing hate speech and abusive language detection systems.",PLoS ONE,2020,50,76,9,True,"{'model': 'tldr@v2.0.0', 'text': 'A transfer learning approach for hate speech detection based on an existing pre-trained language model called BERT (Bidirectional Encoder Representations from Transformers) and a bias alleviation mechanism to mitigate the effect of bias in training set during the fine-tuning of the proposed model.'}",117,2639305,Marzieh Mozafari,2633697,R. Farahbakhsh,145107973,N. Crespi,,,,,,,"Computer Science, Medicine",JournalArticle
118,Gender-based violence in 140 characters or fewer: a #BigData case study of Twitter,"Public institutions are increasingly reliant on data from social media sites to measure public attitude and provide timely public engagement. Such reliance includes the exploration of public views on important social issues such as gender-based violence (GBV). In this study, we examine big (social) data consisting of nearly 14 million tweets collected from Twitter over a period of 10 months to analyze public opinion regarding GBV, highlighting the nature of tweeting practices by geographical location and gender. We demonstrate the utility of computational social science to mine insight from the corpus while accounting for the influence of both transient events and sociocultural factors. We reveal public awareness regarding GBV tolerance and suggest opportunities for intervention and the measurement of intervention effectiveness assisting both governmental and non-governmental organizations in policy development.",PeerJ Preprints,2015,104,30,1,True,"{'model': 'tldr@v2.0.0', 'text': 'Big (social) data consisting of nearly fourteen million tweets collected from Twitter over a period of ten months is examined to analyze public opinion regarding GBV, highlighting the nature of tweeting practices by geographical location and gender.'}",118,7147418,Hemant Purohit,1811614,Tanvi Banerjee,31941584,Andrew J. Hampton,2890773,V. Shalin,2027349,Nayanesh Bhandutia,144463965,A. Sheth,"Computer Science, Psychology, Sociology",JournalArticle
119,Tactical Reframing of Online Disinformation Campaigns Against The Istanbul Convention,"In March 2021, Turkey withdrew from The Istanbul Convention, a human-rights treaty that addresses violence against women, citing issues with the convention’s implicit recognition of sexual and gender minorities. In this work, we trace disinformation campaigns related to the Istanbul Convention and its associated Turkish law that circulate on divorced men’s rights Facebook groups. We find that these groups adjusted the narrative and focus of the campaigns to appeal to a larger audience, which we refer to as “tactical reframing.” Initially, the men organized in a grass-roots manner to campaign against the Turkish law that was passed to codify the convention, focusing on one-sided custody of children and indefinite alimony. Later, they reframed their campaign and began attacking the Istanbul Convention, highlighting its acknowledgment of homosexuality. This case study highlights how disinformation campaigns can be used to weaponize homophobia in order to limit the rights of women. To the best of our knowledge, this is the first case study that analyzes a narrative reframing in the context of a disinformation campaign",ICWSM Workshops,2021,20,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This case study highlights how disinformation campaigns can be used to weaponize homophobia in order to limit the rights of women.'}",119,107918952,Tugrulcan Elmas,1857191,R. Overdorf,1751802,K. Aberer,,,,,,,Computer Science,JournalArticle
120,Fairness-Aware Ranking in Search & Recommendation Systems with Application to LinkedIn Talent Search,"We present a framework for quantifying and mitigating algorithmic bias in mechanisms designed for ranking individuals, typically used as part of web-scale search and recommendation systems. We first propose complementary measures to quantify bias with respect to protected attributes such as gender and age. We then present algorithms for computing fairness-aware re-ranking of results. For a given search or recommendation task, our algorithms seek to achieve a desired distribution of top ranked results with respect to one or more protected attributes. We show that such a framework can be tailored to achieve fairness criteria such as equality of opportunity and demographic parity depending on the choice of the desired distribution. We evaluate the proposed algorithms via extensive simulations over different parameter choices, and study the effect of fairness-aware ranking on both bias and utility measures. We finally present the online A/B testing results from applying our framework towards representative ranking in LinkedIn Talent Search, and discuss the lessons learned in practice. Our approach resulted in tremendous improvement in the fairness metrics (nearly three fold increase in the number of search queries with representative results) without affecting the business metrics, which paved the way for deployment to 100% of LinkedIn Recruiter users worldwide. Ours is the first large-scale deployed framework for ensuring fairness in the hiring domain, with the potential positive impact for more than 630M LinkedIn members.",Knowledge Discovery and Data Mining,2019,44,226,30,True,"{'model': 'tldr@v2.0.0', 'text': 'This work presents a framework for quantifying and mitigating algorithmic bias in mechanisms designed for ranking individuals, typically used as part of web-scale search and recommendation systems, and is the first large-scale deployed framework for ensuring fairness in the hiring domain.'}",120,6748971,S. C. Geyik,9936591,Stuart Ambler,1769861,K. Kenthapadi,,,,,,,Computer Science,"JournalArticle, Book, Conference"
121,Finding Social Media Trolls: Dynamic Keyword Selection Methods for Rapidly-Evolving Online Debates,"Online harassment is a significant social problem. Prevention of online harassment requires rapid detection of harassing, offensive, and negative social media posts. In this paper, we propose the use of word embedding models to identify offensive and harassing social media messages in two aspects: detecting fast-changing topics for more effective data collection and representing word semantics in different domains. We demonstrate with preliminary results that using the GloVe (Global Vectors for Word Representation) model facilitates the discovery of new and relevant keywords to use for data collection and trolling detection. Our paper concludes with a discussion of a research agenda to further develop and test word embedding models for identification of social media harassment and trolling.",ArXiv,2019,14,7,1,False,"{'model': 'tldr@v2.0.0', 'text': 'Preliminary results are demonstrated that using the GloVe (Global Vectors for Word Representation) model facilitates the discovery of new and relevant keywords to use for data collection and trolling detection.'}",121,38696911,Anqi Liu,1731218,Maya Srikanth,1404062616,N. Adams-Cohen,152419600,R. Alvarez,2047844,Anima Anandkumar,,,"Computer Science, Mathematics",JournalArticle
122,Twitter-Based Gender Recognition Using Transformers,"—Social media contains useful information about people and the society that could help advance research in many different areas (e.g. by applying opinion mining, emotion/sentiment analysis, and statistical analysis) such as business and finance, health, socio-economic inequality and gender vulnerability. User demographics provide rich information that could help study the subject further. However, user demographics such as gender are considered private and are not freely available. In this study, we propose a model based on transformers to predict the user's gender from their images and tweets. We fine-tune a model based on Vision Transformers (ViT) to stratify female and male images. Next, we fine-tune another model based on Bidirectional Encoders Representations from Transformers (BERT) to recognize the user’s gender by their tweets. This is highly beneficial, because not all users provide an image that indicates their gender. The gender of such users could be detected from their tweets. The combination model improves the accuracy of image and text classification models by 6.98% and 4.43%, respectively. This shows that the image and text classification models are capable of complementing each other by providing additional information to one another. We apply our method to the PAN-2018 dataset, and obtain an accuracy of 85.52%.",ArXiv,2022,39,0,0,False,"{'model': 'tldr@v2.0.0', 'text': ""A model based on transformers to predict the user's gender from their images and tweets is proposed and applied to the PAN-2018 dataset, improving the accuracy of image and text classification models by 6.98% and 4.43%, respectively.""}",122,2088814573,Z. Nia,49505498,A. Ahmadi,2142894843,Bruce Mellado,2155449970,Jianhong Wu,48747110,J. Orbinski,50121547,A. Asgary,Computer Science,JournalArticle
123,Impact of Facebook Usage on Undergraduate Students Performance in Irbid National University: Case Study,"The aim of this study is to investigate the style of Facebook usage between undergraduate students and the impact on their academics performance. Also, this paper was evaluated in the view of student the using of Facebook. A questioner was design for collecting data from a sample of 480 undergraduate students in Irbid National University. The survey revealed that 77% of the students have an account on Facebook. One of the main findings is that there was a significant relationship between gender and Facebook usage. Moreover, the survey revealed that whenever the less time spent on Facebook, the higher the performance will be in grade point average. This was conducted by the negative correlation between time spent on Facebook and the performance of undergraduate student. Statistically speaking, the study has seven hypotheses; two of them were rejecting against five acceptable hypotheses.",ArXiv,2013,12,3,0,False,"{'model': 'tldr@v2.0.0', 'text': 'One of the main findings is that there was a significant relationship between gender and Facebook usage and the less time spent on Facebook, the higher the performance will be in grade point average.'}",123,3185115,F. Altaany,1968061,F. Jassim,,,,,,,,,"Psychology, Computer Science","JournalArticle, Review"
124,Facebook Shadow Profiles,"We quantify Facebook’s ability to build shadow proﬁles by tracking individuals across the web, irrespective of whether they are users of the social network. For a representative sample of US Internet users, we ﬁnd that Facebook is able to track about 40% of the browsing time of both users and non-users of Facebook, including on privacy-sensitive domains and across user demographics. We show that the collected browsing data can produce accurate predictions of personal information that is valuable for advertisers, such as age or gender. Because Facebook users reveal their demographic information to the platform, and because the browsing behavior of users and non-users of Facebook overlaps, users impose a data externality on non-users by allowing Facebook to infer their personal information.",SSRN Electronic Journal,2022,21,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'It is quantified that Facebook is able to track about 40% of the browsing time of both users and non-users of Facebook, including on privacy-sensitive domains and across user demographics, and shows that the collected browsing data can produce accurate predictions of personal information that is valuable for advertisers.'}",124,143855393,Luis Aguiar,23574157,Christian Peukert,2153849943,Maximilian Schafer,3428698,H. Ullrich,,,,,Economics,
125,"TBCOV: Two Billion Multilingual COVID-19 Tweets with Sentiment, Entity, Geo, and Gender Labels","As the world struggles with several compounded challenges caused by the COVID-19 pandemic in the health, economic, and social domains, timely access to disaggregated national and sub-national data are important to understand the emergent situation but it is difficult to obtain. The widespread usage of social networking sites, especially during mass convergence events, such as health emergencies, provides instant access to citizen-generated data offering rich information about public opinions, sentiments, and situational updates useful for authorities to gain insights. We offer a large-scale social sensing dataset comprising two billion multilingual tweets posted from 218 countries by 87 million users in 67 languages. We used state-of-the-art machine learning models to enrich the data with sentiment labels and named-entities. Additionally, a gender identification approach is proposed to segregate user gender. Furthermore, a geolocalization approach is devised to geotag tweets at country, state, county, and city granularities, enabling a myriad of data analysis tasks to understand real-world issues at national and sub-national levels. We believe this multilingual data with broader geographical and longer temporal coverage will be a cornerstone for researchers to study impacts of the ongoing global health catastrophe and to manage adverse consequences related to people’s health, livelihood, and social well-being.",International Conference on Data Technologies and Applications,2021,91,17,2,True,"{'model': 'tldr@v2.0.0', 'text': 'A large-scale social sensing dataset comprising two billion multilingual tweets posted from 218 countries by 87 million users in 67 languages is offered, believing this multilingual data with broader geographical and longer temporal coverage will be a cornerstone for researchers to study impacts of the ongoing global health catastrophe and to manage adverse consequences related to people’s health, livelihood, and social well-being.'}",125,151491159,Muhammad Imran,48166270,U. Qazi,48046557,Ferda Ofli,,,,,,,Computer Science,JournalArticle
126,Female librarians and male computer programmers? Gender bias in occupational images on digital media platforms,"Media platforms, technological systems, and search engines act as conduits and gatekeepers for all kinds of information. They often influence, reflect, and reinforce gender stereotypes, including those that represent occupations. This study examines the prevalence of gender stereotypes on digital media platforms and considers how human efforts to create and curate messages directly may impact these stereotypes. While gender stereotyping in social media and algorithms has received some examination in the recent literature, its prevalence in different types of platforms (for example, wiki vs. news vs. social network) and under differing conditions (for example, degrees of human‐ and machine‐led content creation and curation) has yet to be studied. This research explores the extent to which stereotypes of certain strongly gendered professions (librarian, nurse, computer programmer, civil engineer) persist and may vary across digital platforms (Twitter, the New York Times online, Wikipedia, and Shutterstock). The results suggest that gender stereotypes are most likely to be challenged when human beings act directly to create and curate content in digital platforms, and that highly algorithmic approaches for curation showed little inclination towards breaking stereotypes. Implications for the more inclusive design and use of digital media platforms, particularly with regard to mediated occupational messaging, are discussed.",J. Assoc. Inf. Sci. Technol.,2019,84,34,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The results suggest that gender stereotypes are most likely to be challenged when human beings act directly to create and curate content in digital platforms, and that highly algorithmic approaches for curation showed little inclination towards breaking stereotypes.'}",126,144724775,Vivek K. Singh,3247454,M. Chayko,1454196769,Raj Inamdar,51167132,Diana Floegel,,,,,"Computer Science, Sociology",JournalArticle
127,Observational Study of Working from Home during the COVID-19 Pandemic Using Social Media Data.,"BACKGROUND
Since March 2020, companies nationwide have started work from home (WFH) due to the rapid increase of confirmed COVID-19 cases in an attempt to help prevent the coronavirus from spreading and rescue the economy from the pandemic. Many organizations have conducted surveys to understand people's opinions towards WFH. However, the findings are limited due to a small sample size and the dynamic topics over time.


OBJECTIVE
The study aims to understand the U.S. public opinions on working from home during the COVID-19 pandemic.


METHODS
We conduct a large-scale social media study using Twitter data to portrait different groups who have positive/negative opinions about WFH. We perform an ordinary least squares regression to investigate the relationship between the sentiment about WFH and user characteristics including gender, age, ethnicity, median household income, and population density. To better understand public opinion, we use latent Dirichlet allocation to extract topics and discover how tweet contents relate to people's attitude.


RESULTS
After performing the ordinary least squares regression using a large-scale dataset (N=28,579) of publicly available Twitter posts concerning working from home ranging from April 10, 2020 to April 22, 2020, we confirm that sentiment of working from home varies across user characteristics. In particular, women tend to be more positive about working from home (p < .001). People in their 40s are more positive towards WFH than other age groups (p < .001). People from high-income areas are more likely to have positive opinions about working from home (p < .001). These nuanced differences are supported by a more fine-grained topic analysis. At a higher level, we find that the most negative sentiment about WFH roughly corresponds to the discussion of government policy. However, people express more positive sentiment when talking about topics on ""remote work/study"" and ""encouragement"". Furthermore, topic distributions vary across different user groups. Women pay more attention to family activities than men (p < .05). Older people talk more about work and express more positive sentiment on WFH.


CONCLUSIONS
This paper presents a large-scale social media-based study to understand the U.S. public opinions on working from home during the COVID-19 pandemic. We hope this study can lend itself to making policies both at national and institution/company levels to improve the overall population's experience of working from home.


CLINICALTRIAL",JMIR Medical Informatics,2021,25,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'It is confirmed that sentiment of working from home varies across user characteristics, and people express more positive sentiment when talking about topics on ""remote work/study"" and ""encouragement"", and topic distributions vary across different user groups.'}",127,2061496107,Ziyu Xiong,2158237484,Pin Li,1486450921,Hanjia Lyu,2116783457,Jiebo Luo,,,,,"Medicine, Computer Science","JournalArticle, Review"
128,Measuring Gender Bias in Educational Videos: A Case Study on YouTube,"Students are increasingly using online materials to learn new subjects or to supplement their learning process in educational institutions. Issues regarding gender bias have been raised in the context of formal education and some measures have been proposed to mitigate them. However, online educational materials in terms of possible gender bias and stereotypes which may appear in diﬀerent forms are yet to be investigated in the context of search bias in a widely-used search platform. As a ﬁrst step towards measuring possible gender bias in online platforms, we have investigated YouTube educational videos in terms of the perceived gender of their narrators. We adopted bias measures for ranked search results to evaluate educational videos returned by YouTube in response to queries related to STEM (Science, Technology, Engineering, and Mathematics) and NON-STEM ﬁelds of education. Gender is a research area by itself in social sciences which is beyond the scope of this work. In this respect, for annotating the perceived gender of the narrator of an instructional video we used only a crude classiﬁcation of gender into Male, and Female. Then, for analysing perceived gender bias we utilised bias measures that have been inspired by search platforms and further incorporated rank information into our analysis. Our preliminary results demonstrate that there is a signiﬁcant bias towards the male gender on the returned YouTube educational videos, and the degree of bias varies when we compare STEM and NON-STEM queries. Finally, there is a strong evidence that rank information might aﬀect the results.",ArXiv,2022,47,3,0,False,,128,3273139,Gizem Gezici,1793443,Y. Saygin,,,,,,,,,Computer Science,JournalArticle
129,When Follow is Just One Click Away: Understanding Twitter Follow Behavior in the 2016 U.S. Presidential Election,,Social Informatics,2017,43,12,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The Twitter follow behaviors observed in the 2016 U.S. presidential election are studied to study the effects of gender and occupation on the number of candidates that one follows and the effect of gender, occupation and celebrities on the choice of candidates to follow.'}",129,2153604061,Yu Wang,33642939,Jiebo Luo,2108216946,Xiyang Zhang,,,,,,,"Computer Science, Psychology",JournalArticle
130,Probabilistic Impact Score Generation using Ktrain-BERT to Identify Hate Words from Twitter Discussions,"Social media has seen a worrying rise in hate speech in recent times. Branching to several distinct categories of cyberbullying, gender discrimination, or racism, the combined label for such derogatory content can be classified as toxic content in general. This paper presents experimentation with a Keras wrapped lightweight BERT model to successfully identify hate speech and predict probabilistic impact score for the same to extract the hateful words within sentences. The dataset used for this task is the Hate Speech and Offensive Content Detection (HASOC 2021) data from FIRE 2021 in English. Our system obtained a validation accuracy of 82.60%, with a maximum F1-Score of 82.68%. Subsequently, our predictive cases performed significantly well in generating impact scores for successful identification of the hate tweets as well as the hateful words from tweet pools.",Fire,2021,13,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Experimentation with a Keras wrapped lightweight BERT model is presented to successfully identify hate speech and predict probabilistic impact score for the same to extract the hateful words within sentences.'}",130,2109605773,Sourav Das,2061544684,Prasanta Mandal,2075836678,S. Chatterji,,,,,,,Computer Science,JournalArticle
131,Analysis of Online Toxicity Detection Using Machine Learning Approaches,"Social media and the internet have become an integral part of how people spread and consume information. Over a period of time, social media evolved dramatically, and almost half of the population is using social media to express their views and opinions. Online hate speech is one of the drawbacks of social media nowadays, which needs to be controlled. In this paper, we will understand how hate speech originated and what are the consequences of it; Trends of machine-learning algorithms to solve an online hate speech problem. This study contributes by providing a systematic approach to help researchers to identify a new research direction and elucidating the shortcomings of the studies and model, as well as providing future directions to advance the field.",ArXiv,2021,23,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This study contributes by providing a systematic approach to help researchers to identify a new research direction and elucidating the shortcomings of the studies and model, as well as providing future directions to advance the field.'}",131,2079227751,Anjum,3126857,R. Katarya,,,,,,,,,Computer Science,JournalArticle
132,"Dawn of the Selfie Era: The Whos, Wheres, and Hows of Selfies on Instagram","Online interactions are increasingly involving images, especially those containing human faces, which are naturally attention grabbing and more effective at conveying feelings than text. To understand this new convention of digital culture, we study the collective behavior of sharing \textit{selfies} on Instagram and present how people appear in selfies and which patterns emerge from such interactions. Analysis of millions of photos shows that the amount of selfies has increased by 900 times from 2012 to 2014. Selfies are an effective medium to grab attention; they generate on average 1.1--3.2 times more likes and comments than other types of content on Instagram. Compared to other content, interactions involving selfies exhibit variations in homophily scores (in terms of age and gender) that suggest they are becoming more widespread. Their style also varies by cultural boundaries in that the average age and majority gender seen in selfies differ from one country to another. We provide explanations of such country-wise variations based on cultural and socioeconomic contexts.",Conference on Online Social Networks,2015,51,90,8,False,"{'model': 'tldr@v2.0.0', 'text': 'Analysis of millions of photos shows that the amount of selfies has increased by 900 times from 2012 to 2014, and interactions involving selfies exhibit variations in homophily scores (in terms of age and gender) that suggest they are becoming more widespread.'}",132,34997997,Flávio Souza,40333421,Diego Couto de Las Casas,3133079,V. Zambaldi,2100687990,Sun-Sook Youn,1775511,M. Cha,144041798,D. Quercia,"Psychology, Computer Science","JournalArticle, Book"
133,Mapping Visual Themes among Authentic and Coordinated Memes,"What distinguishes authentic memes from those created by state actors? I utilize a self-supervised vision model, DeepCluster, to learn low-dimensional visual embeddings of memes and apply K-means to jointly cluster authentic and coordinated memes without additional inputs. I find that authentic and coordinated memes share a large fraction of visual themes but with varying degrees. Coordinated memes from Russian IRA accounts promote more themes around celebrities, quotes, screenshots, military, and gender. Authentic Reddit memes include more themes with comics and movie characters. A simple logistic regression on the low-dimensional embeddings can discern IRA memes from Reddit memes with an out-sample testing accuracy of 0.84.",ArXiv,2022,17,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A self-supervised vision model, DeepCluster, is utilized to learn low-dimensional visual embeddings of memes and apply K-means to jointly cluster authentic and coordinated memes without additional inputs, finding that authentic andcoordinated memes share a large fraction of visual themes but with varying degrees.'}",133,1749334075,Keng-Chi Chang,,,,,,,,,,,Computer Science,JournalArticle
134,Deep Multi-Task Models for Misogyny Identification and Categorization on Arabic Social Media,"The prevalence of toxic content on social media platforms, such as hate speech, offensive language, and misogyny, presents serious challenges to our interconnected society. These challenging issues have attracted widespread attention in Natural Language Processing (NLP) community. In this paper, we present the submitted systems to the first Arabic Misogyny Identification shared task. We investigate three multi-task learning models as well as their single-task counterparts. In order to encode the input text, our models rely on the pre-trained MARBERT language model. The overall obtained results show that all our submitted models have achieved the best performances (top three ranked submissions) in both misogyny identification and categorization tasks.",Fire,2022,21,1,1,False,"{'model': 'tldr@v2.0.0', 'text': 'The overall obtained results show that all the submitted models have achieved the best performances (top three ranked submissions) in both misogyny identification and categorization tasks.'}",134,3196929,Abdelkader El Mahdaouy,150911972,Abdellah El Mekki,2171106164,Ahmed Oumar,2431019,H. Mousannif,2548030,Ismail Berrada,,,Computer Science,JournalArticle
135,Hate Speech and Counter Speech Detection: Conversational Context Does Matter,"Hate speech is plaguing the cyberspace along with user-generated content. Adding counter speech has become an effective way to combat hate speech online. Existing datasets and models target either (a) hate speech or (b) hate and counter speech but disregard the context. This paper investigates the role of context in the annotation and detection of online hate and counter speech, where context is defined as the preceding comment in a conversation thread. We created a context-aware dataset for a 3-way classification task on Reddit comments: hate speech, counter speech, or neutral. Our analyses indicate that context is critical to identify hate and counter speech: human judgments change for most comments depending on whether we show annotators the context. A linguistic analysis draws insights into the language people use to express hate and counter speech. Experimental results show that neural networks obtain significantly better results if context is taken into account. We also present qualitative error analyses shedding light into (a) when and why context is beneficial and (b) the remaining errors made by our best model when context is taken into account.",North American Chapter of the Association for Computational Linguistics,2022,43,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'The role of context is investigated in the annotation and detection of online hate and counter speech, where context is defined as the preceding comment in a conversation thread, and experimental results show that neural networks obtain significantly better results if context is taken into account.'}",135,2000567912,Xinchen Yu,,,,,,,,,,,Computer Science,"JournalArticle, Conference"
136,Sexism Identification in Tweets and Gabs using Deep Neural Networks,"Through anonymisation and accessibility, social media platforms have facilitated the proliferation of hate speech, prompting increased research in developing automatic methods to identify these texts. This paper explores the classification of sexism in text using a variety of deep neural network model architectures such as Long-Short-Term Memory (LSTMs) and Convolutional Neural Networks (CNNs). These networks are used in conjunction with transfer learning in the form of Bidirectional Encoder Representations from Transformers (BERT) and DistilBERT models, along with data augmentation, to perform binary and multiclass sexism classification on the dataset of tweets and gabs from the sEXism Identification in Social neTworks (EXIST) task in IberLEF 2021. The models are seen to perform comparatively to those from the competition, with the best performances seen using BERT and a multi-filter CNN model. Data augmentation further improves these results for the multi-class classification task. This paper also explores the errors made by the models and discusses the difficulty in automatically classifying sexism due to the subjectivity of the labels and the complexity of natural language used in social media. Keywords— Sexism classification, social media, natural language processing, neural networks, machine learning, BERT, transfer learning.",ArXiv,2021,40,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper explores the classification of sexism in text using a variety of deep neural network model architectures such as Long-Short-Term Memory (LSTMs) and Convolutional Neural Networks (CNNs) and explores the errors made by the models and discusses the difficulty in automatically classifying sexism due to the subjectivity of the labels and the complexity of natural language used in social media.'}",136,2139587599,Amikul Kalra,2805349,A. Zubiaga,,,,,,,,,Computer Science,JournalArticle
137,Towards Automatic Personality Prediction Using Facebook Like Categories,"We demonstrate that effortlessly accessible digital records of behavior such as Facebook Likes can be obtained and utilized to automatically distinguish a wide range of highly delicate personal traits including: life satisfaction, cultural ethnicity, political views, age, gender and personality traits. The analysis presented based on a dataset of over 738,000 users who conferred their Facebook Likes, social network activities, egocentric network, demographic characteristics, and the results of various psychometric tests for our extended personality analysis. The proposed model uses unique mapping technique between each Facebook Like object to the corresponding Facebook page category/sub-category object, which is then evaluated as features for a set of machine learning algorithms to predict individual psycho-demographic profiles from Likes. The model , distinguishes between a religious and non-religious individual in 83% of circumstances, Asian and European in 87% of situations, and between emotional stable and emotion unstable in 81% of situations. We provide exemplars of correlations between attributes and Likes and present suggestions for future directions.",ArXiv,2018,13,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is demonstrated that effortlessly accessible digital records of behavior such as Facebook Likes can be obtained and utilized to automatically distinguish a wide range of highly delicate personal traits including: life satisfaction, cultural ethnicity, political views, age, gender and personality traits.'}",137,32278976,Raad Bin Tareaf,48143787,Philipp Berger,1760108,Patrick Hennig,1708312,C. Meinel,,,,,"Computer Science, Psychology, Mathematics",JournalArticle
138,Choosing an algorithmic fairness metric for an online marketplace: Detecting and quantifying algorithmic bias on LinkedIn,"In this paper, we derive an algorithmic fairness metric from the fairness notion of equal opportunity for equally qualified candidates for recommendation algorithms commonly used by two-sided marketplaces. We borrow from the economic literature on discrimination to arrive at a test for detecting bias that is solely attributable to the algorithm, as opposed to other sources such as societal inequality or human bias on the part of platform users. We use the proposed method to measure and quantify algorithmic bias with respect to gender of two algorithms used by LinkedIn—a popular online platform used by job seekers and employers. Moreover, we introduce a framework and the rationale for distinguishing algorithmic bias from human bias, both of which can potentially exist on a two-sided platform where algorithms make recommendations to human users. Finally, we discuss the shortcomings of a few other common algorithmic fairness metrics and why they do not capture the fairness notion of equal opportunity for equally qualified candidates.",ArXiv,2022,11,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'An algorithmic fairness metric is derived from the fairness notion of equal opportunity for equally qualified candidates for recommendation algorithms commonly used by two-sided marketplaces to measure and quantify algorithmic bias with respect to gender of two algorithms used by LinkedIn.'}",138,48623663,YinYin Yu,1403025860,Guillaume Saint-Jacques,,,,,,,,,"Computer Science, Economics",JournalArticle
139,Is Japanese gendered language used on Twitter ? A large scale study,"This study analyzes the usage of Japanese gendered language on Twitter. Starting from a collection of 408 million Japanese tweets from 2015 till 2019 and an additional sample of 2355 manually classified Twitter accounts timelines into gender and categories (politicians, musicians, etc). A large scale textual analysis is performed on this corpus to identify and examine sentence-final particles (SFPs) and first-person pronouns appearing in the texts. It turns out that gendered language is in fact used also on Twitter, in about 6% of the tweets, and that the prescriptive classification into ""male"" and ""female"" language does not always meet the expectations, with remarkable exceptions. Further, SFPs and pronouns show increasing or decreasing trends, indicating an evolution of the language used on Twitter.",Online Journal of Communication and Media Technologies,2020,52,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'It turns out that gendered language is in fact used also on Twitter, in about 6% of the tweets, and that the prescriptive classification into ""male"" and ""female"" language does not always meet the expectations, with remarkable exceptions.'}",139,116807884,Tiziana Carpi,1760557,S. Iacus,,,,,,,,,"Computer Science, Mathematics, History",JournalArticle
140,Characterizing Multi-Domain False News and Underlying User Effects on Chinese Weibo,,Information Processing & Management,2022,96,4,0,True,"{'model': 'tldr@v2.0.0', 'text': 'Investigation of false news across nine domains on Weibo from 2009 to 2019 finds that false news in domains that are close to daily life like health and medicine generated more posts but were used less e-ectively than those in other domains like politics, and that political false news had the most e-ective capacity for diﬀusion.'}",140,46630548,Qiang Sheng,144089410,Juan Cao,144125273,H. Bernard,145800151,Kai Shu,2159216437,Jintao Li,145896397,Huan Liu,Computer Science,JournalArticle
141,Producers of Popular Science Web Videos. Between New Professionalism and Old Gender Issues,"This article provides an overview of the web video production context related to science communication, based on a quantitative analysis of 190 YouTube videos. The authors explore the main characteristics and ongoing strategies of producers, focusing on three topics: professionalism, producer's gender and age profile, and community building. In the discussion, the authors compare the quantitative results with recently published qualitative research on producers of popular science web videos. This complementary approach gives further evidence on the main characteristics of most popular science communicators on YouTube, it shows a new type of professionalism that surpasses the hitherto existing distinction between User Generated Content (UGC) and Professional Generated Content (PGC), raises gender issues, and questions the participatory culture of science communicators on YouTube.",ArXiv,2019,47,7,2,False,"{'model': 'tldr@v2.0.0', 'text': 'An overview of the web video production context related to science communication is provided, based on a quantitative analysis of 190 YouTube videos, which shows a new type of professionalism that surpasses the hitherto existing distinction between User Generated Content (UGC) and Professional Generated content (PGC).'}",141,2074894738,J. Morcillo,47117537,Klemens Czurda,47894937,Andrea Geipel,120476526,C. R. Trotha,,,,,"Sociology, Computer Science","JournalArticle, Review"
142,Subscriptions and external links help drive resentful users to alternative and extremist YouTube videos,"Do online platforms facilitate the consumption of potentially harmful content? Despite widespread concerns that YouTube’s algorithms send people down “rabbit holes” with recommendations to extremist videos, little systematic evidence exists to support this conjecture. Using paired behavioral and survey data provided by participants recruited from a representative sample (n=1,181), we show that exposure to alternative and extremist channel videos on YouTube is heavily concentrated among a small group of people with high prior levels of gender and racial resentment. These viewers typically subscribe to these channels (causing YouTube to recommend their videos more often) and often follow external links to them. Contrary to the “rabbit holes” narrative, non-subscribers are rarely recommended videos from alternative and extremist channels and seldom follow such recommendations when offered. †We are grateful to the Russell Sage Foundation, Anti-Defamation League, Carnegie Corporation of New York, and the National Science Foundation for financial support, to Samantha Luks at YouGov for survey assistance, to Kasey Rhee for research assistance, to Andy Guess for helping design this project in its initial stages, and to Tanushree Mitra, Joseph B. Phillips, David Rothschild, Gianluca Stringhini, and Savvas Zannettou for comments and feedback. We also thank Virgílio A.F. Almeida, Stephen Ansolabehere, Manoel Horta Ribeiro, Aaron Sankin, Brian Schaffner, Robert West, and Anna Zaitsev for sharing their data with us or making it publicly available. This research utilized equipment funded by NSF grant IIS-1910064. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funders. In general, all conclusions and errors are our own. ar X iv :2 20 4. 10 92 1v 1 [ cs .S I] 2 2 A pr 2 02 2 What role do technology platforms play in exposing people to dubious and hateful information and enabling its spread? Concerns have grown in recent years that online communication is exacerbating the human tendency to engage in preferential exposure to congenial information (1–3). Such concerns are particularly acute on social media, where people may be especially likely to view content about topics such as politics and health that is false, extremist, or otherwise potentially harmful. The use of algorithmic recommendations and platform affordances such as following and subscribing features may enable this process, helping people to find potentially harmful content and helping content creators build and monetize an audience for it. These concerns are particularly acute for YouTube, the most widely used social media platform in the U.S. (4). Critics highlight the popularity of extreme and harmful content such as videos by white nationalists on YouTube, which they often attribute to the recommendation system that the company itself says is responsible for 70 percent of user watch time (5). Many fear that these algorithmic recommendations are an engine for radicalization. For instance, the sociologist Zeynep Tufecki wrote that the YouTube recommendation system “may be one of the most powerful radicalizing instruments of the 21st century” (6). These claims seem to be supported by reporting that features descriptions of recommendations to potentially harmful videos and accounts of people whose lives were upended by content they encountered online (7–9). In response to these critiques, YouTube announced changes in 2019 to “reduce the spread of content that comes close to—but doesn’t quite cross the line of—violating our Community Guidelines” (10). It subsequently claimed that these interventions resulted in a 50% drop in watch time from recommendations for “borderline content and harmful misinformation” and a 70% decline in watch time from non-subscribed recommendations (11, 12). Questions remain, however, about the size and composition of the audience for potentially harmful videos on YouTube and the manner in which people reach those videos. To date, research investigating YouTube has lagged behind studies of its social media counterparts. Studies show that sites like Twitter and Facebook can amplify tendencies toward extreme opinions or spread false information (13, 14), though the extent of these effects and the prevalence of exposure is often overstated",ArXiv,2022,43,5,1,False,,142,2111073663,Annie Y. Chen,2064358,B. Nyhan,145683696,Jason Reifler,2053242555,Ronald E. Robertson,35497150,Christo Wilson,,,Computer Science,"JournalArticle, Review"
143,"Deradicalizing YouTube: Characterization, Detection, and Personalization of Religiously Intolerant Arabic Videos","Growing evidence suggests that YouTube's recommendation algorithm plays a role in online radicalization via surfacing extreme content. Radical Islamist groups, in particular, have been profiting from the global appeal of YouTube to disseminate hate and jihadist propaganda. In this quantitative, data-driven study, we investigate the prevalence of religiously intolerant Arabic YouTube videos, the tendency of the platform to recommend such videos, and how these recommendations are affected by demographics and watch history. Based on our deep learning classifier developed to detect hateful videos and a large-scale dataset of over 350K videos, we find that Arabic videos targeting religious minorities are particularly prevalent in search results (30%) and first-level recommendations (21%), and that 15% of overall captured recommendations point to hateful videos. Our personalized audit experiments suggest that gender and religious identity can substantially affect the extent of exposure to hateful content. Our results contribute vital insights into the phenomenon of online radicalization and facilitate curbing online harmful content.",Proc. ACM Hum. Comput. Interact.,2022,94,0,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This quantitative, data-driven study investigates the prevalence of religiously intolerant Arabic YouTube videos, the tendency of the platform to recommend such videos, and how these recommendations are affected by demographics and watch history, and develops a deep learning classifier developed to detect hateful videos.'}",143,67096342,Nuha Albadi,66081097,Maram Kurdi,1681816,Shivakant Mishra,,,,,,,Computer Science,JournalArticle
144,Exploring difference in public perceptions on HPV vaccine between gender groups from Twitter using deep learning,"In this study, we proposed a convolutional neural network model for gender prediction using English Twitter text as input. Ensemble of proposed model achieved an accuracy at 0.8237 on gender prediction and compared favorably with the state-of-the-art performance in a recent author profiling task. We further leveraged the trained models to predict the gender labels from an HPV vaccine related corpus and identified gender difference in public perceptions regarding HPV vaccine. The findings are largely consistent with previous survey-based studies.",ArXiv,2019,30,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A convolutional neural network model is proposed for gender prediction using English Twitter text as input and trained models are leveraged to predict the gender labels from an HPV vaccine related corpus and identified gender difference in public perceptions regarding HPV vaccine.'}",144,1728324,Jingcheng Du,50649494,Chongliang Luo,72272761,Qiang Wei,2155260322,Yong Chen,34394575,Cui Tao,,,"Computer Science, Mathematics","JournalArticle, Review"
145,Co-Training for Demographic Classification Using Deep Learning from Label Proportions,"Deep learning algorithms have recently produced state-of-the-art accuracy in many classification tasks, but this success is typically dependent on access to many annotated training examples. For domains without such data, an attractive alternative is to train models with light, or distant supervision. In this paper, we introduce a deep neural network for the Learning from Label Proportion (LLP) setting, in which the training data consist of bags of unlabeled instances with associated label distributions for each bag. We introduce a new regularization layer, Batch Averager, that can be appended to the last layer of any deep neural network to convert it from supervised learning to LLP. This layer can be implemented readily with existing deep learning packages. To further support domains in which the data consist of two conditionally independent feature views (e.g. image and text), we propose a co-training algorithm that iteratively generates pseudo bags and refits the deep LLP model to improve classification accuracy. We demonstrate our models on demographic attribute classification (gender and race/ethnicity), which has many applications in social media analysis, public health, and marketing. We conduct experiments to predict demographics of Twitter users based on their tweets and profile image, without requiring any user-level annotations for training. We find that the deep LLP approach outperforms baselines for both text and image features separately. Additionally, we find that co-training algorithm improves image and text classification by 4% and 8% absolute F1, respectively. Finally, an ensemble of text and image classifiers further improves the absolute F1 measure by 4% on average.",2017 IEEE International Conference on Data Mining Workshops (ICDMW),2017,28,39,11,True,"{'model': 'tldr@v2.0.0', 'text': 'A new regularization layer, Batch Averager, is introduced that can be appended to the last layer of any deep neural network to convert it from supervised learning to LLP, and can be implemented readily with existing deep learning packages.'}",145,1875047,Ehsan Mohammady Ardehaly,1741453,A. Culotta,,,,,,,,,"Computer Science, Mathematics","JournalArticle, Conference"
146,Nationality Classification Using Name Embeddings,"Nationality identification unlocks important demographic information, with many applications in biomedical and sociological research. Existing name-based nationality classifiers use name substrings as features and are trained on small, unrepresentative sets of labeled names, typically extracted from Wikipedia. As a result, these methods achieve limited performance and cannot support fine-grained classification. We exploit the phenomena of homophily in communication patterns to learn name embeddings, a new representation that encodes gender, ethnicity, and nationality which is readily applicable to building classifiers and other systems. Through our analysis of 57M contact lists from a major Internet company, we are able to design a fine-grained nationality classifier covering 39 groups representing over 90% of the world population. In an evaluation against other published systems over 13 common classes, our F1 score (0.795) is substantial better than our closest competitor Ethnea (0.580). To the best of our knowledge, this is the most accurate, fine-grained nationality classifier available. As a social media application, we apply our classifiers to the followers of major Twitter celebrities over six different domains. We demonstrate stark differences in the ethnicities of the followers of Trump and Obama, and in the sports and entertainments favored by different groups. Finally, we identify an anomalous political figure whose presumably inflated following appears largely incapable of reading the language he posts in.",International Conference on Information and Knowledge Management,2017,32,65,10,True,"{'model': 'tldr@v2.0.0', 'text': 'This work designs a fine-grained nationality classifier covering 39 groups representing over 90% of the world population and exploits the phenomena of homophily in communication patterns to learn name embeddings, a new representation that encodes gender, ethnicity, and nationality which is readily applicable to building classifiers and other systems.'}",146,2049963,Junting Ye,1733414,Shuchu Han,50819900,Yifan Hu,3172811,B. Coskun,35582088,Meizhu Liu,145199626,Hong Qin,Computer Science,"JournalArticle, Book, Conference"
147,Tackling Racial Bias in Automated Online Hate Detection: Towards Fair and Accurate Classification of Hateful Online Users Using Geometric Deep Learning,"Online hate is a growing concern on many social media platforms and other sites. To combat it, technology companies are increasingly identifying and sanctioning ‘hateful users’ rather than simply moderating hateful content. Yet, most research in online hate detection to date has focused on hateful content. This paper examines how fairer and more accurate hateful user detection systems can be developed by incorporating social network information through geometric deep learning. Geometric deep learning dynamically learns information-rich network representations and can generalise to unseen nodes. This is essential for moving beyond manually engineered network features, which lack scalability and produce information-sparse network representations. This paper compares the accuracy of geometric deep learning with other techniques which either exclude network information or incorporate it through manual feature engineering (e.g., node2vec). It also evaluates the fairness of these techniques using the ‘predictive equality’ criteria, comparing the false positive rates on a subset of 136 AfricanAmerican users with 4836 other users. Geometric deep learning produces the most accurate and fairest classifier, with an AUC score of 90.8% on the entire dataset and a false positive rate of zero among the African-American subset for the best performing model. This highlights the benefits of more effectively incorporating social network features in automated hateful user detection. Such an approach is also easily operationalized for real-world content moderation as it has an efficient and scalable design.",ArXiv,2021,55,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Geometric deep learning is found to be the most accurate and fairest classifier, with an AUC score of 90.8% on the entire dataset and a false positive rate of zero among the African-American subset for the best performing model.'}",147,2058646836,Zo Ahmed,2737827,Bertie Vidgen,1741886127,Scott A. Hale,,,,,,,Computer Science,JournalArticle
148,How Much Hate with #china? A Preliminary Analysis on China-related Hateful Tweets Two Years After the Covid Pandemic Began,"Following the outbreak of a global pandemic, online content is filled with hate speech. Donald Trump's ''Chinese Virus'' tweet shifted the blame for the spread of the Covid-19 virus to China and the Chinese people, which triggered a new round of anti-China hate both online and offline. This research intends to examine China-related hate speech on Twitter during the two years following the burst of the pandemic (2020 and 2021). Through Twitter's API, in total 2,172,333 tweets hashtagged #china posted during the time were collected. By employing multiple state-of-the-art pretrained language models for hate speech detection, we identify a wide range of hate of various types, resulting in an automatically labeled anti-China hate speech dataset. We identify a hateful rate in #china tweets of 2.5% in 2020 and 1.9% in 2021. This is well above the average rate of online hate speech on Twitter at 0.6% identified in Gao et al., 2017. We further analyzed the longitudinal development of #china tweets and those identified as hateful in 2020 and 2021 through visualizing the daily number and hate rate over the two years. Our keyword analysis of hate speech in #china tweets reveals the most frequently mentioned terms in the hateful #china tweets, which can be used for further social science studies.",ArXiv,2022,49,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This research intends to examine China-related hate speech on Twitter during the two years following the burst of the pandemic, and identifies a hateful rate in #china tweets of 2.5% in 2020 and 1.9% in 2021.'}",148,2175667087,Jinghua Xu,51191436,Zarah Weiß,,,,,,,,,Computer Science,JournalArticle
149,Review of Inferring Latent Attributes from Twitter,"This paper reviews literature from 2011 to 2013 on how Latent attributes like gender, political leaning etc. can be inferred from a person's twitter and neighborhood data. Prediction of demographic data can bring value to businesses, can prove instrumental in legal investigation. Moreover, political leanings can be inferred from the wide variety of user data available on-line. The motive of this review is to understand how large data sets can be made from available twitter data. The tweeting and re tweeting behavior of a user can be user to infer attributes like, gender, age etc. We explore in this text how this field can be expanded in future and possible avenues for future research.",ArXiv,2015,14,0,0,True,"{'model': 'tldr@v2.0.0', 'text': ""This paper reviews literature from 2011 to 2013 on how Latent attributes like gender, political leaning etc. can be inferred from a person's twitter and neighborhood data to understand how large data sets can be made from available twitter data.""}",149,8287427,Surabhi Singh Ludu,,,,,,,,,,,Computer Science,"JournalArticle, Review"
150,Hate multiverse spreads malicious COVID-19 content online beyond individual platform control,"We show that malicious COVID-19 content, including hate speech, disinformation, and misinformation, exploits the multiverse of online hate to spread quickly beyond the control of any individual social media platform. Machine learning topic analysis shows quantitatively how online hate communities are weaponizing COVID-19, with topics evolving rapidly and content becoming increasingly coherent. Our mathematical analysis provides a generalized form of the public health R0 predicting the tipping point for multiverse-wide viral spreading, which suggests new policy options to mitigate the global spread of malicious COVID-19 content without relying on future coordination between all online platforms.",,2020,23,38,1,False,"{'model': 'tldr@v2.0.0', 'text': 'Mathematical analysis provides a generalized form of the public health R0 predicting the tipping point for multiverse-wide viral spreading, which suggests new policy options to mitigate the global spread of malicious COVID-19 content without relying on future coordination between all online platforms.'}",150,2065925322,N. Vel'asquez,152152429,R. Leahy,1695773203,N. J. Restrepo,51169219,Y. Lupu,118692657,R. Sear,1720776022,N. Gabriel,"Computer Science, Physics",
151,Empowering NGOs in Countering Online Hate Messages,,Online Soc. Networks Media,2021,58,4,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A novel ICT platform that NGO operators can use to monitor and analyze social media data, along with a counter-narrative suggestion tool is introduced, aimed at increasing the efficiency and effectiveness of operators’ activities against islamophobia.'}",151,2087250906,Yi-ling Chung,2034636,Serra Sinem Tekiroğlu,1809243,Sara Tonelli,1912357,Marco Guerini,,,,,Computer Science,JournalArticle
152,Comparative Analysis of Machine Learning and Deep Learning Algorithms for Detection of Online Hate Speech,,ArXiv,2021,33,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'It is concluded that BERT based embeddings give the most useful features for hate speech classification and have the capacity to be made into a practical robust model.'}",152,2106942035,Tashvik Dhamija,2079227751,Anjum,3126857,R. Katarya,,,,,,,Computer Science,JournalArticle
153,Human-Machine Collaboration Approaches to Build a Dialogue Dataset for Hate Speech Countering,"Fighting online hate speech is a challenge that is usually addressed using Natural Language Processing via automatic detection and removal of hate content. Besides this approach, counter narratives have emerged as an effective tool employed by NGOs to respond to online hate on social media platforms. For this reason, Natural Language Generation is currently being studied as a way to automatize counter narrative writing. However, the existing resources necessary to train NLG models are limited to 2-turn interactions (a hate speech and a counter narrative as response), while in real life, interactions can consist of multiple turns. In this paper, we present a hybrid approach for dialogical data collection, which combines the intervention of human expert annotators over machine generated dialogues obtained using 19 different configurations. The result of this work is DIALOCONAN, the first dataset comprising over 3000 fictitious multi-turn dialogues between a hater and an NGO operator, covering 6 targets of hate.",Conference on Empirical Methods in Natural Language Processing,2022,50,1,1,False,"{'model': 'tldr@v2.0.0', 'text': 'DIALOCONAN is presented, the first dataset comprising over 3000 fictitious multi-turn dialogues between a hater and an NGO operator, covering 6 targets of hate, and a hybrid approach for dialogical data collection, which combines the intervention of human expert annotators over machine generated dialogues obtained using 19 different configurations.'}",153,2161343118,Helena Bonaldi,2323757,Sara Dellantonio,2034636,Serra Sinem Tekiroğlu,1912357,Marco Guerini,,,,,Computer Science,"JournalArticle, Conference"
154,Beyond Fish and Bicycles: Exploring the Varieties of Online Women's Ideological Spaces,"The Internet has been instrumental in connecting under-represented and vulnerable groups of people. Platforms built to foster social interaction and engagement have enabled historically disenfranchised groups to have a voice. One such vulnerable group is women. In this paper, we explore the diversity in online women's ideological spaces using a multi-dimensional approach. We perform a large-scale, data-driven analysis of over 6M Reddit comments and submissions from 14 subreddits. We elicit a diverse taxonomy of online women's ideological spaces, ranging from counterparts to the so-called Manosphere to Gender-Critical Feminism. We then perform content analysis, finding meaningful differences across topics and communities. Finally, we shed light on two platforms, ovarit.com and thepinkpill.co, where two toxic communities of online women's ideological spaces (Gender-Critical Feminism and Femcels) migrated after their ban on Reddit.",ArXiv,2023,98,0,0,False,,154,1931977146,Utkucan Balci,2059988259,Chen Ling,2064581974,Emiliano De Cristofaro,3314746,Megan Squire,2350947,G. Stringhini,144728530,J. Blackburn,Computer Science,JournalArticle
155,Sexism Prediction in Spanish and English Tweets Using Monolingual and Multilingual BERT and Ensemble Models,"The popularity of social media has created problems such as hate speech and sexism. The identification and classification of sexism in social media are very relevant tasks, as they would allow building a healthier social environment. Nevertheless, these tasks are considerably challenging. This work proposes a system to use multilingual and monolingual BERT and data points translation and ensemble strategies for sexism identification and classification in English and Spanish. It was conducted in the context of the sEXism Identification in Social neTworks shared 2021 (EXIST 2021) task, proposed by the Iberian Languages Evaluation Forum (IberLEF). The proposed system and its main components are described, and an in-depth hyperparameters analysis is conducted. The main results observed were: (i) the system obtained better results than the baseline model (multilingual BERT); (ii) ensemble models obtained better results than monolingual models; and (iii) an ensemble model considering all individual models and the best standardized values obtained the best accuracies and F1-scores for both tasks. This work obtained first place in both tasks at EXIST, with the highest accuracies (0.780 for task 1 and 0.658 for task 2) and F1-scores (F1-binary of 0.780 for task 1 and F1-macro of 0.579 for task 2).",IberLEF@SEPLN,2021,35,8,2,False,"{'model': 'tldr@v2.0.0', 'text': 'This work proposes a system to use multilingual and monolingual BERT and data points translation and ensemble strategies for sexism identification and classification in English and Spanish and obtained first place in both tasks at EXIST.'}",155,1657652841,Angel Felipe Magnossão de Paula,32300892,Roberto Fray da Silva,32775036,I. Baris Schlicht,,,,,,,Computer Science,JournalArticle
156,Recognizing Explicit and Implicit Hate Speech Using a Weakly Supervised Two-path Bootstrapping Approach,"In the wake of a polarizing election, social media is laden with hateful content. To address various limitations of supervised hate speech classification methods including corpus bias and huge cost of annotation, we propose a weakly supervised two-path bootstrapping approach for an online hate speech detection model leveraging large-scale unlabeled data. This system significantly outperforms hate speech detection systems that are trained in a supervised manner using manually annotated data. Applying this model on a large quantity of tweets collected before, after, and on election day reveals motivations and patterns of inflammatory language.",International Joint Conference on Natural Language Processing,2017,17,52,5,False,"{'model': 'tldr@v2.0.0', 'text': 'This work proposes a weakly supervised two-path bootstrapping approach for an online hate speech detection model leveraging large-scale unlabeled data that significantly outperformshate speech detection systems that are trained in a supervised manner using manually annotated data.'}",156,2112351624,Lei Gao,27589853,Alexis Kuppersmith,40372969,Ruihong Huang,,,,,,,Computer Science,"JournalArticle, Conference"
157,A feast for trolls - Engagement analysis of counternarratives against online toxicity,"This report provides an engagement analysis of counternarratives against online toxicity. Between February 2020 and July 2021, we observed over 15 million toxic messages on social media identified by our fine-grained, multilingual detection AI. Over 1,000 dashboard users responded to toxic messages with combinations of visual memes, text, or AI-generated text, or they reported content. This leads to new, real-life insights on self-regulatory approaches for the mitigation of online hate.",ArXiv,2021,0,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This report provides an engagement analysis of counternarratives against online toxicity, and new, real-life insights on self-regulatory approaches for the mitigation of online hate.'}",157,8231390,T. D. Smedt,1696735715,Pierre Vou'e,51437018,S. Jaki,2087935404,Emily-Claire Duffy,2140457653,Lydia El-Khouri,,,Computer Science,JournalArticle
158,Bangla Text Dataset and Exploratory Analysis for Online Harassment Detection,"Being the seventh most spoken language in the world, the use of the Bangla language online has increased in recent times. Hence, it has become very important to analyze Bangla text data to maintain a safe and harassment-free online place. The data that has been made accessible in this article has been gathered and marked from the comments of people in public posts by celebrities, government officials, athletes on Facebook. The total amount of collected comments is 44001. The dataset is compiled with the aim of developing the ability of machines to differentiate whether a comment is a bully expression or not with the help of Natural Language Processing and to what extent it is improper if it is an inappropriate comment. The comments are labeled with different categories of harassment. Exploratory analysis from different perspectives is also included in this paper to have a detailed overview. Due to the scarcity of data collection of categorized Bengali language comments, this dataset can have a significant role for research in detecting bully words, identifying inappropriate comments, detecting different categories of Bengali bullies, etc. The dataset is publicly available at https://data.mendeley.com/datasets/9xjx8twk8p. Keywords— Bangla Text, Sentimental analysis, Natural language processing (NLP), Cyberbullying, Social Media Bullying, Online Harassment.",ArXiv,2021,3,4,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This dataset is compiled with the aim of developing the ability of machines to differentiate whether a comment is a bully expression or not with the help of Natural Language Processing and to what extent it is improper if it is an inappropriate comment.'}",158,2109417020,Md Faisal Ahmed,2047832126,Zalish Mahmud,2047832070,Zarin Tasnim Biash,2047832085,Ahmed Ann Noor Ryen,2055285123,Arman Hossain,10676418,Faisal Bin Ashraf,Computer Science,"JournalArticle, Review"
159,Hate is the New Infodemic: A Topic-aware Modeling of Hate Speech Diffusion on Twitter,"Online hate speech, particularly over microblogging platforms like Twitter, has emerged as arguably the most severe issue of the past decade. Several countries have reported a steep rise in hate crimes infuriated by malicious hate campaigns. While the detection of hate speech is one of the emerging research areas, the generation and spread of topic-dependent hate in the information network remain under-explored. In this work, we focus on exploring user behavior, which triggers the genesis of hate speech on Twitter and how it diffuses via retweets. We crawl a large-scale dataset of tweets, retweets, user activity history, and follower networks, comprising over 161 million tweets from more than 41 million unique users. We also collect over 600k contemporary news articles published online. We characterize different signals of information that govern these dynamics. Our analyses differentiate the diffusion dynamics in the presence of hate from usual information diffusion. This motivates us to formulate the modeling problem in a topic-aware setting with real-world knowledge. For predicting the initiation of hate speech for any given hashtag, we propose multiple feature-rich models, with the best performing one achieving a macro F1 score of 0.65. Meanwhile, to predict the retweet dynamics on Twitter, we propose RETINA, a novel neural architecture that incorporates exogenous influence using scaled dot-product attention. RETINA achieves a macro F1-score of 0.85, outperforming multiple state-of-the-art models. Our analysis reveals the superlative power of RETINA to predict the retweet dynamics of hateful content compared to the existing diffusion models.",IEEE International Conference on Data Engineering,2020,41,18,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work crawls a large-scale dataset of tweets, retweets, user activity history, and follower networks, comprising over 161 million tweets from more than 41 million unique users, and proposes RETINA, a novel neural architecture that incorporates exogenous influence using scaled dot-product attention to predict the retweet dynamics of hateful content.'}",159,36715403,Sarah Masud,50757931,Subhabrata Dutta,1993509923,Sakshi Makkar,1739191861,Chhavi Jain,1744939,Vikram Goyal,47295571,A. Das,Computer Science,"JournalArticle, Conference"
160,Examining Racial Bias in an Online Abuse Corpus with Structural Topic Modeling,We use structural topic modeling to examine racial bias in data collected to train models to detect hate speech and abusive language in social media posts. We augment the abusive language dataset by adding an additional feature indicating the predicted probability of the tweet being written in African-American English. We then use structural topic modeling to examine the content of the tweets and how the prevalence of different topics is related to both abusiveness annotation and dialect prediction. We find that certain topics are disproportionately racialized and considered abusive. We discuss how topic modeling may be a useful approach for identifying bias in annotated data.,ArXiv,2020,18,8,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is found that certain topics are disproportionately racialized and considered abusive in social media posts and how the prevalence of different topics is related to both abusiveness annotation and dialect prediction is examined.'}",160,2054378953,Thomas Davidson,2052797388,Debasmita Bhattacharya,,,,,,,,,Computer Science,JournalArticle
161,The Cognitive Science of Extremist Ideologies Online,"Extremist ideologies are finding new homes in online forums. These serve as both places for true believers, and recruiting-grounds for curious newcomers. To understand how newcomers learn ideology online, we study the Reddit archives of a novel sexist ideology known as the “the Red Pill”. Matching a longstanding hypothesis in the social sciences, our methods resolve the ideology into two components: a “behavioral” dimension, concerned with correcting behavior towards the self and others, and an “explanatory” dimension, of unifying explanations for the worldview. We then build a model of how newcomers to the group navigate the underlying conceptual structure. This reveals a large population of “tourists”, who leave quickly, and a smaller group of “residents” who join the group and remain for orders of magnitude longer. Newcomers are attracted by the behavioral component, in the form of self-help topics such as diet, exercise, and addiction. Explanations, however, keep them there, turning tourists into residents. They have powerful effects: explanation adoption can more than double the duration of median engagement, and can explain the emergence of a long-tail of high-power engagers. The most sticky explanations, that predict the longest engagement, are about status hierarchies. Extremist ideologies are not new—“Islamism” (Mandaville, 2010) or “white supremacy” (Zanden, 1959) are decades or centuries old—but a great deal of contemporary attention has centered on the new role of online forums in how they spread, evolve, and attract adherents. The connection between an online forum and an ideology is often made when a forum participant commits an act of political violence (Nagle, 2017), but outliers are only one side of the story. Another side is the hundreds of thousands of individuals who encounter these ideologies, experiment with them or even adopt them for a time, but who do not become terrorists themselves. The goal of this paper is to understand the cognitive processes involved in how people learn ideology. As we discuss in detail below, all ideologies have a dual nature: they are both explanations of the world, and patterns of behaviors. A sexist ideology, for example, includes not only a network of re-enforcing beliefs that explain a person’s experiences in terms of the inferiority of women to men, but also habits of action ranging from degrading comments to physical assault (Manne, 2017). As explanations, ideologies are of great interest because of how they both link together ideas in ways that appeal to basic sense-making drives. As patterns of behavior, meanwhile, they matter because of how they alter and create basic features of social life—and, of course, because of how damaging the behaviors can become. ar X iv :2 11 0. 00 62 6v 1 [ cs .S I] 1 O ct 2 02 1",ArXiv,2021,76,4,0,False,"{'model': 'tldr@v2.0.0', 'text': 'To understand how newcomers learn ideology online, the Reddit archives of a novel sexist ideology known as the “the Red Pill” are studied, and a model of how newcomers to the group navigate the underlying conceptual structure is built.'}",161,153538962,C. Perry,1794096,S. Dedeo,,,,,,,,,"Computer Science, Mathematics",JournalArticle
162,UPB at SemEval-2022 Task 5: Enhancing UNITER with Image Sentiment and Graph Convolutional Networks for Multimedia Automatic Misogyny Identification,"In recent times, the detection of hate-speech, offensive, or abusive language in online media has become an important topic in NLP research due to the exponential growth of social media and the propagation of such messages, as well as their impact. Misogyny detection, even though it plays an important part in hate-speech detection, has not received the same attention. In this paper, we describe our classification systems submitted to the SemEval-2022 Task 5: MAMI - Multimedia Automatic Misogyny Identification. The shared task aimed to identify misogynous content in a multi-modal setting by analysing meme images together with their textual captions. To this end, we propose two models based on the pre-trained UNITER model, one enhanced with an image sentiment classifier, whereas the second leverages a Vocabulary Graph Convolutional Network (VGCN). Additionally, we explore an ensemble using the aforementioned models. Our best model reaches an F1-score of 71.4% in Sub-task A and 67.3% for Sub-task B positioning our team in the upper third of the leaderboard. We release the code and experiments for our models on GitHub.",International Workshop on Semantic Evaluation,2022,40,1,1,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes two models based on the pre-trained UNITER model, one enhanced with an image sentiment classifier, whereas the second leverages a Vocabulary Graph Convolutional Network (VGCN).'}",162,1379949812,Andrei Paraschiv,151505823,M. Dascalu,3046903,Dumitru-Clementin Cercel,,,,,,,Computer Science,JournalArticle
163,Detect All Abuse! Toward Universal Abusive Language Detection Models,"Online abusive language detection (ALD) has become a societal issue of increasing importance in recent years. Several previous works in online ALD focused on solving a single abusive language problem in a single domain, like Twitter, and have not been successfully transferable to the general ALD task or domain. In this paper, we introduce a new generic ALD framework, MACAS, which is capable of addressing several types of ALD tasks across different domains. Our generic framework covers multi-aspect abusive language embeddings that represent the target and content aspects of abusive language and applies a textual graph embedding that analyses the user’s linguistic behaviour. Then, we propose and use the cross-attention gate flow mechanism to embrace multiple aspects of abusive language. Quantitative and qualitative evaluation results show that our ALD algorithm rivals or exceeds the six state-of-the-art ALD algorithms across seven ALD datasets covering multiple aspects of abusive language and different online community domains.",International Conference on Computational Linguistics,2020,31,14,4,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper introduces a new generic ALD framework, MACAS, which is capable of addressing several types of ALD tasks across different domains and proposes and uses the cross-attention gate flow mechanism to embrace multiple aspects of abusive language.'}",163,1990752926,Kunze Wang,2111833225,Dong Lu,2046142,Soyeon Caren Han,32545338,Siqu Long,144179461,Josiah Poon,,,Computer Science,"JournalArticle, Conference"
164,Gender Inference using Statistical Name Characteristics in Twitter,"Much attention has been given to the task of gender inference of Twitter users. Although names are strong gender indicators, the names of Twitter users are rarely used as a feature; probably due to the high number of ill-formed names, which cannot be found in any name dictionary. Instead of relying solely on a name database, we propose a novel name classifier. Our approach extracts characteristics from the user names and uses those in order to assign the names to a gender. This enables us to classify international first names as well as ill-formed names.",International Conference on Multidisciplinary Social Networks Research,2016,27,23,1,True,"{'model': 'tldr@v2.0.0', 'text': 'This work proposes a novel name classifier that extracts characteristics from the user names and uses those in order to assign the names to a gender, which enables it to classify international first names as well as ill-formed names.'}",164,2110602409,Juergen Mueller,1705932,Gerd Stumme,,,,,,,,,Computer Science,"Book, JournalArticle"
165,Cross-Age Speaker Verification: Learning Age-Invariant Speaker Embeddings,"Automatic speaker veriﬁcation has achieved remarkable progress in recent years. However, there is little research on cross-age speaker veriﬁcation (CASV) due to insufﬁcient relevant data. In this paper, we mine cross-age test sets based on the VoxCeleb dataset and propose our age-invariant speaker repre-sentation(AISR) learning method. Since the VoxCeleb is collected from the YouTube platform, the dataset consists of cross-age data inherently. However, the meta-data does not contain the speaker age label. Therefore, we adopt the face age estimation method to predict the speaker age value from the as-sociated visual data, then label the audio recording with the estimated age. We construct multiple Cross-Age test sets on VoxCeleb (Vox-CA), which deliberately select the positive trials with large age-gap. Also, the effect of nationality and gender is considered in selecting negative pairs to align with Vox-H cases. The baseline system performance drops from 1.939% EER on the Vox-H test set to 10.419% on the Vox-CA20 test set, which indicates how difﬁcult the cross-age scenario is. Consequently, we propose an age-decoupling adversarial learning (ADAL) method to alleviate the negative effect of the age gap and reduce intra-class variance. Our method outperforms the baseline system by over 10% related EER reduction on the Vox-CA20 test set. The source code and trial resources are available on https://github.com/qinxiaoyi/Cross-Age Speaker Veriﬁcation.",Interspeech,2022,34,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper mine cross-age test sets based on the VoxCeleb dataset and proposes an age-invariant speaker repre-sentation(AISR) learning method to alleviate the negative effect of the age gap and reduce intra-class variance.'}",165,7710427,Xiaoyi Qin,2085129,N. Li,145350701,Chao Weng,144610227,Dan Su,2150652518,Ming Li,,,"Computer Science, Engineering",JournalArticle
166,"Nipping in the Bud: Detection, Diffusion and Mitigation of Hate Speech on Social Media","Since the proliferation of social media usage, hate speech has become a major crisis. Hateful content can spread quickly and create an environment of distress and hostility. Further, what can be considered hateful is contextual and varies with time. While online hate speech reduces the ability of already marginalised groups to participate in discussion freely, offline hate speech leads to hate crimes and violence against individuals and communities. The multifaceted nature of hate speech and its real-world impact have already piqued the interest of the data mining and machine learning communities. Despite our best efforts, hate speech remains an evasive issue for researchers and practitioners alike. This article presents methodological challenges that hinder building automated hate mitigation systems. These challenges inspired our work in the broader area of combating hateful content on the web. We discuss a series of our proposed solutions to limit the spread of hate speech on social media.",ArXiv,2022,35,3,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This article presents methodological challenges that hinder building automated hate mitigation systems and discusses a series of proposed solutions to limit the spread of hate speech on social media.'}",166,144054829,Tanmoy Chakraborty,,Sarah Masud,,,,,,,,,Computer Science,JournalArticle
167,DeepHate: Hate Speech Detection via Multi-Faceted Text Representations,"Online hate speech is an important issue that breaks the cohesiveness of online social communities and even raises public safety concerns in our societies. Motivated by this rising issue, researchers have developed many traditional machine learning and deep learning methods to detect hate speech in online social platforms automatically. However, most of these methods have only considered single type textual feature, e.g., term frequency, or using word embeddings. Such approaches neglect the other rich textual information that could be utilized to improve hate speech detection. In this paper, we propose DeepHate, a novel deep learning model that combines multi-faceted text representations such as word embeddings, sentiments, and topical information, to detect hate speech in online social platforms. We conduct extensive experiments and evaluate DeepHate on three large publicly available real-world datasets. Our experiment results show that DeepHate outperforms the state-of-the-art baselines on the hate speech detection task. We also perform case studies to provide insights into the salient features that best aid in detecting hate speech in online social platforms.",Web Science Conference,2020,51,44,2,True,"{'model': 'tldr@v2.0.0', 'text': 'DeepHate is a novel deep learning model that combines multi-faceted text representations such as word embeddings, sentiments, and topical information, to detect hate speech in online social platforms and outperforms the state-of-the-art baselines on the hate speech detection task.'}",167,2054884807,Rui Cao,38656724,R. Lee,11298055,Tuan-Anh Hoang,,,,,,,Computer Science,"Book, JournalArticle"
168,Using Artificial Intelligence to Recapture Norms: Did #metoo change gender norms in Sweden?,"Norms are challenging to define and measure, but this paper takes advantage of text data and the recent development in machine learning to create an encompassing measure of norms. An LSTM neural network is trained to detect gendered language. The network functions as a tool to create a measure on how gender norms changes in relation to the Metoo movement on Swedish Twitter. This paper shows that gender norms on average are less salient half a year after the date of the first appearance of the hashtag #Metoo. Previous literature suggests that gender norms change over generations, but the current result suggests that norms can change in the short run.",,2019,33,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is shown that gender norms on average are less salient half a year after the date of the first appearance of the hashtag #Metoo, suggesting that norms can change in the short run.'}",168,14302366,Sara Moricz,,,,,,,,,,,"Economics, Psychology",
169,Leveraging cross-platform data to improve automated hate speech detection,"Hate speech is increasingly prevalent online, and its negative outcomes include increased prejudice, extremism, and even offline hate crime. Automatic detection of online hate speech can help us to better understand these impacts. However, while the field has recently progressed through advances in natural language processing, challenges still remain. In particular, most existing approaches for hate speech detection focus on a single social media platform in isolation. This limits both the use of these models and their validity, as the nature of language varies from platform to platform. Here we propose a new cross-platform approach to detect hate speech which leverages multiple datasets and classification models from different platforms and trains a ‘superlearner’ that can combine existing and novel training data to improve detection and increase model applicability. We demonstrate how this approach outperforms existing models, and achieves good performance when tested on messages from novel social media platforms not included in the original training data.",ArXiv,2021,101,3,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This work proposes a new cross-platform approach to detect hate speech which leverages multiple datasets and classification models from different platforms and trains a ‘superlearner’ that can combine existing and novel training data to improve detection and increase model applicability.'}",169,2074327725,John D. Gallacher,,,,,,,,,,,Computer Science,JournalArticle
170,HateCheckHIn: Evaluating Hindi Hate Speech Detection Models,"Due to the sheer volume of online hate, the AI and NLP communities have started building models to detect such hateful content. Recently, multilingual hate is a major emerging challenge for automated detection where code-mixing or more than one language have been used for conversation in social media. Typically, hate speech detection models are evaluated by measuring their performance on the held-out test data using metrics such as accuracy and F1-score. While these metrics are useful, it becomes difficult to identify using them where the model is failing, and how to resolve it. To enable more targeted diagnostic insights of such multilingual hate speech models, we introduce a set of functionalities for the purpose of evaluation. We have been inspired to design this kind of functionalities based on real-world conversation on social media. Considering Hindi as a base language, we craft test cases for each functionality. We name our evaluation dataset HateCheckHIn. To illustrate the utility of these functionalities , we test state-of-the-art transformer based m-BERT model and the Perspective API.",International Conference on Language Resources and Evaluation,2022,33,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A set of functionalities is introduced to enable more targeted diagnostic insights of such multilingual hate speech models based on real-world conversation on social media and is named HateCheckHIn.'}",170,2000633372,Mithun Das,2042289364,Punyajoy Saha,2041989412,Binny Mathew,46405816,Animesh Mukherjee,,,,,Computer Science,JournalArticle
171,Deceiving Google's Perspective API Built for Detecting Toxic Comments,"Social media platforms provide an environment where people can freely engage in discussions. Unfortunately, they also enable several problems, such as online harassment. Recently, Google and Jigsaw started a project called Perspective, which uses machine learning to automatically detect toxic language. A demonstration website has been also launched, which allows anyone to type a phrase in the interface and instantaneously see the toxicity score [1]. In this paper, we propose an attack on the Perspective toxic detection system based on the adversarial examples. We show that an adversary can subtly modify a highly toxic phrase in a way that the system assigns significantly lower toxicity score to it. We apply the attack on the sample phrases provided in the Perspective website and show that we can consistently reduce the toxicity scores to the level of the non-toxic phrases. The existence of such adversarial examples is very harmful for toxic detection systems and seriously undermines their usability.",ArXiv,2017,20,230,17,False,"{'model': 'tldr@v2.0.0', 'text': 'It is shown that an adversary can subtly modify a highly toxic phrase in a way that the system assigns significantly lower toxicity score to it, and this attack can consistently reduce the toxicity scores to the level of the non-toxic phrases.'}",171,144909180,Hossein Hosseini,144097068,Sreeram Kannan,7504388,Baosen Zhang,144786412,R. Poovendran,,,,,Computer Science,JournalArticle
172,Complex Network Analysis of North American Institutions of Higher Education on Twitter,,International Workshop on Complex Networks & Their Applications,2020,16,0,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The structure of a network of 1,435 IHEs on Twitter is explored and the community structure of the network linked to homophily is uncovered -- such that similar followers follow similar colleges.'}",172,144180211,D. Zinoviev,1986118733,Shana Cote,144972367,Robert G. Diaz,,,,,,,"Computer Science, Sociology",JournalArticle
173,Los perfiles de investigación y su implantación en la Universidad Publica de Navarra,"This work aims to monitor and control the presence of UPNA research staff in the main research profiles platforms, not only in the most obvious ones such as Google Scholar Citation, Researcher ID, Scopus ID and ORCID, but also in other services that, in practice, they function as research profiles, such as Mendeley, Linkedin, ResearchGate, this http URL and Academica-e. We also find it interesting to analyze that presence and see how it responds to a variables, such as the department, gender, job category, research group. In this study we have excluded some platforms for different reasons. Dialnet profiles are entered from the UPNA library (BUPNA), which means that all those who meet the requirements for inclusion would be there, so their analysis does not make much sense, since it depends on factors outside the will of the researcher himself. The same is the case with the UPNA Scientific Production Portal (PPC): the data is entered from the Vicerrectorado de Investigacion and should include all members of the UPNA PDI. Using as a base the census of university research staff provided by the Vicerrectorado de Investigacion, it has been verified, for each author, the existence or not of a profile in the different services studied. The results have been tabulated in an Excel file to be able to analyze them later. The data has been collected in March 2018 for Orcid, ResearcherID, ScopusID, Google Scholar Citations and Mendeley. In November 2018, data from Academica-e, this http URL, ResearchGate and Linkedin were taken. For each of the profiles, a search by institutional affiliation was used, when possible, to obtain a first list of UPNA research personnel with that profile. Subsequently, a search was carried out, person by person, of the rest of the research staff that did not appear in that first list.",ArXiv,2020,0,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This work aims to monitor and control the presence of UPNA research staff in the main research profiles platforms, not only in the most obvious ones such as Google Scholar Citation, Researcher ID, Scopus ID and ORCID, but also in other services that function as research profiles, such as Mendeley, Linkedin, ResearchGate, this http URL and Academica-e.'}",173,1729516598,M. Peña,1729518544,Isabel Muñoz Mouriño,104389089,Mercedes Bogino Larrambebere,,,,,,,"Sociology, Computer Science",JournalArticle
174,"Arap-Tweet: A Large Multi-Dialect Twitter Corpus for Gender, Age and Language Variety Identification","In this paper, we present Arap-Tweet, which is a large-scale and multi-dialectal corpus of Tweets from 11 regions and 16 countries in the Arab world representing the major Arabic dialectal varieties. To build this corpus, we collected data from Twitter and we provided a team of experienced annotators with annotation guidelines that they used to annotate the corpus for age categories, gender, and dialectal variety. During the data collection effort, we based our search on distinctive keywords that are specific to the different Arabic dialects and we also validated the location using Twitter API. In this paper, we report on the corpus data collection and annotation efforts. We also present some issues that we encountered during these phases. Then, we present the results of the evaluation performed to ensure the consistency of the annotation. The provided corpus will enrich the limited set of available language resources for Arabic and will be an invaluable enabler for developing author profiling tools and NLP tools for Arabic.",International Conference on Language Resources and Evaluation,2018,34,53,6,False,"{'model': 'tldr@v2.0.0', 'text': 'Arap-Tweet is a large-scale and multi-dialectal corpus of Tweets from 11 regions and 16 countries in the Arab world representing the major Arabic dialectal varieties and a team of experienced annotators with annotation guidelines that they used to annotate the corpus for age categories, gender, and dialectal variety.'}",174,2034351,W. Zaghouani,3115402,A. Charfi,,,,,,,,,Computer Science,JournalArticle
175,Detecting Online Hate Speech: Approaches Using Weak Supervision and Network Embedding Models,,"International Conference on Social, Cultural, and Behavioral Modeling",2020,23,11,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work proposes a weak supervision deep learning model that quantitatively uncover hateful users and presents a novel qualitative analysis to uncover indirect hateful conversations, and utilizes the multilayer network embedding methods to generate features for the prediction task.'}",175,1833299655,Michael Ridenhour,144227173,A. Bagavathi,3422165,Elaheh Raisi,14317484,S. Krishnan,,,,,Computer Science,JournalArticle
176,An Examination of Demographic Differences in Obtaining Investment and Financial Planning Information,"Financial literacy and financial education are important components of modern life. The importance of financial literacy is increasing for financial consumers because of the weakening of both government and employer-based retirement systems. Unfortunately, empirical research shows that financial consumers are not fully informed and are not able to make proper choices even when appropriate information is available. More research is needed as to how financial consumers obtain investment and financial planning information. A primary data study was conducted to understand the differences between the demographic categories of gender, age, education-level, and income-level with the means of obtaining investment and financial planning information. In this research study, which selected a population from the LinkedIn platform, statistical differences between gender, age, education-level, and income-level were confirmed. These differences helped to confirm prior research in this field of study. Practical opportunities for commercial outreach to specific populations became evident through this type of research. Providers of investment and financial planning information can access their targeted audience more effectively by understanding the demographic profile of the audience, as well as the propensity of the demographic profile of the audience to respond. As this type of research is relatively easy to construct and administer, commercial outreach for providers of investment and financial planning information can be conducted in a cost-efficient and effective manner.",,2018,43,0,0,True,,176,2080120886,Paul Bechly,,,,,,,,,,,Economics,
177,CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech,"Although there is an unprecedented effort to provide adequate responses in terms of laws and policies to hate content on social media platforms, dealing with hatred online is still a tough problem. Tackling hate speech in the standard way of content deletion or user suspension may be charged with censorship and overblocking. One alternate strategy, that has received little attention so far by the research community, is to actually oppose hate content with counter-narratives (i.e. informed textual responses). In this paper, we describe the creation of the first large-scale, multilingual, expert-based dataset of hate-speech/counter-narrative pairs. This dataset has been built with the effort of more than 100 operators from three different NGOs that applied their training and expertise to the task. Together with the collected data we also provide additional annotations about expert demographics, hate and response type, and data augmentation through translation and paraphrasing. Finally, we provide initial experiments to assess the quality of our data.",Annual Meeting of the Association for Computational Linguistics,2019,59,101,9,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper describes the creation of the first large-scale, multilingual, expert-based dataset of hate-speech/counter-narrative pairs, built with the effort of more than 100 operators from three different NGOs that applied their training and expertise to the task.'}",177,3365740,Yi-Ling Chung,145459313,E. Kuzmenko,2034636,Serra Sinem Tekiroğlu,1912357,Marco Guerini,,,,,Computer Science,"JournalArticle, Conference"
178,Pricing the woman card: Gender politics between hillary clinton and donald trump,"In this paper, we introduce computer vision to the study of gender politics and present a data-driven method to measure the impact of the ‘woman card’ exchange between Hillary Clinton and Donald Trump. Building from a unique dataset of the two candidates' Twitter followers, we first examine the transition dynamics of the two candidates' Twitter followers one week before the exchange and one week after. Then we train a convolutional neural network to classify the gender of the followers and unfollowers, and study how women in particular are reacting to the ‘woman card’ exchange. Our study suggests that the ‘woman card’ comment has made women more likely to follow Hillary Clinton, less likely to unfollow her and that it has apparently not affected the gender composition of Trump followers.",2016 IEEE International Conference on Big Data (Big Data),2016,14,8,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The study suggests that the ‘woman card’ comment has made women more likely to follow Hillary Clinton, less likely to unfollow her and that it has apparently not affected the gender composition of Trump followers.'}",178,2153604061,Yu Wang,2115387758,Yang Feng,33642939,Jiebo Luo,2108216946,Xiyang Zhang,,,,,"Computer Science, Sociology","JournalArticle, Conference"
179,"Vindication, Virtue and Vitriol: A study of online engagement and abuse toward British MPs during the COVID-19 Pandemic","COVID-19 has given rise to malicious content online, including online abuse and hate toward British MPs. In order to understand and contextualise the level of abuse MPs receive, we consider how ministers use social media to communicate about the crisis, and the citizen engagement that this generates. The focus of the paper is on a large-scale, mixed methods study of abusive and antagonistic responses to UK politicians during the pandemic from early February to late May 2020. We find that pressing subjects such as financial concerns attract high levels of engagement, but not necessarily abusive dialogue. Rather, criticising authorities appears to attract higher levels of abuse. In particular, those who carry the flame for subjects like racism and inequality, may be accused of virtue signalling or receive higher abuse levels due to the topics they are required by their role to address. This work contributes to the wider understanding of abusive language online, in particular that which is directed at public officials.",ArXiv,2020,64,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is found that pressing subjects such as financial concerns attract high levels of engagement, but not necessarily abusive dialogue, which contributes to the wider understanding of abusive language online, in particular that which is directed at public officials.'}",179,145118333,T. Farrell,2448400,Genevieve Gorrell,1785423162,Kalina Bontcheva,,,,,,,"Computer Science, Political Science",JournalArticle
180,Modeling Profanity and Hate Speech in Social Media with Semantic Subspaces,"Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.",WOAH,2021,22,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This study identifies profane subspaces in word and sentence representations and explores their generalization capability on a variety of similar and distant target tasks in a zero-shot setting, and observes that the subspace-based representations transfer more effectively than standard BERT representations in the zero- shot setting.'}",180,144243797,Vanessa Hahn,1412830188,Dana Ruiter,1854885,Thomas Kleinbauer,2561225,D. Klakow,,,,,Computer Science,JournalArticle
181,A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models,"Objective. Chemical named entity recognition (NER) models have the potential to impact a wide range of downstream tasks, from identifying adverse drug reactions to general pharmacoepidemiology. However, it is unknown whether these models work the same for everyone. Performance disparities can potentially cause harm rather than the intended good. Hence, in this paper, we measure gender-related performance disparities of chemical NER systems. Materials and Methods. We develop a framework to measure gender bias in chemical NER models using synthetic data and a newly annotated dataset of over 92,405 words with self-identiﬁed gender information from Reddit. We applied and evaluated state-of-the-art biomedical NER models. Results. Our ﬁndings indicate that chemical NER models are biased. The results of the bias tests on the synthetic dataset and the real-world data multiple fairness issues. For example, for synthetic data, we ﬁnd that female-related names are generally classiﬁed as chemicals, particularly in datasets containing many brand names rather than standard ones. For both datasets, we ﬁnd consistent fairness issues resulting in substantial performance disparities between female- and male-related data. Discussion. Our study highlights the issue of biases in chemical NER models. For example, we ﬁnd that many systems cannot detect contraceptives (e.g., birth control). Conclusion. Chemical NER models are biased and can be harmful to female-related groups. Therefore, practitioners should carefully consider the potential biases of these models and take steps to mitigate them.",ArXiv,2022,52,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A framework to measure gender bias in chemical NER models is developed using synthetic data and a newly annotated dataset of over 92,405 words with self-identiﬁed gender information from Reddit, indicating that chemical N ER models are biased and can be harmful to female-related groups.'}",181,2159185818,Xingmeng Zhao,2080135557,A. Niazi,26355137,Anthony Rios,,,,,,,Computer Science,JournalArticle
182,Non-Binary Gender Expression in Online Interactions,"The presence of non-binary gender individuals in social networks is increasing; however, the relationship between gender and activity within online communities is not well understood and limited by the failures of automated gender recognition algorithms to recognize non-binary individuals. We use natural language processing to investigate individual identity on the Twitter platform, focusing on gender expression as represented by users' chosen pronouns from among 14 different pronoun groups. We find that non-binary groups tend to be more active on the platform, preferring to post messages rather than liking others' messages, compared to binary groups. Additionally, non-binary groups receive more replies, but their messages are reshared and liked less. We also find significant variation in the emotional expressions within non-binary groups. The study highlights the importance of considering gender as a spectrum, rather than a binary, in understanding online interactions and expression.",ArXiv,2023,34,0,0,False,"{'model': 'tldr@v2.0.0', 'text': ""It is found that non-binary groups tend to be more active on the Twitter platform, preferring to post messages rather than liking others' messages, compared to binary groups.""}",182,152955538,Rebecca Dorn,102319456,Julie Jiang,2145510728,Jeremy Abramson,2073018730,Kristina Lerman,,,,,Computer Science,JournalArticle
183,Hate Speech Classification Using SVM and Naive BAYES,"The spread of hatred that was formerly limited to verbal communications has rapidly moved over the Internet. Social media and community forums that allow people to discuss and express their opinions are becoming platforms for the spreading of hate messages. Many countries have developed laws to avoid online hate speech. They hold the companies that run the social media responsible for their failure to eliminate hate speech. But as online content continues to grow, so does the spread of hate speech However, manual analysis of hate speech on online platforms is infeasible due to the huge amount of data as it is expensive and time consuming. Thus, it is important to automatically process the online user contents to detect and remove hate speech from online media. Many recent approaches suffer from interpretability problem which means that it can be difficult to understand why the systems make the decisions they do. Through this work, some solutions for the problem of automatic detection of hate messages were proposed using Support Vector Machine (SVM) and Naïve Bayes algorithms. This achieved near state-of-the-art performance while being simpler and producing more easily interpretable decisions than other methods. Empirical evaluation of this technique has resulted in a classification accuracy of approximately 99% and 50% for SVM and NB respectively over the test set.",ArXiv,2022,34,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Through this work, some solutions for the problem of automatic detection of hate messages were proposed using Support Vector Machine (SVM) and Naïve Bayes algorithms, which achieved near state-of-the-art performance while being simpler and producing more easily interpretable decisions than other methods.'}",183,28317288,D. Asogwa,73054967,C. Chukwuneke,2162463683,C. C. Ngene,72964386,G. Anigbogu,,,,,Computer Science,JournalArticle
184,Reverse engineering socialbot infiltration strategies in Twitter,"Online Social Networks (OSNs) such as Twitter and Facebook have become a significant testing ground for Artificial Intelligence developers who build programs, known as socialbots, that imitate actual users by automating their social-network activities such as forming social links and posting content. Particularly, Twitter users have shown difficulties in distinguishing these socialbots from the human users in their social graphs. Frequently, legitimate users engage in conversations with socialbots. More impressively, socialbots are effective in acquiring human users as followers and exercising influence within them. While the success of socialbots is certainly a remarkable achievement for AI practitioners, their proliferation in the Twitter-sphere opens many possibilities for cybercrime. The proliferation of socialbots in the Twitter-sphere motivates us to assess the characteristics or strategies that make socialbots most likely to succeed. In this direction, we created 120 socialbot accounts in Twitter, which have a profile, follow other users, and generate tweets either by reposting messages that others have posted or by creating their own synthetic tweets. Then, we employ a 2k factorial design experiment in order to quantify the infiltration effectiveness of different socialbot strategies. Our analysis is the first of a kind, and reveals what strategies make socialbots successful in the Twitter-sphere.",International Conference on Advances in Social Networks Analysis and Mining,2014,68,140,11,True,"{'model': 'tldr@v2.0.0', 'text': 'This analysis is the first of a kind, and reveals what strategies make socialbots successful in the Twitter-sphere, and employs a 2k factorial design experiment to quantify the infiltration effectiveness of different socialbot strategies.'}",184,2060687854,C. Freitas,1869561,Fabrício Benevenuto,143841814,Saptarshi Ghosh,1685147,Adriano Veloso,,,,,"Computer Science, Physics","JournalArticle, Book, Conference"
185,Detecting Offensive Language in Tweets Using Deep Learning,,ArXiv,2018,21,129,9,True,"{'model': 'tldr@v2.0.0', 'text': 'A detection scheme that is an ensemble of Recurrent Neural Network (RNN) classifiers that incorporates various features associated with userrelated information, such as the users’ tendency towards racism or sexism, and it can successfully distinguish racism and sexism messages from normal text, and achieve higher classification quality than current state-of-the-art algorithms.'}",185,3452522,Georgios K. Pitsilis,1808315,H. Ramampiaro,3310967,H. Langseth,,,,,,,Computer Science,JournalArticle
186,Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay of Human and Algorithmic Biases in Online Hiring,"Ranking algorithms are being widely employed in various online hiring platforms including LinkedIn, TaskRabbit, and Fiverr. Prior research has demonstrated that ranking algorithms employed by these platforms are prone to a variety of undesirable biases, leading to the proposal of fair ranking algorithms (e.g., Det-Greedy) which increase exposure of underrepresented candidates. However, there is little to no work that explores whether fair ranking algorithms actually improve real world outcomes (e.g., hiring decisions) for underrepresented groups. Furthermore, there is no clear understanding as to how other factors (e.g., job context, inherent biases of the employers) may impact the efficacy of fair ranking in practice. In this work, we analyze various sources of gender biases in online hiring platforms, including the job context and inherent biases of employers and establish how these factors interact with ranking algorithms to affect hiring decisions. To the best of our knowledge, this work makes the first attempt at studying the interplay between the aforementioned factors in the context of online hiring. We carry out a large-scale user study simulating online hiring scenarios with data from TaskRabbit, a popular online freelancing site. Our results demonstrate that while fair ranking algorithms generally improve the selection rates of underrepresented minorities, their effectiveness relies heavily on the job contexts and candidate profiles.","AAAI/ACM Conference on AI, Ethics, and Society",2020,30,22,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The results demonstrate that while fair ranking algorithms generally improve the selection rates of underrepresented minorities, their effectiveness relies heavily on the job contexts and candidate profiles.'}",186,134810739,Tom Sühr,67233765,Sophie Hilgard,1892673,Himabindu Lakkaraju,,,,,,,Computer Science,"JournalArticle, Book"
187,Will Sanders Supporters Jump Ship for Trump? Fine-grained Analysis of Twitter Followers,"In this paper, we study the likelihood of Bernie Sanders supporters voting for Donald Trump instead of Hillary Clinton. Building from a unique time-series dataset of the three candidates' Twitter followers, which we make public here, we first study the proportion of Sanders followers who simultaneously follow Trump (but not Clinton) and how this evolves over time. Then we train a convolutional neural network to classify the gender of Sanders followers, and study whether men are more likely to jump ship for Trump than women. Our study shows that between March and May an increasing proportion of Sanders followers are following Trump (but not Clinton). The proportion of Sanders followers who follow Clinton but not Trump has actually decreased. Equally important, our study suggests that the jumping ship behavior will be affected by gender and that men are more likely to switch to Trump than women.",ArXiv,2016,13,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This study shows that between March and May an increasing proportion of Sanders followers are following Trump (but not Clinton), and suggests that the jumping ship behavior will be affected by gender and that men are more likely to switch to Trump than women.'}",187,2153604061,Yu Wang,2115387758,Yang Feng,2108216946,Xiyang Zhang,2288882,R. Niemi,33642939,Jiebo Luo,,,"Computer Science, Sociology",JournalArticle
188,Exploring and Mitigating Gender Bias in Recommender Systems with Explicit Feedback,"Recommender systems are indispensable because they influence our day-to-day behavior and decisions by giving us personalized suggestions. Services like Kindle, Youtube, and Netflix depend heavily on the performance of their recommender systems to ensure that their users have a good experience and to increase revenues. Despite their popularity, it has been shown that recommender systems reproduce and amplify the bias present in the real world. The resulting feedback creates a selfperpetuating loop that deteriorates the user experience and results in homogenizing recommendations over time. Further, biased recommendations can also reinforce stereotypes based on gender or ethnicity, thus reinforcing the filter bubbles that we live in. In this paper, we address the problem of gender bias in recommender systems with explicit feedback. We propose a model to quantify the gender bias present in book rating datasets and in the recommendations produced by the recommender systems. Our main contribution is to provide a principled approach to mitigate the bias being produced in the recommendations. We theoretically show that the proposed approach provides unbiased recommendations despite biased data. Through empirical evaluation on publicly available book rating datasets, we further show that the proposed model can significantly reduce bias without significant impact on accuracy. Our method is model agnostic and can be applied to any recommender system. To demonstrate the performance of our model, we present the results on four recommender algorithms, two from the K-nearest neighbors family, UserKNN and ItemKNN, and the other two from the matrix factorization family, Alternating least square and Singular value decomposition.",ArXiv,2021,33,5,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes a model to quantify the gender bias present in book rating datasets and in the recommendations produced by the recommender systems, and theoretically shows that the proposed approach provides unbiased recommendations despite biased data.'}",188,2119146760,Shrikant Saxena,8126815,Shweta Jain,,,,,,,,,Computer Science,JournalArticle
189,Gender Bias in Sharenting: Both Men and Women Mention Sons More Often Than Daughters on Social Media,"Gender inequality starts before birth. Parents tend to prefer boys over girls, which is manifested in reproductive behavior, marital life, and parents’ pastimes and investments in their children. While social media and sharing information about children (so-called “sharenting”) have become an integral part of parenthood, it is not well-known if and how gender preference shapes online behavior of users. In this paper, we investigate public mentions of daughters and sons on social media. We use data from a popular social networking site on public posts from 635,665 users. We find that both men and women mention sons more often than daughters in their posts. We also find that posts featuring sons get more “likes” on average. Our results indicate that girls are underrepresented in parents’ digital narratives about their children. This gender imbalance may send a message that girls are less important than boys, or that they deserve less attention, thus reinforcing gender inequality.",ArXiv,2018,42,5,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper investigates public mentions of daughters and sons on social media and finds that both men and women mention sons more often than daughters in their posts, indicating that girls are underrepresented in parents’ digital narratives about their children.'}",189,40894019,E. Sivak,2057782666,I. Smirnov,,,,,,,,,"Computer Science, Physics",JournalArticle
190,The Effects of Gender Signals and Performance in Online Product Reviews,"This work quantifies the effects of signaling gender through gender specific user names, on the success of reviews written on the popular amazon.com shopping platform. Highly rated reviews play an important role in e-commerce since they are prominently displayed next to products. Differences in reviews, perceived—consciously or unconsciously—with respect to gender signals, can lead to crucial biases in determining what content and perspectives are represented among top reviews. To investigate this, we extract signals of author gender from user names to select reviews where the author’s likely gender can be inferred. Using reviews authored by these gender-signaling authors, we train a deep learning classifier to quantify the gendered writing style (i.e., gendered performance) of reviews written by authors who do not send clear gender signals via their user name. We contrast the effects of gender signaling and performance on the review helpfulness ratings using matching experiments. This is aimed at understanding if an advantage is to be gained by (not) signaling one’s gender when posting reviews. While we find no general trend that gendered signals or performances influence overall review success, we find strong context-specific effects. For example, reviews in product categories such as Electronics or Computers are perceived as less helpful when authors signal that they are likely woman, but are received as more helpful in categories such as Beauty or Clothing. In addition to these interesting findings, we believe this general chain of tools could be deployed across various social media platforms.",Frontiers in Big Data,2020,61,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work quantifies the effects of signaling gender through gender specific user names, on the success of reviews written on the popular amazon.com shopping platform and finds strong context-specific effects.'}",190,2632448,Sandipan Sikdar,1490892639,Rachneet Sachdeva,39963117,Johannes Wachs,2101037,F. Lemmerich,1743043,M. Strohmaier,,,"Computer Science, Medicine, Psychology","JournalArticle, Review"
191,ToxVis: Enabling Interpretability of Implicit vs. Explicit Toxicity Detection Models with Interactive Visualization,"The rise of hate speech on online platforms has led to an urgent need for effective content moderation. However, the subjective and multi-faceted nature of hateful online content, including implicit hate speech, poses significant challenges to human moderators and content moderation systems. To address this issue, we developed ToxVis, a visually interactive and explainable tool for classifying hate speech into three categories: implicit, explicit, and non-hateful. We fine-tuned two transformer-based models using RoBERTa, XLNET, and GPT-3 and used deep learning interpretation techniques to provide explanations for the classification results. ToxVis enables users to input potentially hateful text and receive a classification result along with a visual explanation of which words contributed most to the decision. By making the classification process explainable, ToxVis provides a valuable tool for understanding the nuances of hateful content and supporting more effective content moderation. Our research contributes to the growing body of work aimed at mitigating the harms caused by online hate speech and demonstrates the potential for combining state-of-the-art natural language processing models with interpretable deep learning techniques to address this critical issue. Finally, ToxVis can serve as a resource for content moderators, social media platforms, and researchers working to combat the spread of hate speech online.",,2023,12,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'ToxVis, a visually interactive and explainable tool for classifying hate speech into three categories: implicit, explicit, and non-hateful, is developed and demonstrates the potential for combining state-of-the-art natural language processing models with interpretable deep learning techniques to address this critical issue.'}",191,2078502250,U. Gunturi,144703574,Xi Ding,10741193,E. H. Rho,,,,,,,Computer Science,
192,Pretty Princess vs. Successful Leader: Gender Roles in Greeting Card Messages,"People write personalized greeting cards on various occasions. While prior work has studied gender roles in greeting card messages, systematic analysis at scale and tools for raising the awareness of gender stereotyping remain under-investigated. To this end, we collect a large greeting card message corpus covering three different occasions (birthday, Valentine’s Day and wedding) from three sources (exemplars from greeting message websites, real-life greetings from social media and language model generated ones). We uncover a wide range of gender stereotypes in this corpus via topic modeling, odds ratio and Word Embedding Association Test (WEAT). We further conduct a survey to understand people’s perception of gender roles in messages from this corpus and if gender stereotyping is a concern. The results show that people want to be aware of gender roles in the messages, but remain unconcerned unless the perceived gender roles conflict with the recipient’s true personality. In response, we developed GreetA, an interactive visualization and writing assistant tool to visualize fine-grained topics in greeting card messages drafted by the users and the associated gender perception scores, but without suggesting text changes as an intervention.",International Conference on Human Factors in Computing Systems,2021,55,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'GreetA, an interactive visualization and writing assistant tool to visualize fine-grained topics in greeting card messages drafted by the users and the associated gender perception scores, is developed without suggesting text changes as an intervention.'}",192,2128089588,Jiao Sun,35232494,Tongshuang Sherry Wu,2142454943,Yue Jiang,2148480172,Ronil Awalegaonkar,143724481,Xi Victoria Lin,2143919864,Diyi Yang,Computer Science,"Book, JournalArticle, Conference, Review"
193,Computer Vision and Conflicting Values: Describing People with Automated Alt Text,"Scholars have recently drawn attention to a range of controversial issues posed by the use of computer vision for automatically generating descriptions of people in images. Despite these concerns, automated image description has become an important tool to ensure equitable access to information for blind and low vision people. In this paper, we investigate the ethical dilemmas faced by companies that have adopted the use of computer vision for producing alt text: textual descriptions of images for blind and low vision people. We use Facebook's automatic alt text tool as our primary case study. First, we analyze the policies that Facebook has adopted with respect to identity categories, such as race, gender, age, etc., and the company's decisions about whether to present these terms in alt text. We then describe an alternative---and manual---approach practiced in the museum community, focusing on how museums determine what to include in alt text descriptions of cultural artifacts. We compare these policies, using notable points of contrast to develop an analytic framework that characterizes the particular apprehensions behind these policy choices. We conclude by considering two strategies that seem to sidestep some of these concerns, finding that there are no easy ways to avoid the normative dilemmas posed by the use of computer vision to automate alt text.","AAAI/ACM Conference on AI, Ethics, and Society",2021,67,7,0,True,"{'model': 'tldr@v2.0.0', 'text': ""This paper analyzes the policies that Facebook has adopted with respect to identity categories, such as race, gender, age, etc., and the company's decisions about whether to present these terms in alt text, and describes an alternative---and manual---approach practiced in the museum community, focusing on how museums determine what to include in altText descriptions of cultural artifacts.""}",193,121178369,Margot Hanley,2881033,Solon Barocas,144463523,K. Levy,3283573,Shiri Azenkot,2994505,H. Nissenbaum,,,Computer Science,"JournalArticle, Book"
194,Whose Opinions Matter? Perspective-aware Models to Identify Opinions of Hate Speech Victims in Abusive Language Detection,"Social media platforms provide users the freedom of expression and a medium to exchange information and express diverse opinions. Unfortunately, this has also resulted in the growth of abusive content with the purpose of discriminating people and targeting the most vulnerable communities such as immigrants, LGBT, Muslims, Jews and women. Because abusive language is subjective in nature, there might be highly polarizing topics or events involved in the annotation of abusive contents such as hate speech (HS). Therefore, we need novel approaches to model conflicting perspectives and opinions coming from people with different personal and demographic backgrounds. In this paper, we present an in-depth study to model polarized opinions coming from different communities under the hypothesis that similar characteristics (ethnicity, social background, culture etc.) can influence the perspectives of annotators on a certain phenomenon. We believe that by relying on this information, we can divide the annotators into groups sharing similar perspectives. We can create separate gold standards, one for each group, to train state-of-the-art deep learning models. We can employ an ensemble approach to combine the perspective-aware classifiers from different groups to an inclusive model. We also propose a novel resource, a multi-perspective English language dataset annotated according to different sub-categories relevant for characterising online abuse: hate speech, aggressiveness, offensiveness and stereotype. Unlike our previous work, where the annotations were based on crowd-sourcing, here, we involved the victims of targeted communities in the annotation process, who volunteered to annotate the dataset, providing a natural selection of the annotator groups based on their personal characteristics. By training state-of-the-art deep learning models on this novel resource, we show how our approach improves the prediction performance of a state-of-the-art supervised classifier. Moreover, we also perform an in-depth qualitative analysis of the novel dataset to identify and understand the relevant keywords, topics and events causing polarization among the annotators in expressed opinions.",ArXiv,2021,55,11,2,False,"{'model': 'tldr@v2.0.0', 'text': 'An in-depth study to model polarized opinions coming from different communities under the hypothesis that similar characteristics can influence the perspectives of annotators on a certain phenomenon, and how this approach improves the prediction performance of a state-of-the-art supervised classifier.'}",194,49181304,S. Akhtar,3101511,Valerio Basile,1787198,V. Patti,,,,,,,Computer Science,JournalArticle
195,Identification of Bias Against People with Disabilities in Sentiment Analysis and Toxicity Detection Models,"Sociodemographic biases are a common problem for natural language processing, affecting the fairness and integrity of its applications. Within sentiment analysis, these biases may undermine sentiment predictions for texts that mention personal attributes that unbiased human readers would consider neutral. Such discrimination can have great consequences in the applications of sentiment analysis both in the public and private sectors. For example, incorrect inferences in applications like online abuse and opinion analysis in social media platform can lead to unwanted ramifications, such as wrongful censoring, towards certain populations. In this paper, we address the discrimination against people with disabilities, PWD, done by sentiment analysis and toxicity classification models. We provide an examination of sentiment and toxicity analysis models to understand in detail how they discriminate PWD. We present Bias Identification Test in Sentiments (BITS), a corpus of 1,126 sentences designed to probe sentiment analysis models for biases in disability. We use this corpus to demonstrate statistically significant biases in four widely used sentiment analysis tools (TextBlob, VADER, Google Cloud Natural Language API and DistilBERT) and two toxicity analysis models trained to predict toxic comments on Jigsaw challenges (Toxic comment classification and Unintended Bias in Toxic comments). The results show that all exhibit strong negative biases on sentences that mention disability. We publicly release BITS Corpus for others to identify potential biases against disability in any sentiment analysis tools and also to update the corpus to be used as a test for other sociodemographic variables as well.",,2021,57,6,2,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper provides an examination of sentiment and toxicity analysis models to understand in detail how they discriminate PWD, and presents Bias Identification Test in Sentiments (BITS), a corpus of 1,126 sentences designed to probe sentiment analysis models for biases in disability.'}",195,2053812167,Pranav Venkit,31950200,Shomir Wilson,,,,,,,,,Computer Science,
196,"Who are Political Retweeters?, Demographic comparison of political retweeters with retweeters of non-political personalities","Twitter has been a focus of research in political science for a few years now as it provides the opportunity to make direct observations on the spread of political information in different communities. Here we will be studying the phenomena of information diffusion, and focus on nodes that are responsible for spreading political information everywhere on the Twitter network. This paper attempts to fill gaps in the literature regarding the demographics of political retweeters using various techniques on the name and location-related data from most active French political retweeters. Here I will try to state the break-down of these accounts in categories based on gender, language, location, education level, and self-descriptions. To put the information about political retweeters in context we will also create a category of non-political retweeters to draw comparisons between the groups regarding the above-mentioned variables.",ArXiv,2020,11,0,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper attempts to fill gaps in the literature regarding the demographics of political retweeters using various techniques on the name and location-related data from most active French political retweeting accounts.'}",196,1630371314,Muhammad Umer Gurchani,,,,,,,,,,,"Computer Science, Political Science",JournalArticle
197,Multilingual Twitter Corpus and Baselines for Evaluating Demographic Bias in Hate Speech Recognition,"Existing research on fairness evaluation of document classification models mainly uses synthetic monolingual data without ground truth for author demographic attributes. In this work, we assemble and publish a multilingual Twitter corpus for the task of hate speech detection with inferred four author demographic factors: age, country, gender and race/ethnicity. The corpus covers five languages: English, Italian, Polish, Portuguese and Spanish. We evaluate the inferred demographic labels with a crowdsourcing platform, Figure Eight. To examine factors that can cause biases, we take an empirical analysis of demographic predictability on the English corpus. We measure the performance of four popular document classifiers and evaluate the fairness and bias of the baseline classifiers on the author-level demographic attributes.",International Conference on Language Resources and Evaluation,2020,55,52,9,False,"{'model': 'tldr@v2.0.0', 'text': 'This work assemble and publish a multilingual Twitter corpus for the task of hate speech detection with inferred four author demographic factors: age, country, gender and race/ethnicity, and measures the performance of four popular document classifiers and evaluates the fairness and bias of the baseline classifiers on the author-level demographic attributes.'}",197,144007496,Xiaolei Huang,15493820,Linzi Xing,2462276,Franck Dernoncourt,143946641,Michael J. Paul,,,,,Computer Science,JournalArticle
198,Wav2Pix: Speech-conditioned Face Generation Using Generative Adversarial Networks,"Speech is a rich biometric signal that contains information about the identity, gender and emotional state of the speaker. In this work, we explore its potential to generate face images of a speaker by conditioning a Generative Adversarial Network (GAN) with raw speech input. We propose a deep neural network that is trained from scratch in an end-to-end fashion, generating a face directly from the raw speech waveform without any additional identity information (e.g reference image or one-hot encoding). Our model is trained in a self-supervised approach by exploiting the audio and visual signals naturally aligned in videos. With the purpose of training from video data, we present a novel dataset collected for this work, with high-quality videos of youtubers with notable expressiveness in both the speech and visual signals.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2019,31,57,4,True,"{'model': 'tldr@v2.0.0', 'text': 'A deep neural network is proposed that is trained from scratch in an end-to-end fashion, generating a face directly from the raw speech waveform without any additional identity information (e.g reference image or one-hot encoding).'}",198,1381525702,A. Duarte,153738374,Francisco Roldan,118129922,Miquel Tubau,115672881,Janna Escur,2074982546,Santiago Pascual,31571033,Amaia Salvador,Computer Science,"JournalArticle, Conference"
199,RedditBias: A Real-World Resource for Bias Evaluation and Debiasing of Conversational Language Models,"Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification. Recent work has predominantly focused on measuring and mitigating bias in pretrained language models. Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final perfor mance in dialog tasks, e.g., conversational response generation. In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender,race,religion, and queerness. Further, we develop an evaluation framework which simultaneously 1)measures bias on the developed REDDITBIAS resource, and 2)evaluates model capability in dialog tasks after model debiasing. We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods. Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.",Annual Meeting of the Association for Computational Linguistics,2021,57,45,4,True,"{'model': 'tldr@v2.0.0', 'text': 'RedDITBIAS is presented, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness, and an evaluation framework is developed.'}",199,2107062845,Soumya Barikeri,29891652,Anne Lauscher,1747849,Ivan Vulic,2472657,Goran Glavas,,,,,Computer Science,"JournalArticle, Conference"
200,Exploring the contextual factors affecting multimodal emotion recognition in videos,"Emotional expressions form a key part of user behavior on today's digital platforms. While multimodal emotion recognition techniques are gaining research attention, there is a lack of deeper understanding on how visual and non-visual features can be used to better recognize emotions in certain contexts, but not others. This study analyzes the interplay between the effects of multimodal emotion features derived from facial expressions, tone and text in conjunction with two key contextual factors: i) gender of the speaker, and ii) duration of the emotional episode. Using a large public dataset of 2,176 manually annotated YouTube videos, we found that while multimodal features consistently outperformed bimodal and unimodal features, their performance varied significantly across different emotions, gender and duration contexts. Multimodal features performed particularly better for male speakers in recognizing most emotions. Furthermore, multimodal features performed particularly better for shorter than for longer videos in recognizing neutral and happiness, but not sadness and anger. These findings offer new insights towards the development of more context-aware emotion recognition and empathetic systems.",,2020,90,5,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This study analyzes the interplay between the effects of multimodal emotion features derived from facial expressions, tone and text in conjunction with two key contextual factors: i) gender of the speaker, and ii) duration of the emotional episode.'}",200,2598614,Prasanta Bhattacharya,2110345324,R. Gupta,40341306,Yinping Yang,,,,,,,"Computer Science, Psychology",
201,Toward Understanding Friendship in Online Social Networks,"All major on-line social networks, such as MySpace, Facebook, LiveJournal, and Orkut, are built around the concept of friendship. It is not uncommon for a social network participant to have over 100 friends. A natural question arises: are they all real friends of hers, or does she mean something different when she calls them ""friends?"" Speaking in other words, what is the relationship between off-line (real, traditional) friendship and its on-line (virtual) namesake? In this paper, we use sociological data to suggest that there is a significant difference between the concepts of virtual and real friendships. We further investigate the structure of on-line friendship and observe that it follows the Pareto (or double Pareto) distribution and is subject to age stratification but not to gender segregation. We introduce the concept of digital personality that quantifies the willingness of a social network participant to engage in virtual friendships.",ArXiv,2009,14,19,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper uses sociological data to suggest that there is a significant difference between the concepts of virtual and real friendships, and introduces the concept of digital personality that quantifies the willingness of a social network participant to engage in virtual friendships.'}",201,144180211,D. Zinoviev,143834988,Vy T Duong,,,,,,,,,"Sociology, Computer Science, Psychology",JournalArticle
202,Estimating clique composition and size distributions from sampled network data,"Cliques are defined as complete graphs or subgraphs; they are the strongest form of cohesive subgroup, and are of interest in both social science and engineering contexts. In this paper we show how to efficiently estimate the distribution of clique sizes from a probability sample of nodes obtained from a graph (e.g., by independence or link-trace sampling). We introduce two types of unbiased estimators, one of which exploits labeling of sampled nodes neighbors and one of which does not require this information. This is the first work to present statistically principled design-based estimators for clique distributions in arbitrary graphs using sampled network data. We generalize our estimators to cases in which cliques are distinguished not only by size but also by node attributes, allowing us to estimate clique composition by size. Last, we compare our estimators on a variety of real-world graphs and provide suggestions for their use.",Conference on Computer Communications Workshops,2013,46,20,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This is the first work to present statistically principled design-based estimators for clique distributions in arbitrary graphs using sampled network data and generalizes their estimators to cases in which cliques are distinguished not only by size but also by node attributes, allowing us to estimate clique composition by size.'}",202,2752625,Minas Gjoka,50874070,Emily Smith,3014984,C. Butts,,,,,,,"Computer Science, Mathematics, Physics","JournalArticle, Conference"
203,"Algorithms that ""Don't See Color"": Measuring Biases in Lookalike and Special Ad Audiences","Researchers and journalists have repeatedly shown that algorithms commonly used in domains such as credit, employment, healthcare, or criminal justice can have discriminatory effects. Some organizations have tried to mitigate these effects by simply removing sensitive features from an algorithm's inputs. In this paper, we explore the limits of this approach using a unique opportunity. In 2019, Facebook agreed to settle a lawsuit by removing certain sensitive features from inputs of an algorithm that identifies users similar to those provided by an advertiser for ad targeting, making both the modified and unmodified versions of the algorithm available to advertisers. We develop methodologies to measure biases along the lines of gender, age, and race in the audiences created by this modified algorithm, relative to the unmodified one. Our results provide experimental proof that merely removing demographic features from a real-world algorithmic system's inputs can fail to prevent biased outputs. As a result, organizations using algorithms to help mediate access to important life opportunities should consider other approaches to mitigating discriminatory effects.","AAAI/ACM Conference on AI, Ethics, and Society",2019,55,13,1,True,"{'model': 'tldr@v2.0.0', 'text': ""Results provide experimental proof that merely removing demographic features from a real-world algorithmic system's inputs can fail to prevent biased outputs, and organizations using algorithms to help mediate access to important life opportunities should consider other approaches to mitigating discriminatory effects.""}",203,2098911,Piotr Sapiezynski,47581570,A. Ghosh,2059239828,Lev Kaplan,1729928,A. Mislove,93374290,A. Rieke,,,Computer Science,"JournalArticle, Book"
204,User Profiling Using Smartphone Network Traffic Analysis,"The recent decade has witnessed phenomenal growth in communication technology. Development of user friendly software platforms, such as Facebook, WhatsApp etc. have facilitated ease of communication and thereby people have started freely sharing messages and multimedia over the Internet. Further, there is a shift in trends with services being accessed from smartphones over personal computers. To protect the security and privacy of the smartphone users, most of the applications use encryption that encapsulates communications over the Internet. However, research has shown that the statistical information present in a traffic can be used to identify the application, and further, the activity performed by the user inside that application. In this paper, we extend the scope of analysis by proposing a learning framework to leverage application and activity data to profile smartphone users in terms of their gender, profession age group etc. This will greatly help the authoritative agencies to conduct their investigations related to national security and other purposes.",International Conference on Communication Systems and Networks,2020,19,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes a learning framework to leverage application and activity data to profile smartphone users in terms of their gender, profession age group etc. to help the authoritative agencies to conduct their investigations related to national security and other purposes.'}",204,31727118,Ayush Bahuguna,2993136,Ashutosh Bhatia,145157445,Kamlesh Tiwari,49243271,D. Vishwakarma,,,,,Computer Science,"JournalArticle, Conference"
205,Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis,"Some users of social media are spreading racist, sexist, and otherwise hateful content. For the purpose of training a hate speech detection system, the reliability of the annotations is crucial, but there is no 
universally agreed-upon definition. We collected potentially hateful messages and asked two groups of internet users to determine 
whether they were hate speech or not, whether they should be banned or not and to rate their degree of offensiveness. One of the groups was shown a definition prior to completing the survey. We aimed to assess whether hate speech can be annotated reliably, and the extent to which existing definitions are in accordance with subjective ratings. Our results indicate that showing users a definition caused them to partially align their own opinion with the definition but did not improve reliability, which was very low overall. We conclude that the presence of hate speech should perhaps 
not be considered a binary yes-or-no decision, and raters need more detailed instructions for the annotation.",ArXiv,2016,11,305,24,False,"{'model': 'tldr@v2.0.0', 'text': 'It is concluded that the presence of hate speech should perhaps not be considered a binary yes-or-no decision, and raters need more detailed instructions for the annotation, which was very low overall.'}",205,26234127,Björn Ross,2074989296,Michael Rist,2072475370,Guillermo Carbonell,11289633,Benjamin Cabrera,8803928,Nils Kurowsky,3321718,Michael Wojatzki,"Computer Science, Psychology","JournalArticle, Review"
206,On the Dynamics of Local to Global Campaigns for Curbing Gender-based Violence,"Gender-based violence (GBV) is a human-generated crisis, existing in various forms, including offline, via physical and sexual violence, and now online via harassment and trolling. While studying social media campaigns for different domains such as public health, natural crises, etc. has received attention in the literature, such studies for GBV are still in nascent form. The dynamics of campaigns responding to curb this crisis could benefit from systematic investigation. To our knowledge, this is the first study to examine such public campaigns involving social media by organizations operating at the local, national and global levels, with an eye to answering the following research questions: (1) How do members of one campaign community engage with other campaign communities? (2) How do demographic variables such as gender effect campaign engagement in light of given regional crime statistics? (3) Is there any coordination among organizational users for campaigns with similar underlying social causes?",ArXiv,2016,40,3,1,False,,206,3451639,P. Karuna,7147418,Hemant Purohit,3451346,B. Stabile,3451790,Angela J. Hattery,,,,,"Political Science, Computer Science",JournalArticle
207,Sentence-Level BERT and Multi-Task Learning of Age and Gender in Social Media,"Social media currently provide a window on our lives, making it possible to learn how people from different places, with different backgrounds, ages, and genders use language. In this work we exploit a newly-created Arabic dataset with ground truth age and gender labels to learn these attributes both individually and in a multi-task setting at the sentence level. Our models are based on variations of deep bidirectional neural networks. More specifically, we build models with gated recurrent units and bidirectional encoder representations from transformers (BERT). We show the utility of multi-task learning (MTL) on the two tasks and identify task-specific attention as a superior choice in this context. We also find that a single-task BERT model outperform our best MTL models on the two tasks. We report tweet-level accuracy of 51.43% for the age task (three-way) and 65.30% on the gender task (binary), both of which outperforms our baselines with a large margin. Our models are language-agnostic, and so can be applied to other languages.",ArXiv,2019,68,4,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This work exploits a newly-created Arabic dataset with ground truth age and gender labels to learn these attributes both individually and in a multi-task setting at the sentence level, and builds models with gated recurrent units and bidirectional encoder representations from transformers (BERT).'}",207,1388437494,Muhammad Abdul-Mageed,50445559,Chiyu Zhang,2140095,Arun Rajendran,1397289779,AbdelRahim Elmadany,52349140,Michael Przystupa,1412391493,L. Ungar,Computer Science,JournalArticle
208,Using Sentiment Representation Learning to Enhance Gender Classification for User Profiling,,APWeb/WAIM,2018,32,2,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A Sentiment Representation Learning based Multi-Layer Perceptron (SRL-MLP) model to classify gender is proposed and results show that this approach can improve gender classification accuracy by 5.53\\%, from 84.20\\% to 89.73\\%.'}",208,1391155457,Yunpei Zheng,2109136926,Lin Li,2112683049,Luo Zhong,1739414,Jianwei Zhang,71776766,Jinhang Liu,,,Computer Science,"JournalArticle, Review"
209,Face Off: Polarized Public Opinions on Personal Face Mask Usage during the COVID-19 Pandemic,"In spite of a growing body of scientific evidence on the effectiveness of individual face mask usage for reducing transmission rates [1], individual face mask usage has become a highly polarized topic within the United States. A series of policy shifts by various governmental bodies have been speculated to have contributed to the polarization of face masks. A typical method to investigate the effects of these policy shifts is to use surveys. However, survey-based approaches have multiple limitations: biased responses, limited sample size, badly crafted questions may skew responses and inhibit insight, and responses may prove quickly irrelevant as opinions change in response to a dynamic topic. We propose a novel approach to 1) accurately gauge public sentiment towards face masks in the United States during COVID-19 using a multi-modal demographic inference framework with topic modeling and 2) determine whether face mask policy shifts contributed to polarization towards face masks using offline change point analysis on Twitter data. First, we infer several key demographics of individual Twitter users such as their age, gender, and whether they are a college student using a multi-modal demographic prediction framework and analyze the average sentiment for each respective demographic. Next, we conduct topic analysis using latent Dirichlet allocation (LDA). Finally, we conduct offline change point discovery on our sentiment time series data using the Pruned Exact Linear Time (PELT) search algorithm. Experimental results on a large corpus of Twitter data reveal multiple insights regarding demographic sentiment towards face masks that agree with existing surveys. Furthermore, we find two key policy-shift events contributed to statistically significant changes in sentiment for both Republicans and Democrats.",2020 IEEE International Conference on Big Data (Big Data),2020,25,17,1,True,"{'model': 'tldr@v2.0.0', 'text': 'A novel approach to accurately gauge public sentiment towards face masks in the United States during COVID-19 using a multi-modal demographic inference framework with topic modeling and determine whether face mask policy shifts contributed to polarization towards face mask using offline change point analysis on Twitter data is proposed.'}",209,2007011382,Neil Yeung,2072610800,J. Lai,33642939,Jiebo Luo,,,,,,,Computer Science,"JournalArticle, Conference, Review"
210,Demographic Representation and Collective Storytelling in the Me Too Twitter Hashtag Activism Movement,"The #MeToo movement on Twitter has drawn attention to the pervasive nature of sexual harassment and violence. While #MeToo has been praised for providing support for self-disclosures of harassment or violence and shifting societal response, it has also been criticized for exemplifying how women of color have been discounted for their historical contributions to and excluded from feminist movements. Through an analysis of over 600,000 tweets from over 256,000 unique users, we examine online #MeToo conversations across gender and racial/ethnic identities and the topics that each demographic emphasized. We found that tweets authored by white women were overrepresented in the movement compared to other demographics, aligning with criticism of unequal representation. We found that intersected identities contributed differing narratives to frame the movement, co-opted the movement to raise visibility in parallel ongoing movements, employed the same hashtags both critically and supportively, and revived and created new hashtags in response to pivotal moments. Notably, tweets authored by black women often expressed emotional support and were critical about differential treatment in the justice system and by police. In comparison, tweets authored by white women and men often highlighted sexual harassment and violence by public figures and weaved in more general political discussions. We discuss the implications of this work for digital activism research and design, including suggestions to raise visibility by those who were under-represented in this hashtag activism movement. Content warning: this article discusses issues of sexual harassment and violence.",Proc. ACM Hum. Comput. Interact.,2020,109,18,1,False,"{'model': 'tldr@v2.0.0', 'text': 'It was found that tweets authored by white women were overrepresented in the movement compared to other demographics, aligning with criticism of unequal representation and the implications of this work for digital activism research and design are discussed.'}",210,49355602,Aaron Mueller,1411379613,Zach Wood-Doughty,1840645,Silvio Amir,1478928280,Mark Dredze,35076424,A. Nobles,,,"Computer Science, Medicine",JournalArticle
211,Auditing for Diversity Using Representative Examples,"Assessing the diversity of a dataset of information associated with people is crucial before using such data for downstream applications. For a given dataset, this often involves computing the imbalance or disparity in the empirical marginal distribution of a protected attribute (e.g. gender, dialect, etc.). However, real-world datasets, such as images from Google Search or collections of Twitter posts, often do not have protected attributes labeled. Consequently, to derive disparity measures for such datasets, the elements need to hand-labeled or crowd-annotated, which are expensive processes. We propose a cost-effective approach to approximate the disparity of a given unlabeled dataset, with respect to a protected attribute, using a control set of labeled representative examples. Our proposed algorithm uses the pairwise similarity between elements in the dataset and elements in the control set to effectively bootstrap an approximation to the disparity of the dataset. Importantly, we show that using a control set whose size is much smaller than the size of the dataset is sufficient to achieve a small approximation error. Further, based on our theoretical framework, we also provide an algorithm to construct adaptive control sets that achieve smaller approximation errors than randomly chosen control sets. Simulations on two image datasets and one Twitter dataset demonstrate the efficacy of our approach (using random and adaptive control sets) in auditing the diversity of a wide variety of datasets.",Knowledge Discovery and Data Mining,2021,39,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work proposes a cost-effective approach to approximate the disparity of a given unlabeled dataset, with respect to a protected attribute, using a control set of labeled representative examples, and provides an algorithm to construct adaptive control sets that achieve smaller approximation errors than randomly chosen control sets.'}",211,35604162,Vijay Keswani,144776615,L. E. Celis,,,,,,,,,Computer Science,"JournalArticle, Book, Conference"
212,It's a Man's Wikipedia? Assessing Gender Inequality in an Online Encyclopedia,"
 
 Wikipedia is a community-created encyclopedia that contains information about notable people from different countries, epochs and disciplines and aims to document the world's knowledge from a neutral point of view. However, the narrow diversity of the Wikipedia editor community has the potential to introduce systemic biases such as gender biases into the content of Wikipedia. In this paper we aim to tackle a sub problem of this larger challenge by presenting and applying a computational method for assessing gender bias on Wikipedia along multiple dimensions. We find that while women on Wikipedia are covered and featured well in many Wikipedia language editions, the way women are portrayed starkly differs from the way men are portrayed. We hope our work contributes to increasing awareness about gender biases online, and in particular to raising attention to the different levels in which gender biases can manifest themselves on the web.
 
",International Conference on Web and Social Media,2015,39,202,22,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper presents and applies a computational method for assessing gender bias on Wikipedia along multiple dimensions and finds that while women on Wikipedia are covered and featured well in many Wikipedia language editions, the way women are portrayed starkly differs from the way men are portrayed.'}",212,144065562,Claudia Wagner,144240725,David García,33570565,M. Jadidi,1743043,M. Strohmaier,,,,,Computer Science,JournalArticle
213,"Using Word Embeddings to Examine Gender Bias in Dutch Newspapers, 1950-1990","Contemporary debates on filter bubbles and polarization in public and social media raise the question to what extent news media of the past exhibited biases. This paper specifically examines bias related to gender in six Dutch national newspapers between 1950 and 1990. We measure bias related to gender by comparing local changes in word embedding models trained on newspapers with divergent ideological backgrounds. We demonstrate clear differences in gender bias and changes within and between newspapers over time. In relation to themes such as sexuality and leisure, we see the bias moving toward women, whereas, generally, the bias shifts in the direction of men, despite growing female employment number and feminist movements. Even though Dutch society became less stratified ideologically (depillarization), we found an increasing divergence in gender bias between religious and social-democratic on the one hand and liberal newspapers on the other. Methodologically, this paper illustrates how word embeddings can be used to examine historical language change. Future work will investigate how fine-tuning deep contextualized embedding models, such as ELMO, might be used for similar tasks with greater contextual information.",LChange@ACL,2019,25,19,0,True,"{'model': 'tldr@v2.0.0', 'text': 'Bias related to gender in six Dutch national newspapers between 1950 and 1990 is examined by comparing local changes in word embedding models trained on newspapers with divergent ideological backgrounds to demonstrate clear differences in gender bias and changes within and between newspapers over time.'}",213,33585083,M. Wevers,,,,,,,,,,,"Computer Science, Mathematics, Sociology",JournalArticle
214,Voting with Feet: Who are Leaving Hillary Clinton and Donald Trump,"From a crowded field with 17 candidates, Hillary Clinton and Donald Trump have emerged as the two presidential nominees in the 2016 U. S. presidential election. The two candidates each boast more than 7 million followers on Twitter, and at the same time both have witnessed hundreds of thousands of people leave their camps. In this paper we attempt to characterize individuals who have left Hillary Clinton and Donald Trump between September 2015 and March 2016. Our study focuses on four dimensions of social demographics: social capital, gender, age and race. Within each camp, we compare the characteristics of the current followers with former followers, i.e., individuals who have left since September 2015. We use the number of followers to measure social capital, and use profile images to infer gender, age and race. For classifying gender and race, we train a convolutional neural network (CNN). For age, we use the Face++ API. Our study shows that for both candidates followers with more social capital are more likely to leave (or switch camps). For both candidates females make up a larger presence among unfollowers than among current followers. Somewhat surprisingly, the effect is particularly pronounced for Clinton. Middle-aged individuals are more likely to leave Trump, and the young are more likely to leave Hillary Clinton. Lastly, for both candidates, African Americans make up a smaller presence among unfollowers than among followers, and the effect is particularly strong for Hillary Clinton.",IEEE International Symposium on Multimedia,2016,20,20,1,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper attempts to characterize individuals who have left Hillary Clinton and Donald Trump between September 2015 and March 2016, and shows that for both candidates followers with more social capital are more likely to leave (or switch camps).'}",214,2153604061,Yu Wang,2115387758,Yang Feng,33642939,Jiebo Luo,2108216946,Xiyang Zhang,,,,,Computer Science,JournalArticle
215,Text-mining forma mentis networks reconstruct public perception of the STEM gender gap in social media,"Mindset reconstruction maps how individuals structure and perceive knowledge, a map unfolded here by investigating language and its cognitive reflection in the human mind, i.e., the mental lexicon. Textual forma mentis networks (TFMN) are glass boxes introduced for extracting and understanding mindsets’ structure (in Latin forma mentis) from textual data. Combining network science, psycholinguistics and Big Data, TFMNs successfully identified relevant concepts in benchmark texts, without supervision. Once validated, TFMNs were applied to the case study of distorted mindsets about the gender gap in science. Focusing on social media, this work analysed 10,000 tweets mostly representing individuals’ opinions at the beginning of posts. “Gender” and “gap” elicited a mostly positive, trustful and joyous perception, with semantic associates that: celebrated successful female scientists, related gender gap to wage differences, and hoped for a future resolution. The perception of “woman” highlighted jargon of sexual harassment and stereotype threat (a form of implicit cognitive bias) about women in science “sacrificing personal skills for success”. The semantic frame of “man” highlighted awareness of the myth of male superiority in science. No anger was detected around “person”, suggesting that tweets got less tense around genderless terms. No stereotypical perception of “scientist” was identified online, differently from real-world surveys. This analysis thus identified that Twitter discourse mostly starting conversations promoted a majorly stereotype-free, positive/trustful perception of gender disparity, aimed at closing the gap. Hence, future monitoring against discriminating language should focus on other parts of conversations like users’ replies. TFMNs enable new ways for monitoring collective online mindsets, offering data-informed ground for policy making.",PeerJ Computer Science,2020,129,21,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Twitter discourse mostly starting conversations promoted a majorly stereotype-free, positive/trustful perception of gender disparity, aimed at closing the gap, and TFMNs enable new ways for monitoring collective online mindsets, offering data-informed ground for policy making.'}",215,144667749,Massimo Stella,,,,,,,,,,,"Psychology, Computer Science, Medicine, Physics","JournalArticle, Review"
216,BERT-Based Arabic Social Media Author Profiling,"We report our models for detecting age, language variety, and gender from social media data in the context of the Arabic author profiling and deception detection shared task (APDA). We build simple models based on pre-trained bidirectional encoders from transformers (BERT). We first fine-tune the pre-trained BERT model on each of the three datasets with shared task released data. Then we augment shared task data with in-house data for gender and dialect, showing the utility of augmenting training data. Our best models on the shared task test data are acquired with a majority voting of various BERT models trained under different data conditions. We acquire 54.72% accuracy for age, 93.75% for dialect, 81.67% for gender, and 40.97% joint accuracy across the three tasks.",Fire,2019,47,7,0,False,"{'model': 'tldr@v2.0.0', 'text': ""The authors' models for detecting age, language variety, and gender from social media data in the context of the Arabic author profiling and deception detection shared task (APDA) are reported, showing the utility of augmenting training data.""}",216,50445559,Chiyu Zhang,1388437494,Muhammad Abdul-Mageed,,,,,,,,,"Computer Science, Sociology",JournalArticle
217,Enhanced Self-Perception in Mixed Reality: Egocentric Arm Segmentation and Database With Automatic Labeling,"In this study, we focus on the egocentric segmentation of arms to improve self-perception in Augmented Virtuality (AV). The main contributions of this work are: <inline-formula> <tex-math notation=""LaTeX"">$i$ </tex-math></inline-formula>) a comprehensive survey of segmentation algorithms for AV; <inline-formula> <tex-math notation=""LaTeX"">$ii$ </tex-math></inline-formula>) an <italic>Egocentric Arm Segmentation Dataset (EgoArm)</italic>, composed of more than 10, 000 images, demographically inclusive (variations of skin color, and gender), and open for research purposes. We also provide all details required for the automated generation of groundtruth and semi-synthetic images; <inline-formula> <tex-math notation=""LaTeX"">$iii$ </tex-math></inline-formula>) the proposal of a deep learning network to segment arms in AV; <inline-formula> <tex-math notation=""LaTeX"">$iv$ </tex-math></inline-formula>) a detailed quantitative and qualitative evaluation to showcase the usefulness of the deep network and EgoArm dataset, reporting results on different real egocentric hand datasets, including GTEA Gaze+, EDSH, EgoHands, Ego Youtube Hands, THU-Read, TEgO, FPAB, and Ego Gesture, which allow for direct comparisons with existing approaches using color or depth. Results confirm the suitability of the EgoArm dataset for this task, achieving improvements up to 40% with respect to the baseline network, depending on the particular dataset. Results also suggest that, while approaches based on color or depth can work under controlled conditions (lack of occlusion, uniform lighting, only objects of interest in the near range, controlled background, etc.), deep learning is more robust in real AV applications.",IEEE Access,2020,75,11,1,True,"{'model': 'tldr@v2.0.0', 'text': 'Results suggest that, while approaches based on color or depth can work under controlled conditions (lack of occlusion, uniform lighting, only objects of interest in the near range, controlled background, etc.), deep learning is more robust in real AV applications.'}",217,1410197220,E. González-Sosa,1576465164,P. Pérez,2144683355,R. Tolosana,3419528,R. Kachach,2345461,Á. Villegas,,,Computer Science,"JournalArticle, Review"
218,Countering Malicious Content Moderation Evasion in Online Social Networks: Simulation and Detection of Word Camouflage,". This article contributes signiﬁcantly to countering malicious information by developing multilingual tools to simulate and detect new methods of evasion of content on social networks, making the ﬁght against information disorders more effective.",ArXiv,2022,52,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Developing multilingual tools to simulate and detect new methods of evasion of content on social networks, making the fight against information disorders more effective.'}",218,2124423135,Álvaro Huertas-García,47619557,Alejandro Martín,1411252016,J. Huertas-Tato,2151499554,David Camacho,,,,,Computer Science,JournalArticle
219,Gender Recognition in Informal and Formal Language Scenarios via Transfer Learning,,Workshop on Engineering Applications,2021,18,3,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The results indicate that it is possible to transfer the knowledge from a system trained on a specific type of expressions or idioms such as those typically used in social media into a more formal type of text data, where the amount of data is more scarce and its structure is completely different.'}",219,1654226971,D. Escobar-Grisales,1390023752,J. C. Vásquez-Correa,1390008905,J. Orozco-Arroyave,,,,,,,Computer Science,JournalArticle
220,Estimating Subgraph Frequencies with or without Attributes from Egocentrically Sampled Data,"In this paper we show how to efficiently produce unbiased estimates of subgraph frequencies from a probability sample of egocentric networks (i.e., focal nodes, their neighbors, and the induced subgraphs of ties among their neighbors). A key feature of our proposed method that differentiates it from prior methods is the use of egocentric data. Because of this, our method is suitable for estimation in large unknown graphs, is easily parallelizable, handles privacy sensitive network data (e.g. egonets with no neighbor labels), and supports counting of large subgraphs (e.g. maximal clique of size 205 in Section 6) by building on top of existing exact subgraph counting algorithms that may not support sampling. It gracefully handles a variety of sampling designs such as uniform or weighted independence or random walk sampling. Our method can be used for subgraphs that are: (i) undirected or directed; (ii) induced or non-induced; (iii) maximal or non-maximal; and (iv) potentially annotated with attributes. We compare our estimators on a variety of real-world graphs and sampling methods and provide suggestions for their use. Simulation shows that our method outperforms the state-of-the-art approach for relative subgraph frequencies by up to an order of magnitude for the same sample size. Finally, we apply our methodology to a rare sample of Facebook users across the social graph to estimate and interpret the clique size distribution and gender composition of cliques.",ArXiv,2015,56,8,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper shows how to efficiently produce unbiased estimates of subgraph frequencies from a probability sample of egocentric networks and applies the method to a rare sample of Facebook users across the social graph to estimate and interpret the clique size distribution and gender composition of cliques.'}",220,2752625,Minas Gjoka,50874070,Emily Smith,3014984,C. Butts,,,,,,,Computer Science,JournalArticle
221,GAEA: Graph Augmentation for Equitable Access via Reinforcement Learning,"Disparate access to resources by different subpopulations is a prevalent issue in societal and sociotechnical networks. For example, urban infrastructure networks may enable certain racial groups to more easily access resources such as high-quality schools, grocery stores, and polling places. Similarly, social networks within universities and organizations may enable certain groups to more easily access people with valuable information or influence. Here we introduce a new class of problems, Graph Augmentation for Equitable Access (GAEA), to enhance equity in networked systems by editing graph edges under budget constraints. We prove such problems are NP-hard, and cannot be approximated within a factor of (1-1/3e). We develop a principled, sample- and time- efficient Markov Reward Process (MRP)-based mechanism design framework for GAEA. Our algorithm outperforms baselines on a diverse set of synthetic graphs. We further demonstrate the method on real-world networks, by merging public census, school, and transportation datasets for the city of Chicago and applying our algorithm to find human-interpretable edits to the bus network that enhance equitable access to high-quality schools across racial groups. Further experiments on Facebook networks of universities yield sets of new social connections that would increase equitable access to certain attributed nodes across gender groups.","AAAI/ACM Conference on AI, Ethics, and Society",2020,40,6,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work introduces a new class of problems, Graph Augmentation for Equitable Access (GAEA), to enhance equity in networked systems by editing graph edges under budget constraints, and develops a principled, sample- and time- efficient Markov Reward Process (MRP)-based mechanism design framework for GAEA.'}",221,27344623,Govardana Sachithanandam Ramachandran,1707458,Ivan Brugere,1697944,L. Varshney,2228109,Caiming Xiong,,,,,Computer Science,"Book, JournalArticle"
222,Inferring User Preferences by Probabilistic Logical Reasoning over Social Networks,"We propose a framework for inferring the latent attitudes or preferences of users by performing probabilistic first-order logical reasoning over the social network graph. Our method answers questions about Twitter users like {\em Does this user like sushi?} or {\em Is this user a New York Knicks fan?} by building a probabilistic model that reasons over user attributes (the user's location or gender) and the social network (the user's friends and spouse), via inferences like homophily (I am more likely to like sushi if spouse or friends like sushi, I am more likely to like the Knicks if I live in New York). The algorithm uses distant supervision, semi-supervised data harvesting and vector space models to extract user attributes (e.g. spouse, education, location) and preferences (likes and dislikes) from text. The extracted propositions are then fed into a probabilistic reasoner (we investigate both Markov Logic and Probabilistic Soft Logic). Our experiments show that probabilistic logical reasoning significantly improves the performance on attribute and relation extraction, and also achieves an F-score of 0.791 at predicting a users likes or dislikes, significantly better than two strong baselines.",ArXiv,2014,90,16,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Probabilistic logical reasoning significantly improves the performance on attribute and relation extraction, and also achieves an F-score of 0.791 at predicting a users likes or dislikes, significantly better than two strong baselines.'}",222,49298465,Jiwei Li,1863425,Alan Ritter,1746807,Dan Jurafsky,,,,,,,Computer Science,JournalArticle
223,Towards Crafting Text Adversarial Samples,"Adversarial samples are strategically modified samples, which are crafted with the purpose of fooling a classifier at hand. An attacker introduces specially crafted adversarial samples to a deployed classifier, which are being mis-classified by the classifier. However, the samples are perceived to be drawn from entirely different classes and thus it becomes hard to detect the adversarial samples. Most of the prior works have been focused on synthesizing adversarial samples in the image domain. In this paper, we propose a new method of crafting adversarial text samples by modification of the original samples. Modifications of the original text samples are done by deleting or replacing the important or salient words in the text or by introducing new words in the text sample. Our algorithm works best for the datasets which have sub-categories within each of the classes of examples. While crafting adversarial samples, one of the key constraint is to generate meaningful sentences which can at pass off as legitimate from language (English) viewpoint. Experimental results on IMDB movie review dataset for sentiment analysis and Twitter dataset for gender detection show the efficiency of our proposed method.",ArXiv,2017,16,180,19,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes a new method of crafting adversarial text samples by modification of the original samples, which works best for the datasets which have sub-categories within each of the classes of examples.'}",223,1744768,Suranjana Samanta,145640180,S. Mehta,,,,,,,,,Computer Science,"JournalArticle, Review"
224,Does putting your emotions into words make you feel better? Measuring the minute-scale dynamics of emotions from online data,"Studies of affect labeling, i.e. putting your feelings into words, indicate that it can attenuate positive and negative emotions. Here we track the evolution of individual emotions for tens of thousands of Twitter users by analyzing the emotional content of their tweets before and after they explicitly report having a strong emotion. Our results reveal how emotions and their expression evolve at the temporal resolution of one minute. While the expression of positive emotions is preceded by a short but steep increase in positive valence and followed by short decay to normal levels, negative emotions build up more slowly, followed by a sharp reversal to previous levels, matching earlier findings of the attenuating effects of affect labeling. We estimate that positive and negative emotions last approximately 1.25 and 1.5 hours from onset to evanescence. A separate analysis for male and female subjects is suggestive of possible gender-specific differences in emotional dynamics.",ArXiv,2018,49,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This work tracks the evolution of individual emotions for tens of thousands of Twitter users by analyzing the emotional content of their tweets before and after they explicitly report having a strong emotion, revealing how emotions and their expression evolve at the temporal resolution of one minute.'}",224,2089733995,Rui Fan,2325888,Ali Varamesh,2307347,Onur Varol,2058909146,Alexander T. J. Barron,3367211,I. A. Leemput,145644167,M. Scheffer,Computer Science,JournalArticle
225,Fairness across Network Positions in Cyberbullying Detection Algorithms,"Cyberbullying, which often has a deeply negative impact on the victim, has grown as a serious issue in online social networks. Recently, researchers have created automated machine learning algorithms to detect Cyberbullying using social and textual features. However, the very algorithms that are intended to fight off one threat (cyberbullying) may inadvertently be falling prey to another important threat (bias of the automatic detection algorithms). This is exacerbated by the fact that while the current literature on algorithmic fairness has multiple empirical results, metrics, and algorithms for countering bias across immediately observable demographic characteristics (e.g. age, race, gender), there have been no efforts at empirically quantifying the variation in algorithmic performance based on the network role or position of individuals. We audit an existing cyberbullying algorithm using Twitter data for disparity in detection performance based on the network centrality of the potential victim and then demonstrate how this disparity can be countered using an Equalized Odds postprocessing technique. The results pave the way for more accurate and fair cyberbullying detection algorithms.",International Conference on Advances in Social Networks Analysis and Mining,2019,12,6,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work audits an existing cyberbullying algorithm using Twitter data for disparity in detection performance based on the network centrality of the potential victim and demonstrates how this disparity can be countered using an Equalized Odds postprocessing technique.'}",225,144724775,Vivek K. Singh,114709211,Connor Hofenbitzer,,,,,,,,,Computer Science,"JournalArticle, Book, Conference"
226,DECK: Behavioral Tests to Improve Interpretability and Generalizability of BERT Models Detecting Depression from Text,"Models that accurately detect depression from 001 text are important tools for addressing the post- 002 pandemic mental health crisis. BERT-based 003 classifiers’ promising performance and the off- 004 the-shelf availability make them great candi- 005 dates for this task. However, these models 006 are known to suffer from performance incon- 007 sistencies and poor generalization. In this 008 paper, we introduce the DECK ( DE pression 009 C hec K list), depression-specific model behav- 010 ioral tests that allow better interpretability and 011 improve generalizability of BERT classifiers in 012 depression domain. We create 23 tests to eval- 013 uate BERT, RoBERTa and ALBERT depres- 014 sion classifiers on three datasets, two Twitter- 015 based and one clinical interview-based. Our 016 evaluation shows that these models: 1) are ro- 017 bust to certain gender-sensitive variations in 018 text; 2) rely on important depressive language 019 marker of the increased use of first person 020 pronouns; 3) fail to detect some other depres- 021 sion symptoms like suicidal ideation. We also 022 demonstrate that DECK tests can be used to 023 incorporate symptom-specific information in 024 the training data and consistently improve gen- 025 eralizability of all three BERT models, with the 026 out-of-distribution F1-score increase of up to 027 53.93%. The DECK tests, together with the 028 associated code, are available for download at 029 https://github.com/Anonymous. 030",ArXiv,2022,62,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'The DECK tests can be used to incorporate symptom-specific information in 024 the training data and consistently improve gen- 025 eralizability of all three BERT models, with the out-of-distribution F1-score increase of up to 53.93%.'}",226,2848048,Jekaterina Novikova,94055272,Ksenia Shkaruta,,,,,,,,,Computer Science,JournalArticle
227,Awe Versus Aww: The Effectiveness of Two Kinds of Positive Emotional Stimulation on Stress Reduction for Online Content Moderators,"When people have the freedom to create and post content on the internet, particularly anonymously, they do not always respect the rules and regulations of the websites on which they post, leaving other unsuspecting users vulnerable to sexism, racism, threats, and other unacceptable content in their daily cyberspace diet. However, content moderators witness the worst of humanity on a daily basis in place of the average netizen. This takes its toll on moderators, causing stress, fatigue, and emotional distress akin to the symptomology of post-traumatic stress disorder (PTSD). The goal of the present study was to explore whether adding positive stimuli to breaktimes-images of baby animals or beautiful, aweinspiring landscapes-could help reduce the negative side-effects of being a content moderator. To test this, we had over 300 experienced content moderators read and decide whether 200 fake text-based social media posts were acceptable or not for public consumption. Although we set out to test positive emotional stimulation, however, we actually found that it is the cumulative nature of the negative emotions that likely negates most of the effects of the intervention: the longer the person had practiced content moderation, the stronger their negative experience. Connections to compassion fatigue and how best to spend work breaks as a content moderator are discussed.",Proc. ACM Hum. Comput. Interact.,2022,97,0,0,True,,227,144263543,C. Cook,2109852673,Jie Cai,2379340,D. Y. Wohn,,,,,,,Computer Science,JournalArticle
228,Real-time Emotion and Gender Classification using Ensemble CNN,"Analyzing expressions on the person’s face plays a very vital role in identifying emotions and behavior of a person. Recognizing these Expressions automatically results in a crucial component of natural human-machine interfaces.Therefore research in this field has a wide range of applications in biometric authentication, surveillance systems,emotions to emoticons in various social media platforms.Another application includes conducting customer satisfaction surveys. As we know that the large corporations made huge investments to get feedback and do surveys but fail to get equitable responses . Emotion & Gender recognition through facial gestures is a technology that aims to improve product and services performance by monitoring customer behavior to specific products or service staff by their evaluation. In the past few years there have been a wide variety of advances performed in terms of feature extraction mechanisms , detection of face and also expression classification techniques.This paper is the implementation of an Ensemble CNN for building a real-time system that can detect emotion and gender of the person.The Experimental results shows accuracy of 68% for Emotion classification into 7 classes (angry, fear, sad, happy,surprise, neutral, disgust) on FER-2013 dataset and 95% for Gender Classification (Male or Female) on IMDB dataset.Our work can predict Emotion and Gender on single face images as well as multiple face images. Also when input is given through webcam our complete pipeline of this real-time system can take less than 0.5 seconds to generate results.",ArXiv,2021,19,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper is the implementation of an Ensemble CNN for building a real-time system that can detect emotion and gender of the person and can predict Emotion and Gender on single face images as well as multiple face images.'}",228,2140461014,Abhinav Lahariya,2116377221,Varsha Singh,2192568,U. Tiwary,,,,,,,Computer Science,"JournalArticle, Review"
229,Product Market Demand Analysis Using NLP in Banglish Text with Sentiment Analysis and Named Entity Recognition,"Product market demand analysis plays a significant role for originating business strategies due to its noticeable impact on the competitive business field. Furthermore, there are roughly 228 million native Bengali speakers, the majority of whom use Banglish text to interact with one another on social media. Consumers are buying and evaluating items on social media with Banglish text as social media emerges as an online marketplace for entrepreneurs. People use social media to find preferred smartphone brands and models by sharing their positive and bad experiences with them. For this reason, our goal is to gather Banglish text data and use sentiment analysis and named entity identification to assess Bangladeshi market demand for smartphones in order to determine the most popular smartphones by gender. We scraped product related data from social media with instant data scrapers and crawled data from Wikipedia and other sites for product information with python web scrapers. Using Python's Pandas and Seaborn libraries, the raw data is filtered using NLP methods. To train our datasets for named entity recognition, we utilized Spacey's custom NER model, Amazon Comprehend Custom NER. A tensorflow sequential model was deployed with parameter tweaking for sentiment analysis. Meanwhile, we used the Google Cloud Translation API to estimate the gender of the reviewers using the BanglaLinga library. In this article, we use natural language processing (NLP) approaches and several machine learning models to identify the most in-demand items and services in the Bangladeshi market. Our model has an accuracy of 87.99% in Spacy Custom Named Entity recognition, 95.51% in Amazon Comprehend Custom NER, and 87.02% in the Sequential model for demand analysis. After Spacy's study, we were able to manage 80% of mistakes related to misspelled words using a mix of Levenshtein distance and ratio algorithms.",Annual Conference on Information Sciences and Systems,2022,12,3,0,False,"{'model': 'tldr@v2.0.0', 'text': 'NLP approaches and several machine learning models are used to identify the most in-demand items and services in the Bangladeshi market and estimate the gender of the reviewers using the BanglaLinga library.'}",229,51307595,Md. Sabbir Hossain,2161431117,Nishat Nayla,3446644,Annajiat Alim Rasel,,,,,,,Computer Science,"JournalArticle, Conference, Review"
230,Res-CNN-BiLSTM Network for overcoming Mental Health Disturbances caused due to Cyberbullying through Social Media,"Mental Health Disturbance has many reasons and cyberbullying is one of the major causes that does exploitation using social media as an instrument. The cyberbullying is done on the basis of Religion, Ethnicity, Age and Gender which is a sensitive psychological issue. This can be addressed using Natural Language Processing with Deep Learning, since social media is the medium and it generates massive form of data in textual form. Such data can be leveraged to ﬁnd the semantics and derive what type of cyberbullying is done and who are the people involved for early measures. Since deriving semantics is essential we proposed a Hybrid Deep Learning Model named 1-Dimensional CNN-Bidirectional-LSTMs with Residuals shortly known as Res-CNN-BiLSTM. In this paper we have proposed the architecture and compared its performance with different approaches of Embedding Deep Learning Algorithms.",ArXiv,2022,53,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A Hybrid Deep Learning Model named 1-Dimensional CNN-Bidirectional-LSTMs with Residuals shortly known as Res-CNN-BiLSTM is proposed and its performance is compared with different approaches of Embedding Deep Learning Algorithms.'}",230,97771467,Raunak Joshi,2116391439,Abhishek Gupta,2153471895,Nandan Kanvinde,,,,,,,Computer Science,JournalArticle
231,How well can machine learning predict demographics of social media users,"The wide use of social media sites and other digital technologies have resulted in an unprecedented availability of digital data that are being used to study human behavior across research domains. Although unsolicited opinions and sentiments are available on these platforms, demographic details are usually missing. Demographic information is pertinent in fields such as demography and public health, where significant differences can exist across sex, racial and socioeconomic groups. In an attempt to address this shortcoming, a number of academic studies have proposed methods for inferring the demographics of social media users using details such as names, usernames, and network characteristics. Gender is the easiest trait to accurately infer, with measures of accuracy higher than 90 percent in some studies. Race, ethnicity and age tend to be more challenging to predict for a variety of reasons including the novelty of social media to certain age groups and a lack of significant deviations in user details across racial and ethnic groups. Although the endeavor to predict user demographics is plagued with ethical questions regarding privacy and data ownership, knowing the demographics in a data sample can aid in addressing issues of bias and population representation, so that existing societal inequalities are not exacerbated.",,2017,91,13,1,False,"{'model': 'tldr@v2.0.0', 'text': 'Knowing the demographics in a data sample can aid in addressing issues of bias and population representation, so that existing societal inequalities are not exacerbated.'}",231,7363052,N. Cesare,4985351,Christan Earl Grant,2725774,Q. Nguyen,121406180,Hedwig Lee,2332684,E. Nsoesie,,,Psychology,
232,Demographic Inference and Representative Population Estimates from Multilingual Social Media Data,"Social media provide access to behavioural data at an unprecedented scale and granularity. However, using these data to understand phenomena in a broader population is difficult due to their non-representativeness and the bias of statistical inference tools towards dominant languages and groups. While demographic attribute inference could be used to mitigate such bias, current techniques are almost entirely monolingual and fail to work in a global environment. We address these challenges by combining multilingual demographic inference with post-stratification to create a more representative population sample. To learn demographic attributes, we create a new multimodal deep neural architecture for joint classification of age, gender, and organization-status of social media users that operates in 32 languages. This method substantially outperforms current state of the art while also reducing algorithmic bias. To correct for sampling biases, we propose fully interpretable multilevel regression methods that estimate inclusion probabilities from inferred joint population counts and ground-truth population counts. In a large experiment over multilingual heterogeneous European regions, we show that our demographic inference and bias correction together allow for more accurate estimates of populations and make a significant step towards representative social sensing in downstream applications with multilingual social media.",The Web Conference,2019,88,97,9,True,"{'model': 'tldr@v2.0.0', 'text': 'This work creates a new multimodal deep neural architecture for joint classification of age, gender, and organization-status of social media users that operates in 32 languages and substantially outperforms current state of the art while also reducing algorithmic bias.'}",232,50219006,Zijian Wang,1801223,Scott A. Hale,2518906,David Ifeoluwa Adelani,1907673,Przemyslaw A. Grabowicz,2105567264,Timo Hartmann,1724463,Fabian Flöck,Computer Science,"JournalArticle, Book, Conference"
233,Why Do Men Get More Attention? Exploring Factors Behind Success in An Online Design Community,"
 
 Online platforms are an increasingly popular tool for people to produce, promote or sell their work. However recent studies indicate that social disparities and biases present in the real world might transfer to online platforms and could be exacerbated by seemingly harmless design choices on the site (for example: recommendation systems or publicly visible success measures). In this paper we analyze an exclusive online community of teams of design professionals called Dribbble and investigate apparent differences in outcomes by gender. Overall, we find that men produce more work, and are able to show it to a larger audience thus receiving more likes. Some of this effect can be explained by the fact that women have different skills and design different images. Most importantly however, women and men position themselves differently in the Dribbble community. Our investigation of users' position in the social network shows that women have more clustered and gender homophilous following relations, which leads them to have smaller and more closely knit social networks. Overall, our study demonstrates that looking behind the apparent patterns of gender inequalities in online markets with the help of social networks and product differentiation helps us to better understand gender differences in success and failure.
 
",International Conference on Web and Social Media,2017,53,24,5,True,"{'model': 'tldr@v2.0.0', 'text': 'This study demonstrates that looking behind the apparent patterns of gender inequalities in online markets with the help of social networks and product differentiation helps to better understand gender differences in success and failure.'}",233,39963117,Johannes Wachs,46886279,Anikó Hannák,51033166,András Vörös,1886154,B. Daróczy,,,,,"Psychology, Computer Science",JournalArticle
234,Demographic differences in search engine use with implications for cohort selection,,Information Retrieval Journal,2018,25,11,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The correlation between demography (age, gender, and income) and the text of queries submitted to search engines and the results indicate that studies where demographic representation is important, such as in the study of health aspect of users or when search engines are evaluated for fairness, care should be taken in the selection of search engine data.'}",234,1388775854,E. Yom-Tov,,,,,,,,,,,"Computer Science, Psychology",JournalArticle
235,Bias-Aware Face Mask Detection Dataset,"In December 2019, a novel coronavirus (COVID-19) spread so quickly around the world that many countries had to set mandatory face mask rules in public areas to reduce the transmission of the virus. To monitor public adherence, researchers aimed to rapidly develop eﬃcient systems that can detect faces with masks automatically. However, lack of representative and novel datasets proved to be the biggest challenge. Early attempts to collect face mask datasets did not account for potential race, gender, and age biases. Therefore, the resulting models show inherent biases toward speciﬁc race groups, such as Asian or Caucasian. In this work, we present a novel face mask detection dataset that contains images posted on Twitter during the pandemic from around the world. Unlike previous datasets, the proposed Bias-Aware Face Mask Detection (BAFMD) dataset contains more images from underrepresented race and age groups to mitigate the problem for the face mask detection task. We perform experiments to investigate potential biases in widely used face mask detection datasets and illustrate that the BAFMD dataset yields models with better performance and generalization ability. The dataset is publicly available at https://github.com/Alpkant/BAFMD .",ArXiv,2022,36,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A novel face mask detection dataset that contains images posted on Twitter during the pandemic from around the world is presented and it is illustrated that the BAFMD dataset yields models with better performance and generalization ability.'}",235,1410151432,Alperen Kantarci,48046557,Ferda Ofli,151491159,Muhammad Imran,3025777,H. K. Ekenel,,,,,"Computer Science, Engineering",JournalArticle
236,Social Media Analysis based on Semanticity of Streaming and Batch Data.,"Languages shared by people differ in different regions based on their accents, pronunciation and word usages. In this era sharing of language takes place mainly through social media and blogs. Every second swing of such a micro posts exist which induces the need of processing those micro posts, in-order to extract knowledge out of it. Knowledge extraction differs with respect to the application in which the research on cognitive science fed the necessities for the same. This work further moves forward such a research by extracting semantic information of streaming and batch data in applications like Named Entity Recognition and Author Profiling. In the case of Named Entity Recognition context of a single micro post has been utilized and context that lies in the pool of micro posts were utilized to identify the sociolect aspects of the author of those micro posts. In this work Conditional Random Field has been utilized to do the entity recognition and a novel approach has been proposed to find the sociolect aspects of the author (Gender, Age group).",,2018,35,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Conditional Random Field has been utilized to do the entity recognition and a novel approach has been proposed to find the sociolect aspects of the author (Gender, Age group) in this work.'}",236,52176724,H. B. B. Ganesh,,,,,,,,,,,Computer Science,
237,Analyzing Political Parody in Social Media,"Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts. In this paper, we present the first computational study of parody. We introduce a new publicly available data set of tweets from real politicians and their corresponding parody accounts. We run a battery of supervised machine learning models for automatically detecting parody tweets with an emphasis on robustness by testing on tweets from accounts unseen in training, across different genders and across countries. Our results show that political parody tweets can be predicted with an accuracy up to 90%. Finally, we identify the markers of parody through a linguistic analysis. Beyond research in linguistics and political communication, accurately and automatically detecting parody is important to improving fact checking for journalists and analytics such as sentiment analysis through filtering out parodical utterances.",Annual Meeting of the Association for Computational Linguistics,2020,65,14,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A new publicly available data set of tweets from real politicians and their corresponding parody accounts is introduced and it is shown that political parody tweets can be predicted with an accuracy up to 90%.'}",237,1661214231,Antonis Maronikolakis,1661213189,Danae Sánchez Villegas,1398830377,Daniel Preotiuc-Pietro,3238627,Nikolaos Aletras,,,,,Computer Science,"JournalArticle, Conference"
238,Emotion Detection with Neural Personal Discrimination,"There have been a recent line of works to automatically predict the emotions of posts in social media. Existing approaches consider the posts individually and predict their emotions independently. Different from previous researches, we explore the dependence among relevant posts via the authors’ backgrounds, since the authors with similar backgrounds, e.g., gender, location, tend to express similar emotions. However, such personal attributes are not easy to obtain in most social media websites, and it is hard to capture attributes-aware words to connect similar people. Accordingly, we propose a Neural Personal Discrimination (NPD) approach to address above challenges by determining personal attributes from posts, and connecting relevant posts with similar attributes to jointly learn their emotions. In particular, we employ adversarial discriminators to determine the personal attributes, with attention mechanisms to aggregate attributes-aware words. In this way, social correlationship among different posts can be better addressed. Experimental results show the usefulness of personal attributes, and the effectiveness of our proposed NPD approach in capturing such personal attributes with significant gains over the state-of-the-art models.",Conference on Empirical Methods in Natural Language Processing,2019,33,4,0,True,"{'model': 'tldr@v2.0.0', 'text': 'Experimental results show the usefulness of personal attributes, and the effectiveness of the proposed NPD approach in capturing such personal attributes with significant gains over the state-of-the-art models.'}",238,1882859,Xiabing Zhou,116326671,Zhongqing Wang,2109167274,Shoushan Li,143740945,Guodong Zhou,,Min Zhang,,,Computer Science,"JournalArticle, Conference"
239,Learning Invariant Representations of Social Media Users,"The evolution of social media users’ behavior over time complicates user-level comparison tasks such as verification, classification, clustering, and ranking. As a result, naive approaches may fail to generalize to new users or even to future observations of previously known users. In this paper, we propose a novel procedure to learn a mapping from short episodes of user activity on social media to a vector space in which the distance between points captures the similarity of the corresponding users’ invariant features. We fit the model by optimizing a surrogate metric learning objective over a large corpus of unlabeled social media content. Once learned, the mapping may be applied to users not seen at training time and enables efficient comparisons of users in the resulting vector space. We present a comprehensive evaluation to validate the benefits of the proposed approach using data from Reddit, Twitter, and Wikipedia.",Conference on Empirical Methods in Natural Language Processing,2019,61,20,4,True,"{'model': 'tldr@v2.0.0', 'text': 'A novel procedure to learn a mapping from short episodes of user activity on social media to a vector space in which the distance between points captures the similarity of the corresponding users’ invariant features is proposed.'}",239,145580321,Nicholas Andrews,134363428,M. Bishop,,,,,,,,,"Computer Science, Mathematics","JournalArticle, Conference"
240,"Hypers at ComMA@ICON: Modelling Aggressive, Gender Bias and Communal Bias Identification","Due to the exponential increasing reach of social media, it is essential to focus on its negative aspects as it can potentially divide society and incite people into violence. In this paper, we present our system description of work on the shared task ComMA@ICON, where we have to classify how aggressive the sentence is and if the sentence is gender-biased or communal biased. These three could be the primary reasons to cause significant problems in society. Our approach utilizes different pretrained models with Attention and mean pooling methods. We were able to get Rank 1 with 0.253 Instance F1 score on Bengali, Rank 2 with 0.323 Instance F1 score on multilingual set, Rank 4 with 0.129 Instance F1 score on meitei and Rank 5 with 0.336 Instance F1 score on Hindi. The source code and the pretrained models of this work can be found here.",ICON,2021,21,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper presents their system description of work on the shared task ComMA@ICON, where they have to classify how aggressive the sentence is and if the sentence was gender-biased or communal biased.'}",240,2131010558,Sean Benhur,2148245126,Roshan Nayak,2131048205,Kanchana Sivanraju,2029654648,Adeep Hande,6604715,S. Navaneethakrishnan,1996839134,R. Priyadharshini,Computer Science,JournalArticle
241,Protest Activity Detection and Perceived Violence Estimation from Social Media Images,"We develop a novel visual model which can recognize protesters, describe their activities by visual attributes and estimate the level of perceived violence in an image. Studies of social media and protests use natural language processing to track how individuals use hashtags and links, often with a focus on those items' diffusion. These approaches, however, may not be effective in fully characterizing actual real-world protests (e.g., violent or peaceful) or estimating the demographics of participants (e.g., age, gender, and race) and their emotions. Our system characterizes protests along these dimensions. We have collected geotagged tweets and their images from 2013-2017 and analyzed multiple major protest events in that period. A multi-task convolutional neural network is employed in order to automatically classify the presence of protesters in an image and predict its visual attributes, perceived violence and exhibited emotions. We also release the UCLA Protest Image Dataset, our novel dataset of 40,764 images (11,659 protest images and hard negatives) with various annotations of visual attributes and sentiments. Using this dataset, we train our model and demonstrate its effectiveness. We also present experimental results from various analysis on geotagged image data in several prevalent protest events. Our dataset will be made accessible at https://www.sscnet.ucla.edu/comm/jjoo/mm-protest/.",ACM Multimedia,2017,57,65,3,True,"{'model': 'tldr@v2.0.0', 'text': 'A novel visual model is developed which can recognize protesters, describe their activities by visual attributes and estimate the level of perceived violence in an image and is employed in order to automatically classify the presence of protesters in animage and predict its visual attributes, perceived violence and exhibited emotions.'}",241,26421513,Donghyeon Won,1398679323,Zachary C. Steinert-Threlkeld,1834047,Jungseock Joo,,,,,,,Computer Science,"JournalArticle, Book"
242,Hate speech detection using static BERT embeddings,,Journées Bases de Données Avancées,2021,25,6,0,True,"{'model': 'tldr@v2.0.0', 'text': 'With the extensive experimental trails it is observed that the neural network performed better with static BE compared to using FT, GV or FT + GV as word embeddings, and one metric that significantly improved is specificity.'}",242,2069461919,G. Rajput,52186859,N. Punn,52133313,S. K. Sonbhadra,145092061,Sonali Agarwal,,,,,Computer Science,JournalArticle
243,A Survey of Relevant Text Mining Technology,"Recent advances in text mining and natural language processing technology have enabled researchers to detect an authors identity or demographic characteristics, such as age and gender, in several text genres by automatically analysing the variation of linguistic characteristics. However, applying such techniques in the wild, i.e., in both cybercriminal and regular online social media, differs from more general applications in that its defining characteristics are both domain and process dependent. This gives rise to a number of challenges of which contemporary research has only scratched the surface. More specifically, a text mining approach applied on social media communications typically has no control over the dataset size, the number of available communications will vary across users. Hence, the system has to be robust towards limited data availability. Additionally, the quality of the data cannot be guaranteed. As a result, the approach needs to be tolerant to a certain degree of linguistic noise (for example, abbreviations, non-standard language use, spelling variations and errors). Finally, in the context of cybercriminal fora, it has to be robust towards deceptive or adversarial behaviour, i.e. offenders who attempt to hide their criminal intentions (obfuscation) or who assume a false digital persona (imitation), potentially using coded language. In this work we present a comprehensive survey that discusses the problems that have already been addressed in current literature and review potential solutions. Additionally, we highlight which areas need to be given more attention.",ArXiv,2022,86,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A comprehensive survey is presented that discusses the problems that have already been addressed in current literature and review potential solutions, and highlights which areas need to be given more attention.'}",243,2884270,Claudia Peersman,153196116,M. Edwards,1439752615,E. Williams,144450942,A. Rashid,,,,,Computer Science,"JournalArticle, Review"
244,Towards Measuring Fairness in Speech Recognition: Casual Conversations Dataset Transcriptions,"The problem of machine learning systems demonstrating bias towards specific groups of individuals has been studied extensively, particularly in the Facial Recognition area, but much less so in Automatic Speech Recognition (ASR). This paper presents initial Speech Recognition results on “Casual Conversations” – a publicly released 846 hour corpus designed to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of metadata, including age, gender, and skin tone. The entire corpus has been manually transcribed, allowing for detailed ASR evaluations across these metadata. Multiple ASR models are evaluated, including models trained on LibriSpeech, 14,000 hour transcribed, and over 2 million hour untranscribed social media videos. Significant differences in word error rate across gender and skin tone are observed at times for all models. We are releasing human transcripts from the Casual Conversations dataset to encourage the community to develop a variety of techniques to reduce these statistical biases.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2021,36,9,0,True,"{'model': 'tldr@v2.0.0', 'text': 'Initial Speech Recognition results on “Casual Conversations” is presented – a publicly released 846 hour corpus designed to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of metadata, including age, gender, and skin tone.'}",244,2145159028,Chunxi Liu,1774515,M. Picheny,2769735,Leda Sari,94319657,Pooja Chitkara,2064375075,Alex Xiao,2108584042,Xiaohui Zhang,"Computer Science, Engineering","JournalArticle, Conference"
245,What might matter in autonomous cars adoption: first person versus third person scenarios,"The discussion between the automotive industry, governments, ethicists, policy makers and general public about autonomous cars' moral agency is widening, and therefore we see the need to bring more insight into what meta-factors might actually influence the outcomes of such discussions, surveys and plebiscites. In our study, we focus on the psychological (personality traits), practical (active driving experience), gender and rhetoric/framing factors that might impact and even determine respondents' a priori preferences of autonomous cars' operation. We conducted an online survey (N=430) to collect data that show that the third person scenario is less biased than the first person scenario when presenting ethical dilemma related to autonomous cars. According to our analysis, gender bias should be explored in more extensive future studies as well. We recommend any participatory technology assessment discourse to use the third person scenario and to direct attention to the way any autonomous car related debate is introduced, especially in terms of linguistic and communication aspects and gender.",ArXiv,2018,33,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'Any participatory technology assessment discourse to use the third person scenario and to direct attention to the way any autonomous car related debate is introduced, especially in terms of linguistic and communication aspects and gender are recommended.'}",245,2421163,Eva Zácková,1727154,J. Romportl,,,,,,,,,"Psychology, Computer Science","JournalArticle, Review"
246,Gender Differences in Appropriate Shocks and Mortality among Patients with Primary Prophylactic Implantable Cardioverter-Defibrillators: Systematic Review and Meta-Analysis,"Background Some but not all prior studies have shown that women receiving a primary prophylactic implantable cardioverter defibrillator (ICD) have a lower risk of death and appropriate shocks than men. Purpose To evaluate the effect of gender on the risk of appropriate shock, all-cause mortality and inappropriate shock in contemporary studies of patients receiving a primary prophylactic ICD. Data Source PubMed, LIVIVO, Cochrane CENTRAL between 2010 and 2016. Study Selection Studies providing at least 1 gender-specific risk estimate for the outcomes of interest. Data Extraction Abstracts were screened independently for potentially eligible studies for inclusion. Thereby each abstract was reviewed by at least two authors. Data Synthesis Out of 680 abstracts retained by our search strategy, 20 studies including 46’657 patients had gender-specific information on at least one of the relevant endpoints. Mean age across the individual studies varied between 58 and 69 years. The proportion of women enrolled ranged from 10% to 30%. Across 6 available studies, women had a significantly lower risk of first appropriate shock compared with men (pooled multivariable adjusted hazard ratio 0.62 (95% CI [0.44; 0.88]). Across 14 studies reporting multivariable adjusted gender-specific hazard ratio estimates for all-cause mortality, women had a lower risk of death than men (pooled hazard ratio 0.75 (95% CI [0.66; 0.86]). There was no statistically significant difference for the incidence of first inappropriate shocks (3 studies, pooled hazard ratio 0.99 (95% CI [0.56; 1.73]). Limitations Individual patient data were not available for most studies. Conclusion In this large contemporary meta-analysis, women had a significantly lower risk of appropriate shocks and death than men, but a similar risk of inappropriate shocks. These data may help to select patients who benefit from primary prophylactic ICD implantation.",PLoS ONE,2016,50,26,0,True,"{'model': 'tldr@v2.0.0', 'text': 'In this large contemporary meta-analysis, women had a significantly lower risk of appropriate shocks and death than men, but a similar risk of inappropriate shocks.'}",246,47288843,D. Conen,2464308,B. Arendacká,3344593,C. Röver,5727381,L. Bergau,2060292980,Pascal Munoz,5007721,S. Wijers,"Medicine, Physics, Biology","Review, MetaAnalysis, JournalArticle"
247,"First Women, Second Sex: Gender Bias in Wikipedia","Contributing to the writing of history has never been as easy as it is today. Anyone with access to the Web is able to play a part on Wikipedia, an open and free encyclopedia, and arguably one of the primary sources of knowledge on the Web. In this paper, we study gender bias in Wikipedia in terms of how women and men are characterized in their biographies. To do so, we analyze biographical content in three aspects: meta-data, language, and network structure. Our results show that, indeed, there are differences in characterization and structure. Some of these differences are reflected from the off-line world documented by Wikipedia, but other differences can be attributed to gender bias in Wikipedia content. We contextualize these differences in social theory and discuss their implications for Wikipedia policy.",ACM Conference on Hypertext & Social Media,2015,69,94,8,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper analyzes biographical content in Wikipedia in terms of how women and men are characterized in their biographies in three aspects: meta-data, language, and network structure to show that there are differences in characterization and structure.'}",247,1388342726,Eduardo Graells-Garrido,1684032,M. Lalmas,143653472,F. Menczer,,,,,,,"Computer Science, Psychology","Book, JournalArticle"
248,"Do They All Look the Same? Deciphering Chinese, Japanese and Koreans by Fine-Grained Deep Learning","We study to what extend Chinese, Japanese and Korean faces can be classified and which facial attributes offer the most important cues. First, we propose a novel way of ob- taining large numbers of facial images with nationality la- bels. Then we train state-of-the-art neural networks with these labeled images. We are able to achieve an accuracy of 75.03% in the classification task, with chances being 33.33% and human accuracy 49% . Further, we train mul- tiple facial attribute classifiers to identify the most distinc- tive features for each group. We find that Chinese, Japanese and Koreans do exhibit substantial differences in certain at- tributes, such as bangs, smiling, and bushy eyebrows. Along the way, we uncover several gender-related cross-country patterns as well. Our work, which complements existing APIs such as Microsoft Cognitive Services and Face++, could find potential applications in tourism, e-commerce, social media marketing, criminal justice and even counter- terrorism.",Conference on Multimedia Information Processing and Retrieval,2016,24,20,1,True,"{'model': 'tldr@v2.0.0', 'text': 'It is found that Chinese, Japanese and Koreans do exhibit substantial differences in certain features, such as bangs, smiling, and bushy eyebrows, along with several gender-related cross-country patterns as well.'}",248,2153604061,Yu Wang,2115387758,Yang Feng,145585312,Haofu Liao,33642939,Jiebo Luo,2155641186,Xiangyang Xu,,,"Computer Science, Psychology","JournalArticle, Conference"
249,Multi-Task Learning for Mental Health using Social Media Text,"We introduce initial groundwork for estimating suicide risk and mental health in a deep learning framework. By modeling multiple conditions, the system learns to make predictions about suicide risk and mental health at a low false positive rate. Conditions are modeled as tasks in a multi-task learning (MTL) framework, with gender prediction as an additional auxiliary task. We demonstrate the effectiveness of multi-task learning by comparison to a well-tuned single-task baseline with the same number of parameters. Our best MTL model predicts potential suicide attempt, as well as the presence of atypical mental health, with AUC > 0.8. We also find additional large improvements using multi-task learning on mental health tasks with limited training data.",ArXiv,2017,41,79,8,False,"{'model': 'tldr@v2.0.0', 'text': 'This work introduces initial groundwork for estimating suicide risk and mental health in a deep learning framework by modeling multiple conditions and demonstrates the effectiveness of multi-task learning by comparison to a well-tuned single-task baseline with the same number of parameters.'}",249,145583569,Adrian Benton,49501003,Margaret Mitchell,2022288,Dirk Hovy,,,,,,,Computer Science,JournalArticle
250,Auditing Search Engines for Differential Satisfaction Across Demographics,"Many online services, such as search engines, social media platforms, and digital marketplaces, are advertised as being available to any user, regardless of their age, gender, or other demographic factors. However, there are growing concerns that these services may systematically underserve some groups of users. In this paper, we present a framework for internally auditing such services for differences in user satisfaction across demographic groups, using search engines as a case study. We first explain the pitfalls of naively comparing the behavioral metrics that are commonly used to evaluate search engines. We then propose three methods for measuring latent differences in user satisfaction from observed differences in evaluation metrics. To develop these methods, we drew on ideas from the causal inference literature and the multilevel modeling literature. Our framework is broadly applicable to other online services, and provides general insight into interpreting their evaluation metrics.",The Web Conference,2017,54,73,4,True,"{'model': 'tldr@v2.0.0', 'text': 'A framework for internally auditing such services for differences in user satisfaction across demographic groups, using search engines as a case study is presented, and three methods for measuring latent differences inuser satisfaction from observed differences in evaluation metrics are proposed.'}",250,39718171,Rishabh Mehrotra,32071555,Ashton Anderson,145472333,Fernando Diaz,144676398,Amit Sharma,1831395,H. Wallach,49724730,Emine Yilmaz,Computer Science,"Book, JournalArticle, Conference"
251,Anonymizing k-Facial Attributes via Adversarial Perturbations,"A face image not only provides details about the identity of a subject but also reveals several attributes such as gender, race, sexual orientation, and age. Advancements in machine learning algorithms and popularity of sharing images on the World Wide Web, including social media websites, have increased the scope of data analytics and information profiling from photo collections. This poses a serious privacy threat for individuals who do not want to be profiled. This research presents a novel algorithm for anonymizing selective attributes which an individual does not want to share without affecting the visual quality of images. Using the proposed algorithm, a user can select single or multiple attributes to be surpassed while preserving identity information and visual content. The proposed adversarial perturbation based algorithm embeds imperceptible noise in an image such that attribute prediction algorithm for the selected attribute yields incorrect classification result, thereby preserving the information according to user's choice. Experiments on three popular databases i.e. MUCT, LFWcrop, and CelebA show that the proposed algorithm not only anonymizes \textit{k}-attributes, but also preserves image quality and identity information.",International Joint Conference on Artificial Intelligence,2018,31,52,6,True,"{'model': 'tldr@v2.0.0', 'text': ""The proposed adversarial perturbation based algorithm embeds imperceptible noise in an image such that attribute prediction algorithm for the selected attribute yields incorrect classification result, thereby preserving the information according to user's choice.""}",251,24380882,S. Chhabra,2041134713,Richa Singh,2338122,Mayank Vatsa,50046315,Gaurav Gupta,,,,,Computer Science,"JournalArticle, Conference"
252,Listener’s Social Identity Matters in Personalised Response Generation,"Personalised response generation enables generating human-like responses by means of assigning the generator a social identity. However, pragmatics theory suggests that human beings adjust the way of speaking based on not only who they are but also whom they are talking to. In other words, when modelling personalised dialogues, it might be favourable if we also take the listener’s social identity into consideration. To validate this idea, we use gender as a typical example of a social variable to investigate how the listener’s identity influences the language used in Chinese dialogues on social media. Also, we build personalised generators. The experiment results demonstrate that the listener’s identity indeed matters in the language use of responses and that the response generator can capture such differences in language use. More interestingly, by additionally modelling the listener’s identity, the personalised response generator performs better in its own identity.",International Conference on Natural Language Generation,2020,45,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is demonstrated that the listener’s identity indeed matters in the language use of responses and that the response generator can capture such differences in language use.'}",252,48390820,Guanyi Chen,51456789,Yinhe Zheng,1389983751,Yupei Du,,,,,,,Computer Science,JournalArticle
253,"Attitudes toward Open Access, Open Peer Review, and Altmetrics among Contributors to Spanish Scholarly Journals","Abstract:This paper aims for a better understanding of the perspectives of contributors to Spanish academic journals regarding open access, open peer review, and altmetrics. Specifically, it explores how age, gender, years of professional experience, and perception and use of social media influence authors’ opinions of these developments in scholarly publishing. A sample of 295 contributors to Spanish academic journals participated in a survey about the aforementioned topics. They were found to hold a favourable opinion of open access but were more cautious about open peer review and altmetrics. The responses of younger and female scholars indicated more reluctance to accept open peer review practices. A positive attitude toward social networks did not necessarily translate into enthusiasm for emerging trends in scholarly publishing. Despite this, ResearchGate users were more aware of altmetrics.",Journal of Scholarly Publishing,2018,34,28,1,True,"{'model': 'tldr@v2.0.0', 'text': 'How age, gender, years of professional experience, and perception and use of social media influence authors’ opinions of these developments in scholarly publishing is explored.'}",253,2083866433,Francisco Segado-Boj,1404788055,J. Martín-Quevedo,2047188282,J. J. Prieto-Gutierrez,,,,,,,"Computer Science, Political Science","JournalArticle, Review"
254,Debiasing Convolutional Neural Networks via Meta Orthogonalization,"While deep learning models often achieve strong task performance, their successes are hampered by their inability to disentangle spurious correlations from causative factors, such as when they use protected attributes (e.g., race, gender, etc.) to make decisions. In this work, we tackle the problem of debiasing convolutional neural networks (CNNs) in such instances. Building off of existing work on debiasing word embeddings and model interpretability, our Meta Orthogonalization method encourages the CNN representations of different concepts (e.g., gender and class labels) to be orthogonal to one another in activation space while maintaining strong downstream task performance. Through a variety of experiments, we systematically test our method and demonstrate that it significantly mitigates model bias and is competitive against current adversarial debiasing methods.",ArXiv,2020,29,2,0,False,"{'model': 'tldr@v2.0.0', 'text': 'The Meta Orthogonalization method encourages the CNN representations of different concepts to be orthogonal to one another in activation space while maintaining strong downstream task performance and is competitive against current adversarial debiasing methods.'}",254,134244157,Kurtis Evan David,47362268,Qiang Liu,145891577,Ruth Fong,,,,,,,Computer Science,JournalArticle
255,Cross-linguistic differences in gender congruency effects: Evidence from meta-analyses,"It has been proposed that the order in which words are prepared for production depends on the speaker's language. When producing the translation equivalent of the small cat, speakers of German or Dutch select the gender-marked determiner at a relatively early stage of production. Speakers of French or Italian postpone the encoding of a determiner or adjective until the phonological form of the noun is available. Hence, even though the words are produced in the same order (e.g., die kleine Katze in German, le petit chat in French), they are not planned in the same order and might require different amounts of advanced planning prior to production onset. This distinction between early and late selection languages was proposed to account for the observation that speakers of Germanic and Slavic languages, but not of Romance languages, are slower to name pictures in the context of a distractor word of a different gender. Meta-analyses are conducted to provide the first direct test of this cross-linguistic difference and to test a prediction of the late selection hypothesis. They confirm the existence of the gender congruency effect in German/Slavic languages and its absence in Romance languages when target and distractor words are presented simultaneously. They do not allow confirming the hypothesis that in the latter languages, a similar effect emerges when the presentation of the distractor is delayed. Overall, these analyses confirm the cross-linguistic difference but show that the evidence available to date is not sufficient to confirm or reject the late selection hypothesis as an explanation of this difference. We highlight specific directions for future research.",,2021,41,0,0,False,,255,2211737155,Audrey Burki,69537288,E. V. D. Hoven,1398083088,N. Schiller,2076456025,N. Dimitrov,,,,,"Computer Science, Biology",
256,"""Woman-Metal-White vs Man-Dress-Shorts"": Combining Social, Temporal and Image Signals to Understand Popularity of Pinterest Fashion Boards","Pinterest is a popular photo sharing website. Fashion is one the most popular and content generating category on this platform. Most of the popular fashion brands and designers use boards on Pinterest for showcasing their products. However, the characteristics of popular fashion boards are not well-known. These characteristics can be used for predicting popularity of a nascent board. Further, newly formed boards can organize their content in a way similar to the popular fashion boards to garner enhanced popularity. What properties on these fashion boards determine their popularity? Can these properties be systematically quantified? In this paper, we show how social, temporal and image signals can together help in characterizing the popular fashion boards. In particular, we study the sharing/borrowing behavior of pins and the image content characteristics of the fashion boards. We analyze the sharing behavior using social and temporal signals, and propose six novel yet simple metrics: originality score, retention coefficients, production coefficients, inter-copying time, duration of sharing and speed coefficients. We further study the image based content properties by extracting fashion, color and gender terms embedded in the pin images. We observe significant differences across the popular (highly followed or highly ranked by the experts) and the unpopular (less followed) boards. We then use these characteristic features to early predict the popularity of a board and achieve a high correlation of 0.874 with low RMSE value. Our key observation is that likes and repin retention coefficients are the most discriminatory factors of a board’s popularity apart from the usage of various color, gender and fashion terms.",International Conference on Web and Social Media,2018,48,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper studies the sharing/borrowing behavior of pins and the image content characteristics of the fashion boards, and observes significant differences across the popular (highly followed or highly ranked by the experts) and the unpopular (less followed) boards.'}",256,34594216,S. Maity,3368698,Anshit E. Chaudhary,33392067,Animesh Mukherjee,,,,,,,Computer Science,JournalArticle
257,"What and How Are We Reporting in HRI? A Review and Recommendations for Reporting Recruitment, Compensation, and Gender","Study reproducibility and generalizability of results to broadly inclusive populations is crucial in any research. Previous meta-analyses in HRI have focused on the consistency of reported information from papers in various categories. However, members of the HRI community have noted that much of the information needed for reproducible and generalizable studies is not found in published papers. We address this issue by surveying the reported study metadata over the past three years (2019 through 2021) of the main proceedings of the International Conference on Human-Robot Interaction (HRI) as well as alt.HRI. Based on the analysis results, we propose a set of recommendations for the HRI community that follow the longer-standing reporting guidelines from human-computer interaction (HCI), psychology, and other fields most related to HRI. Finally, we examine three key areas for user study reproducibility: recruitment details, participant compensation, and participant gender. We find a lack of reporting within each of these study metadata categories: of the 236 studies, 139 studies failed to report recruitment method, 118 studies failed to report compensation, and 62 studies failed to report gender data. This analysis therefore provides guidance about specific types of needed reporting improvements for HRI.",ArXiv,2022,28,3,0,False,,257,2053561821,J. Cordero,151360572,Thomas R. Groechel,2062776414,Maja J. Matari'c,,,,,,,Computer Science,"JournalArticle, Review"
258,Cultural transmission modes of music sampling traditions remain stable despite delocalization in the digital age,"Music sampling is a common practice among hip-hop and electronic producers that has played a critical role in the development of particular subgenres. Artists preferentially sample drum breaks, and previous studies have suggested that these may be culturally transmitted. With the advent of digital sampling technologies and social media the modes of cultural transmission may have shifted, and music communities may have become decoupled from geography. The aim of the current study was to determine whether drum breaks are culturally transmitted through musical collaboration networks, and to identify the factors driving the evolution of these networks. Using network-based diffusion analysis we found strong evidence for the cultural transmission of drum breaks via collaboration between artists, and identified several demographic variables that bias transmission. Additionally, using network evolution methods we found evidence that the structure of the collaboration network is no longer biased by geographic proximity after the year 2000, and that gender disparity has relaxed over the same period. Despite the delocalization of communities by the internet, collaboration remains a key transmission mode of music sampling traditions. The results of this study provide valuable insight into how demographic biases shape cultural transmission in complex networks, and how the evolution of these networks has shifted in the digital age.",PLoS ONE,2018,71,14,0,True,"{'model': 'tldr@v2.0.0', 'text': 'Using network-based diffusion analysis and network evolution methods, strong evidence is found for the cultural transmission of drum breaks via collaboration between artists, and several demographic variables that bias transmission are identified.'}",258,51488839,Mason Youngblood,,,,,,,,,,,"Medicine, Mathematics, Computer Science, Physics, Sociology",JournalArticle
259,I Am Not What I Write: Privacy Preserving Text Representation Learning,"Online users generate tremendous amounts of textual information by participating in different activities, such as writing reviews and sharing tweets. This textual data provides opportunities for researchers and business partners to study and understand individuals. However, this user-generated textual data not only can reveal the identity of the user but also may contain individual's private information (e.g., age, location, gender). Hence, ""you are what you write"" as the saying goes. Publishing the textual data thus compromises the privacy of individuals who provided it. The need arises for data publishers to protect people's privacy by anonymizing the data before publishing it. It is challenging to design effective anonymization techniques for textual information which minimizes the chances of re-identification and does not contain users' sensitive information (high privacy) while retaining the semantic meaning of the data for given tasks (high utility). In this paper, we study this problem and propose a novel double privacy preserving text representation learning framework, DPText, which learns a textual representation that (1) is differentially private, (2) does not contain private information and (3) retains high utility for the given task. Evaluating on two natural language processing tasks, i.e., sentiment analysis and part of speech tagging, we show the effectiveness of this approach in terms of preserving both privacy and utility.",ArXiv,2019,52,14,3,False,"{'model': 'tldr@v2.0.0', 'text': 'A novel double privacy preserving text representation learning framework, DPText, is proposed, which learns a textual representation that is differentially private, does not contain private information and retains high utility for the given task.'}",259,3204789,Ghazaleh Beigi,145800151,Kai Shu,2773849,Ruocheng Guo,2893721,Suhang Wang,145896397,Huan Liu,,,Computer Science,"JournalArticle, Review"
260,An Investigation of Biases in Web Search Engine Query Suggestions,"
Purpose
Survey-based studies suggest that search engines are trusted more than social media or even traditional news, although cases of false information or defamation are known. The purpose of this paper is to analyze query suggestion features of three search engines to see if these features introduce some bias into the query and search process that might compromise this trust. The authors test the approach on person-related search suggestions by querying the names of politicians from the German Bundestag before the German federal election of 2017.


Design/methodology/approach
This study introduces a framework to systematically examine and automatically analyze the varieties in different query suggestions for person names offered by major search engines. To test the framework, the authors collected data from the Google, Bing and DuckDuckGo query suggestion APIs over a period of four months for 629 different names of German politicians. The suggestions were clustered and statistically analyzed with regards to different biases, like gender, party or age and with regards to the stability of the suggestions over time.


Findings
By using the framework, the authors located three semantic clusters within the data set: suggestions related to politics and economics, location information and personal and other miscellaneous topics. Among other effects, the results of the analysis show a small bias in the form that male politicians receive slightly fewer suggestions on “personal and misc” topics. The stability analysis of the suggested terms over time shows that some suggestions are prevalent most of the time, while other suggestions fluctuate more often.


Originality/value
This study proposes a novel framework to automatically identify biases in web search engine query suggestions for person-related searches. Applying this framework on a set of person-related query suggestions shows first insights into the influence search engines can have on the query process of users that seek out information on politicians.
",Online information review (Print),2019,52,10,0,True,"{'model': 'tldr@v2.0.0', 'text': 'Applying this framework on a set of person-related query suggestions shows first insights into the influence search engines can have on the query process of users that seek out information on politicians.'}",260,41018503,Malte Bonart,144071745,A. Samokhina,2263517,G. Heisenberg,34588911,Philipp Schaer,,,,,Computer Science,"JournalArticle, Review"
261,"Layoffs, inequity and COVID-19: A longitudinal study of the journalism jobs crisis in Australia from 2012 to 2020","In Australia and beyond, journalism is reportedly an industry in crisis, a crisis exacerbated by COVID-19. However, the evidence revealing the crisis is often anecdotal or limited in scope. In this unprecedented longitudinal research, we draw on data from the Australian journalism jobs market from January 2012 until March 2020. Using Data Science and Machine Learning techniques, we analyse two distinct data sets: job advertisements (ads) data comprising 3698 journalist job ads from a corpus of over 8 million Australian job ads; and official employment data from the Australian Bureau of Statistics. Having matched and analysed both sources, we address both the demand for and supply of journalists in Australia over this critical period. The data show that the crisis is real, but there are also surprises. Counter-intuitively, the number of journalism job ads in Australia rose from 2012 until 2016, before falling into decline. Less surprisingly, for the entire period studied the figures reveal extreme volatility, characterised by large and erratic fluctuations. The data also clearly show that COVID-19 has significantly worsened the crisis. We then tease out more granular findings, including: that there are now more women than men journalists in Australia, but that gender inequity is worsening, with women journalists getting younger and worse-paid just as men journalists are, on average, getting older and better-paid; that, despite the crisis besetting the industry, the demand for journalism skills has increased; and that, perhaps concerningly, the skills sought by journalism job ads increasingly include ‘social media’ and ‘generalist communications’ skills.",Journalism,2020,87,9,1,True,,261,1610935383,Nikolas Dawson,151369695,S. Molitorisz,1808087,Marian-Andrei Rizoiu,101278687,P. Fray,,,,,"Political Science, Economics",JournalArticle
262,From social netizens to data citizens: variations of GDPR awareness in 28 European countries,,Computer Law and Security Review,2021,41,3,1,True,"{'model': 'tldr@v2.0.0', 'text': 'Education, occupation, and age were the strongest sociodemographic predictors of GDPR awareness, with little influence of gender, subjective economic well-being, or locality size.'}",262,145441542,R. Rughinis,2983012,C. Rughiniș,148160740,Simona Vulpe,38230471,D. Rosner,,,,,Computer Science,"JournalArticle, Review"
263,"State of AI Ethics Report (Volume 6, February 2022)","This report from the Montreal AI Ethics Institute (MAIEI) covers the most salient progress in research and reporting over the second half of 2021 in the field of AI ethics. Particular emphasis is placed on an""Analysis of the AI Ecosystem"",""Privacy"",""Bias"",""Social Media and Problematic Information"",""AI Design and Governance"",""Laws and Regulations"",""Trends"", and other areas covered in the""Outside the Boxes""section. The two AI spotlights feature application pieces on""Constructing and Deconstructing Gender with AI-Generated Art""as well as""Will an Artificial Intellichef be Cooking Your Next Meal at a Michelin Star Restaurant?"". Given MAIEI's mission to democratize AI, submissions from external collaborators have featured, such as pieces on the""Challenges of AI Development in Vietnam: Funding, Talent and Ethics""and using""Representation and Imagination for Preventing AI Harms"". The report is a comprehensive overview of what the key issues in the field of AI ethics were in 2021, what trends are emergent, what gaps exist, and a peek into what to expect from the field of AI ethics in 2022. It is a resource for researchers and practitioners alike in the field to set their research and development agendas to make contributions to the field of AI ethics.",ArXiv,2022,0,0,0,False,,263,144150274,Abhishek Gupta,2065129004,Connor Wright,115543382,M. B. Ganapini,2007670955,Masa Sweidan,1785367236,Renjie Butalid,,,Computer Science,"JournalArticle, Review"
264,Ensemble Learning Applied to Classify GPS Trajectories of Birds into Male or Female,"We describe our first-place solution to the Animal Behavior Challenge (ABC 2018) on predicting gender of bird from its GPS trajectory. The task consisted in predicting the gender of shearwater based on how they navigate themselves across a big ocean. The trajectories are collected from GPS loggers attached on shearwaters' body, and represented as a variable-length sequence of GPS points (latitude and longitude), and associated meta-information, such as the sun azimuth, the sun elevation, the daytime, the elapsed time on each GPS location after starting the trip, the local time (date is trimmed), and the indicator of the day starting the from the trip. We used ensemble of several variants of Gradient Boosting Classifier along with Gaussian Process Classifier and Support Vector Classifier after extensive feature engineering and we ranked first out of 74 registered teams. The variants of Gradient Boosting Classifier we tried are CatBoost (Developed by Yandex), LightGBM (Developed by Microsoft), XGBoost (Developed by Distributed Machine Learning Community). Our approach could easily be adapted to other applications in which the goal is to predict a classification output from a variable-length sequence.",ArXiv,2018,12,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This work describes its first-place solution to the Animal Behavior Challenge (ABC 2018) on predicting gender of bird from its GPS trajectory, using ensemble of several variants of Gradient Boosting Classifier along with Gaussian Process Classifier and Support Vector Classifier after extensive feature engineering.'}",264,51226950,Dewan Fayzur,,,,,,,,,,,"Computer Science, Mathematics",JournalArticle
265,Fashion and Apparel Classification using Convolutional Neural Networks,"We present an empirical study of applying deep Convolutional Neural Networks (CNN) to the task of fashion and apparel image classification to improve meta-data enrichment of e-commerce applications. Five different CNN architectures were analyzed using clean and pre-trained models. The models were evaluated in three different tasks person detection, product and gender classification, on two small and large scale datasets.",Forum Media Technology,2018,13,16,1,False,"{'model': 'tldr@v2.0.0', 'text': 'An empirical study of applying deep Convolutional Neural Networks to the task of fashion and apparel image classification to improve meta-data enrichment of e-commerce applications.'}",265,7298041,Alexander Schindler,2766990,T. Lidy,51921744,S. Karner,2065828276,Matthias Hecker,,,,,Computer Science,JournalArticle
266,Vision based body gesture meta features for Affective Computing,"Early detection of psychological distress is key to effective treatment. Automatic detection of distress, such as depression, is an active area of research. Current approaches utilise vocal, facial, and bodily modalities. Of these, the bodily modality is the least investigated, partially due to the difficulty in extracting bodily representations from videos, and partially due to the lack of viable datasets. Existing body modality approaches use automatic categorization of expressions to represent body language as a series of specific expressions, much like words within natural language. In this dissertation I present a new type of feature, within the body modality, that represents meta information of gestures, such as speed, and use it to predict a non-clinical depression label. This differs to existing work by representing overall behaviour as a small set of aggregated meta features derived from a person's movement. In my method I extract pose estimation from videos, detect gestures within body parts, extract meta information from individual gestures, and finally aggregate these features to generate a small feature vector for use in prediction tasks. I introduce a new dataset of 65 video recordings of interviews with self-evaluated distress, personality, and demographic labels. This dataset enables the development of features utilising the whole body in distress detection tasks. I evaluate my newly introduced meta-features for predicting depression, anxiety, perceived stress, somatic stress, five standard personality measures, and gender. A linear regression based classifier using these features achieves a 82.70% F1 score for predicting depression within my novel dataset.",ArXiv,2020,57,5,0,False,"{'model': 'tldr@v2.0.0', 'text': ""This dissertation presents a new type of feature, within the body modality, that represents meta information of gestures, such as speed, and uses it to predict a non-clinical depression label, which differs to existing work by representing overall behaviour as a small set of aggregated meta features derived from a person's movement.""}",266,1515600521,Indigo Orton,,,,,,,,,,,Computer Science,JournalArticle
267,Deep Learning Reveals Patterns of Diverse and Changing Sentiments Towards COVID-19 Vaccines Based on 11 Million Tweets,"Over 12 billion doses of COVID-19 vaccines have been administered at the time of writing. However, public perceptions of vaccines have been complex. We analyzed COVID-19 vaccine-related tweets to understand the evolving perceptions of COVID-19 vaccines. We finetuned a deep learning classifier using a state-of-the-art model, XLNet, to detect each tweet's sentiment automatically. We employed validated methods to extract the users' race or ethnicity, gender, age, and geographical locations from user profiles. Incorporating multiple data sources, we assessed the sentiment patterns among subpopulations and juxtaposed them against vaccine uptake data to unravel their interactive patterns. 11,211,672 COVID-19 vaccine-related tweets corresponding to 2,203,681 users over two years were analyzed. The finetuned model for sentiment classification yielded an accuracy of 0.92 on testing set. Users from various demographic groups demonstrated distinct patterns in sentiments towards COVID-19 vaccines. User sentiments became more positive over time, upon which we observed subsequent upswing in the population-level vaccine uptake. Surrounding dates where positive sentiments crest, we detected encouraging news or events regarding vaccine development and distribution. Positive sentiments in pregnancy-related tweets demonstrated a delayed pattern compared with trends in general population, with postponed vaccine uptake trends. Distinctive patterns across subpopulations suggest the need of tailored strategies. Global news and events profoundly involved in shaping users' thoughts on social media. Populations with additional concerns, such as pregnancy, demonstrated more substantial hesitancy since lack of timely recommendations. Feature analysis revealed hesitancies of various subpopulations stemmed from clinical trial logics, risks and complications, and urgency of scientific evidence.",ArXiv,2022,33,0,0,False,"{'model': 'tldr@v2.0.0', 'text': ""This work finetuned a deep learning classifier using a state-of-the-art model, XLNet, to detect each tweet's sentiment automatically, and found distinct patterns in sentiments towards COVID-19 vaccines from various demographic groups.""}",267,2113290411,Hanyin Wang,2047727449,M. Hutch,2110468525,Yikuan Li,49934192,Adrienne S. Kline,2059580280,S. Otero,5981960,L. Mithal,Computer Science,JournalArticle
268,Mobile APP User Attribute Prediction by Heterogeneous Information Network Modeling,,"International Conference on Dependability in Sensor, Cloud, and Big Data Systems and Applications",2019,25,0,0,True,"{'model': 'tldr@v2.0.0', 'text': 'The experimental results show that: the prediction of user attributes based on heterogeneous information networks can achieve higher accuracy than traditional machine learning classification methods and TPathMine model based on the number of clicks is more accurate in classifying users of different age groups, and the weight of each meta-path is consistent with human intuition or the real world situation.'}",268,1419462953,Hekai Zhang,2869419,Jibing Gong,121121022,Zhiyong Teng,2155683292,Dan Wang,2113217089,Hongfei Wang,1490934712,Linfeng Du,"Computer Science, Mathematics",JournalArticle
269,Sixteen Years of Phishing User Studies: What Have We Learned?,"Several previous studies have investigated user susceptibility to phishing attacks. A thorough meta-analysis or systematic review is required to gain a better understanding of these findings and to assess the strength of evidence for phishing susceptibility of a subpopulation, e.g., older users. We aim to determine whether an effect exists; another aim is to determine whether the effect is positive or negative and to obtain a single summary estimate of the effect. OBJECTIVES: We systematically review the results of previous user studies on phishing susceptibility and conduct a meta-analysis. METHOD: We searched four online databases for English studies on phishing. We included all user studies in phishing detection and prevention, whether they proposed new training techniques or analyzed users’ vulnerability. FINDINGS: A careful analysis reveals some discrepancies between the findings. More than half of the studies that analyzed the effect of age reported no statistically significant relationship between age and users’ performance. Some studies reported older people performed better while some reported the opposite. A similar finding holds for the gender difference. The meta-analysis shows: 1) a significant relationship between participants’ age and their susceptibility 2) females are more susceptible than males 3) users training significantly improves their detection ability.",IEEE Transactions on Dependable and Secure Computing,2021,108,3,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A meta-analysis of previous user studies on phishing susceptibility shows a significant relationship between participants’ age and their susceptibility, and females are more susceptible than males and users training significantly improves their detection ability.'}",269,40300847,Shahryar Baki,1561734006,Rakesh M. Verma,,,,,,,,,Computer Science,"JournalArticle, Review"
270,SweLL on the rise: Swedish Learner Language corpus for European Reference Level studies,"We present a new resource for Swedish, SweLL, a corpus of Swedish Learner essays linked to learners’ performance according to the Common European Framework of Reference (CEFR). SweLL consists of three subcorpora ― SpIn, SW1203 and Tisus, collected from three different educational establishments. The common metadata for all subcorpora includes age, gender, native languages, time of residence in Sweden, type of written task. Depending on the subcorpus, learner texts may contain additional information, such as text genres, topics, grades. Five of the six CEFR levels are represented in the corpus: A1, A2, B1, B2 and C1 comprising in total 339 essays. C2 level is not included since courses at C2 level are not offered. The work flow consists of collection of essays and permits, essay digitization and registration, meta-data annotation, automatic linguistic annotation. Inter-rater agreement is presented on the basis of SW1203 subcorpus. The work on SweLL is still ongoing with more that 100 essays waiting in the pipeline. This article both describes the resource and the “how-to” behind the compilation of SweLL.",International Conference on Language Resources and Evaluation,2016,22,28,3,False,"{'model': 'tldr@v2.0.0', 'text': 'A new resource for Swedish, SweLL, a corpus of Swedish Learner essays linked to learners\' performance according to the Common European Framework of Reference (CEFR) is presented and the ""how-to"" behind the compilation of SweLL is described.'}",270,143620707,E. Volodina,2153768,I. Pilán,3393561,Ingegerd Enström,3393152,Lorena Llozhi,2101654978,Peter Lundkvist,47675659,Gunlög Sundberg,Computer Science,JournalArticle
271,Self-Destructing Models: Increasing the Costs of Harmful Dual Uses in Foundation Models,"A growing ecosystem of large, open-source foundation models has reduced the labeled data and technical expertise necessary to apply machine learning to many new problems. Yet foundation models pose a clear dual-use risk, indiscrimi-nately reducing the costs of building both harmful and beneﬁcial machine learning systems. To mitigate this risk, we propose the task blocking paradigm, in which foundation models are trained with an additional mechanism to impede adaptation to harmful tasks while retaining good performance on desired tasks. We call the resulting models self-destructing models , inspired by mechanisms that prevent adversaries from using tools for harmful purposes. We present an algorithm for training self-destructing models leveraging techniques from meta-learning and adversarial learning, showing that it can largely prevent a BERT-based model from learning to perform gender identiﬁcation without harming the model’s ability to perform profession classiﬁcation. We conclude with a discussion of future directions.",ArXiv,2022,38,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'An algorithm is presented for training self-destructing models leveraging techniques from meta-learning and adversarial learning, showing that it can largely prevent a BERT-based model from learning to perform gender identification without harming the model’s ability to perform profession classiﬁcation.'}",271,49688913,Eric Mitchell,153322217,Peter Henderson,144783904,Christopher D. Manning,1746807,Dan Jurafsky,46881670,Chelsea Finn,,,Computer Science,JournalArticle
272,Fairness in Cardiac MR Image Analysis: An Investigation of Bias Due to Data Imbalance in Deep Learning Based Segmentation,,International Conference on Medical Image Computing and Computer-Assisted Intervention,2021,28,27,2,True,"{'model': 'tldr@v2.0.0', 'text': 'This work performs an analysis for racial/gender groups, focusing on the problem of training data imbalance, using a nnU-Net model trained and evaluated on cine short axis cardiac MR data from the UK Biobank dataset, consisting of 5,903 subjects from 6 different racial groups.'}",272,1398910685,E. Puyol-Antón,3583803,B. Ruijsink,143754963,S. Piechnik,2113905253,S. Neubauer,144236487,S. Petersen,153869015,R. Razavi,Computer Science,JournalArticle
273,Using meta-analytic priors to incorporate external information for study evaluation (preprint),"Background: The COVID-19 pandemic has had a profound impact on health, everyday life and economics around the world. An important complication that can arise in connection with a COVID-19 infection is acute kidney injury. A recent observational cohort study of COVID-19 patients treated at multiple sites of a tertiary care center in Berlin, Germany identified risk factors for the development of (severe) acute kidney injury. Since inferring results from a single study can be tricky, we validate these findings and potentially adjust results by including external information from other studies on acute kidney injury and COVID-19. Methods: We synthesize the results of the main study with other trials via a Bayesian meta-analysis. The external information is used to construct a predictive distribution and to derive posterior estimates for the study of interest. We focus on various important potential risk factors for acute kidney injury development such as mechanical ventilation, use of vasopressors, hypertension, obesity, diabetes, gender and smoking. Results: Our results show that depending on the degree of heterogeneity in the data the estimated effect sizes may be refined considerably with inclusion of external data. Our findings confirm that mechanical ventilation and use of vasopressors are important risk factors for the development of acute kidney injury in COVID-19 patients. Hypertension also appears to be a risk factor that should not be ignored. Shrinkage weights depended to a large extent on the estimated heterogeneity in the model. Conclusions: Our work shows how external information can be used to adjust the results from a primary study, using a Bayesian meta-analytic approach. How much information is borrowed from external studies will depend on the degree of heterogeneity present in the model.",,2022,15,0,0,False,"{'model': 'tldr@v2.0.0', 'text': 'It is confirmed that mechanical ventilation and use of vasopressors are important risk factors for the development of acute kidney injury in COVID-19 patients, and how much information is borrowed from external studies will depend on the degree of heterogeneity present in the model.'}",273,51139911,Thilo Welz,3553488,E. Knop,3092832,F. Konietschke,2047426588,J.H.B. Hardenberg,49347525,Markus Pauly,89826879,C. Rover,Mathematics,
274,Single versus Double Blind Reviewing at WSDM 2017,"In this paper we study the implications for conference program committees of using single-blind reviewing, in which committee members are aware of the names and affiliations of paper authors, versus double-blind reviewing, in which this information is not visible to committee members. WSDM 2017, the 10th ACM International ACM Conference on Web Search and Data Mining, performed a controlled experiment in which each paper was reviewed by four committee members. Two of these four reviewers were chosen from a pool of committee members who had access to author information; the other two were chosen from a disjoint pool who did not have access to this information. This information asymmetry persisted through the process of bidding for papers, reviewing papers, and entering scores. Reviewers in the single-blind condition typically bid for 22% fewer papers, and preferentially bid for papers from top institutions. Once papers were allocated to reviewers, single-blind reviewers were significantly more likely than their double-blind counterparts to recommend for acceptance papers from famous authors and top institutions. The estimated odds multipliers are 1.63 for famous authors and 1.58 and 2.10 for top universities and companies respectively, so the result is tangible. For female authors, the associated odds multiplier of 0.78 is not statistically significant in our study. However, a meta-analysis places this value in line with that of other experiments, and in the context of this larger aggregate the gender effect is also statistically significant.",ArXiv,2017,49,12,0,False,"{'model': 'tldr@v2.0.0', 'text': 'This paper studies the implications for conference program committees of using single-blind reviewing, in which committee members are aware of the names and affiliations of paper authors, versus double-blind review, inWhich this information is not visible to committee members.'}",274,49365095,A. Tomkins,2156053262,Min Zhang,2319552,W. Heavlin,,,,,,,"Computer Science, Psychology","JournalArticle, Review"
275,Adaptive image-feature learning for disease classification using inductive graph networks,,International Conference on Medical Image Computing and Computer-Assisted Intervention,2019,13,11,0,True,"{'model': 'tldr@v2.0.0', 'text': 'This work proposes a new network architecture that exploits an inductive end-to-end learning approach for disease classification, where filters from both the CNN and the graph are trained jointly and validate this architecture against state-of-the-art inductive graph networks.'}",275,80843089,Hendrik Burwinkel,32868927,Anees Kazi,40898514,Gerome Vivar,3098247,Shadi Albarqouni,3357082,G. Zahnd,145587210,Nassir Navab,"Computer Science, Engineering, Mathematics",JournalArticle
276,Decision Support for Intoxication Prediction Using Graph Convolutional Networks,,International Conference on Medical Image Computing and Computer-Assisted Intervention,2020,17,1,0,True,"{'model': 'tldr@v2.0.0', 'text': 'A new machine learning based CADx method which fuses symptoms and meta information of the patients using graph convolutional networks is proposed which stabilizes the poison prediction.'}",276,80843089,Hendrik Burwinkel,2372357,Matthias Keicher,1667759086,D. Bani-Harouni,5061241,T. Zellner,6470232,F. Eyer,145587209,N. Navab,Computer Science,JournalArticle
277,Mitigating Biases in Student Performance Prediction via Attention-Based Personalized Federated Learning,"Traditional learning-based approaches to student modeling generalize poorly to underrepresented student groups due to biases in data availability. In this paper, we propose a methodology for predicting student performance from their online learning activities that optimizes inference accuracy over different demographic groups such as race and gender. Building upon recent foundations in federated learning, in our approach, personalized models for individual student subgroups are derived from a global model aggregated across all student models via meta-gradient updates that account for subgroup heterogeneity. To learn better representations of student activity, we augment our approach with a self-supervised behavioral pretraining methodology that leverages multiple modalities of student behavior (e.g., visits to lecture videos and participation on forums), and include a neural network attention mechanism in the model aggregation stage. Through experiments on three real-world datasets from online courses, we demonstrate that our approach obtains substantial improvements over existing student modeling baselines in predicting student learning outcomes for all subgroups. Visual analysis of the resulting student embeddings confirm that our personalization methodology indeed identifies different activity patterns within different subgroups, consistent with its stronger inference ability compared with the baselines.",International Conference on Information and Knowledge Management,2022,50,2,1,True,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes a methodology for predicting student performance from their online learning activities that optimizes inference accuracy over different demographic groups such as race and gender, and obtains substantial improvements over existing student modeling baselines in predicting student learning outcomes for all subgroups.'}",277,9628638,Yun-Wei Chu,2911998,Seyyedali Hosseinalipour,1685627749,Elizabeth Tenorio,2136168910,Laura Cruz,34569448,K. Douglas,1730535,Andrew S. Lan,Computer Science,"JournalArticle, Book, Conference"
278,Pre-Trained Language Transformers are Universal Image Classifiers,"Facial images disclose many hidden personal traits such as age, gender, race, health, emotion, and psychology. Understanding these traits will help to classify the people in different attributes. In this paper, we have presented a novel method for classifying images using a pretrained transformer model. We apply the pretrained transformer for the binary classification of facial images in criminal and non-criminal classes. The pretrained transformer of GPT-2 is trained to generate text and then fine-tuned to classify facial images. During the finetuning process with images, most of the layers of GT-2 are frozen during backpropagation and the model is frozen pretrained transformer (FPT). The FPT acts as a universal image classifier, and this paper shows the application of FPT on facial images. We also use our FPT on encrypted images for classification. Our FPT shows high accuracy on both raw facial images and encrypted images. We hypothesize the meta-learning capacity FPT gained because of its large size and trained on a large size with theory and experiments. The GPT-2 trained to generate a single word token at a time, through the autoregressive process, forced to heavy-tail distribution. Then the FPT uses the heavy-tail property as its meta-learning capacity for classifying images. Our work shows one way to avoid bias during the machine classification of images. The FPT encodes worldly knowledge because of the pretraining of one text, which it uses during the classification. The statistical error of classification is reduced because of the added context gained from the text. 1 ar X iv :2 20 1. 10 18 2v 1 [ cs .C V ] 2 5 Ja n 20 22 Our paper shows the ethical dimension of using encrypted data for classification. Criminal images are sensitive to share across the boundary but encrypted largely evades ethical concern. FPT showing good classification accuracy on encrypted images shows promise for further research on privacy-preserving machine learning. We have collected facial images of criminal and non-criminal classes from multiple web sources for a balanced training data set. For experimentation, we used in total 20k images of criminals and non-criminals (10k for each class) collected from eleven different data sources. Our findings show that our proposed model can classify criminal and non-criminal images with 0.99 AUROC and 0.98 average Precision. For better generalization of our model, we also encrypted images using the Chaos-Based ImageEncryption algorithm. In our experiments, the proposed method can classify encrypted images with 0.98 AUROC and 0.97 average Precision.",ArXiv,2022,46,1,0,False,"{'model': 'tldr@v2.0.0', 'text': 'A novel method for classifying images using a pretrained transformer model for binary classification of facial images in criminal and non-criminal classes is presented and the ethical dimension of using encrypted data for classification is shown.'}",278,2061600973,Rahul Goel,2130973751,Modar Sulaiman,,Kimia Noorbakhsh,2112139689,Mahdieh Sharifi,2157585194,Ragunath R. Sharma,31948108,Pooyan Jamshidi,Computer Science,JournalArticle
279,Surveying Turkish High School and University Students' Attitudes and Approaches to Physics Problem Solving.,"Student attitudes and approaches to problem solving can impact how well they learn physics. Prior research in the US using a validated Attitude and Approaches to Problem Solving (AAPS) survey suggests that there are major differences between students in introductory physics and astronomy courses and physics experts in terms of their attitudes and approaches to physics problem solving. Here we discuss the validation, administration and analysis of data for the Turkish version of the AAPS survey for high school and university students in Turkey. After the validation and administration of the Turkish version of the survey, the analysis of the data was conducted by grouping the data by grade level, school type, and gender. While there are no statistically significant differences between the averages of various groups on the survey, overall, the university students in Turkey were more expert-like than vocational high school students. On an item by item basis, there are statistically differences between the averages of the groups on many items. For example, on average, the university students demonstrated less expert-like attitudes about the role of equations and formulas in problem solving, in solving difficult problems, and in knowing when the solution is not correct, whereas they displayed more expert-like attitudes and approaches on items related to meta-cognition in physics problem solving. A principal component analysis on the data yields item clusters into which the student responses on various survey items can be grouped. A comparison of the responses of the Turkish and American university students enrolled in algebra-based introductory physics courses shows that on more than half of the items, the responses of these two groups were statistically significantly different with the US students on average responding to the items in more expert-like manner.",,2016,56,23,1,True,,279,34746037,N. Balta,144286795,Andrew J. Mason,144916681,C. Singh,,,,,,,"Mathematics, Physics",Review

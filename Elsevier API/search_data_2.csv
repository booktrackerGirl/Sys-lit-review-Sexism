,abstract,prism:coverDate,prism:aggregationType,subtypeDescription,prism:publicationName,source-id,citedby-count,prism:volume,title,openaccess,openaccessFlag,prism:doi,dc:publisher,index,venue,year,referenceCount,influentialCitationCount,tldr,author_1_id,author_1_name,author_2_id,author_2_name,author_3_id,author_3_name,author_4_id,author_4_name,author_5_id,author_5_name,author_6_id,author_6_name,author_1_paperCount,author_1_citationCount,author_1_hIndex,author_2_paperCount,author_2_citationCount,author_2_hIndex,author_3_paperCount,author_3_citationCount,author_3_hIndex,author_4_paperCount,author_4_citationCount,author_4_hIndex,author_5_paperCount,author_5_citationCount,author_5_hIndex,author_6_paperCount,author_6_citationCount,author_6_hIndex,fieldsOfStudy
0,"© 2022 Elsevier LtdThe spread of Hate Speech on online platforms is a severe issue for societies and requires the identification of offensive content by platforms. Research has modeled Hate Speech recognition as a text classification problem that predicts the class of a message based on the text of the message only. However, context plays a huge role in communication. In particular, for short messages, the text of the preceding tweets can completely change the interpretation of a message within a discourse. This work extends previous efforts to classify Hate Speech by considering the current and previous tweets jointly. In particular, we introduce a clearly defined way of extracting context. We present the development of the first dataset for conversational-based Hate Speech classification with an approach for collecting context from long conversations for code-mixed Hindi (ICHCL dataset). Overall, our benchmark experiments show that the inclusion of context can improve classification performance over a baseline. Furthermore, we develop a novel processing pipeline for processing the context. The best-performing pipeline uses a fine-tuned SentBERT paired with an LSTM as a classifier. This pipeline achieves a macro F1 score of 0.892 on the ICHCL test dataset. Another KNN, SentBERT, and ABC weighting-based pipeline yields an F1 Macro of 0.807, which gives the best results among traditional classifiers. So even a KNN model gives better results with an optimized BERT than a vanilla BERT model.",2023-04-01,Journal,Article,Expert Systems with Applications,24201,1,215,Detecting offensive speech in conversational code-mixed dialogue on social media: A contextual dataset and benchmark experiments,0,false,10.1016/j.eswa.2022.119342,Elsevier Ltd,0,Expert systems with applications,2022.0,51.0,0.0,,2085214622,Hiren Madhu,2057059204,Shrey Satapara,33682998,Sandip J Modha,32416012,Thomas Mandl,1911868,Prasenjit Majumder,,,5.0,141.0,3.0,6.0,141.0,3.0,28.0,727.0,9.0,208.0,2676.0,26.0,118.0,1478.0,18.0,,,,
1,"© 2022 Elsevier B.V.The enormous growth of social media provides a platform for displaying harmful, offensive online behaviour, which keeps increasing with time. The popularity of smartphones and the anonymity of the internet have made online offensive behaviour very common. Therefore, research on social media offensive behaviour has increased in recent years. In this paper, we have endeavoured to depict the variety of abusive behaviour one can encounter online and the significance of detecting them by classifying them into four categories: Content-Based, Sentiment and Emotion Based, User or Profile Based, and Network or Graph-Based approach. We review the state-of-the-art methods to detect bullies and abusive content on social media and discuss the factors that drive offenders to indulge in offensive activity, preventive actions to avoid online toxicity, and various cyber laws in different countries. Finally, we identify and discuss the future research directions that serve as a reference to overcome offensive content in social media.",2023-03-01,Journal,Review,Entertainment Computing,19400158708,0,45,"Online offensive behaviour in socialmedia: Detection approaches, comprehensive review and future directions",0,false,10.1016/j.entcom.2022.100544,Elsevier B.V.,1,Entertainment Computing,2023.0,113.0,0.0,,2198249048,Sneha Chinivar,2198254237,Roopa M.S.,2198254207,Arunalatha J.S.,2093461647,Venugopal K.R.,,,,,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,7.0,61.0,3.0,,,,,,,
2,"© 2022 Elsevier LtdDetecting suicidal tendencies and preventing suicides is an important social goal. The rise and continuance of emotion, the emotion category, and the intensity of the emotion are important clues about suicidal tendencies. The three determinants of emotion, viz. Valence, Arousal, and Dominance (VAD) can help determine a person's exact emotion(s) and its intensity. This paper introduces an end-to-end VAD-assisted transformer-based multi-task network for detecting emotion (primary task) and its intensity (auxiliary task) in suicide notes. As part of this research, we expand the utility of the emotion-annotated benchmark dataset of suicide notes, CEASE-v2.0, by annotating all its sentences with emotion intensity labels. Empirical results show that our multi-task method performs better than the corresponding single-task systems, with the best attained overall Mean Recall (MR) of 65.25% on the emotion task. On a similar task, we improved MR by 8.78% over the existing state-of-the-art system. We evaluated our approach on three benchmark datasets for three different tasks. We observed that the introduced method consistently outperformed existing state-of-the-art approaches on the studied datasets, demonstrating its capacity to generalize to other downstream correlated tasks. We qualitatively examined our model's output by comparing it to the labeling of a psychiatrist.",2023-03-01,Journal,Article,Information Processing and Management,12689,0,60,VAD-assisted multitask transformer framework for emotion recognition and intensity prediction on suicide notes,0,false,10.1016/j.ipm.2022.103234,Elsevier Ltd,2,Information Processing &amp; Management,2023.0,42.0,0.0,,1409869614,Soumitra Ghosh,1734904,Asif Ekbal,145532184,P. Bhattacharyya,,,,,,,24.0,69.0,4.0,458.0,6183.0,41.0,813.0,9183.0,45.0,,,,,,,,,,
3,"© 2021, The Author(s).Abusive language is an important issue in online communication across different platforms and languages. Having a robust model to detect abusive instances automatically is a prominent challenge. Several studies have been proposed to deal with this vital issue by modeling this task in the cross-domain and cross-lingual setting. This paper outlines and describes the current state of this research direction, providing an overview of previous studies, including the available datasets and approaches employed in both cross-domain and cross-lingual settings. This study also outlines several challenges and open problems of this area, providing insights and a useful roadmap for future work.",2023-02-01,Journal,Article,Personal and Ubiquitous Computing,22315,3,27,Towards multidomain and multilingual abusive language detection: a survey,1,true,10.1007/s00779-021-01609-1,Springer Science and Business Media Deutschland GmbH,3,Personal and Ubiquitous Computing,2021.0,161.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The current state of research in this area is described, providing an overview of previous studies, including the available datasets and approaches employed in both cross-domain and cross-lingual settings, and several challenges and open problems are outlined.'}",9278845,Endang Wahyu Pamungkas,3101511,Valerio Basile,1787198,V. Patti,,,,,,,19.0,334.0,11.0,123.0,2883.0,25.0,220.0,4576.0,36.0,,,,,,,,,,Computer Science
4,"© 2022 Elsevier B.V.As the number of non-native English speakers on social media has skyrocketed in recent years, sentiment and emotion analysis on regional languages and code-mixed data has gained traction. Despite extensive research on English, the area of Hindi–English code-mixed texts is still relatively new and understudied. We create an emotion annotated Hindi–English (Hinglish) code-mixed dataset by performing emotion annotation on the benchmark SentiMix dataset to solve this problem and enable future researchers to contribute to this domain. We propose an end-to-end transformer-based multitask framework for sentiment detection and emotion recognition from the SentiMix code-mixed dataset. We fine-tune the pre-trained cross-lingual embedding model, XLMR, using task-specific data to further exploit the efficacy of transfer learning to improve the overall efficiency of our methods. Our proposed multi-task solution outperforms the state-of-the-art single-task and multitask baselines by a considerable margin, implying that the auxiliary task (i.e. emotion recognition) increases the efficiency of the primary task (i.e. sentiment detection) in a multi-task environment. It should be noted that the reported findings were obtained without the use of any ensemble techniques, thereby adhering to a model of effective and production-ready NLP.",2023-01-25,Journal,Article,Knowledge-Based Systems,24772,0,260,Multitasking of sentiment detection and emotion recognition in code-mixed Hinglish data,0,false,10.1016/j.knosys.2022.110182,Elsevier B.V.,4,Knowledge-Based Systems,2022.0,26.0,0.0,,1409869614,Soumitra Ghosh,2194830832,Amit Priyankar,1734904,Asif Ekbal,145532184,P. Bhattacharyya,,,,,24.0,69.0,4.0,1.0,0.0,0.0,458.0,6183.0,41.0,813.0,9183.0,45.0,,,,,,,Computer Science
5,"© 2022 Elsevier LtdThe generation of stereotypes allows us to simplify the cognitive complexity we have to deal with in everyday life. Stereotypes are extensively used to describe people who belong to a different ethnic group, particularly in racial hoaxes and hateful content against immigrants. This paper addresses the study of stereotypes from a novel perspective that involves psychology and computational linguistics both. On the one hand, it describes an Italian social media corpus built within a social psychology study, where stereotypes and related forms of discredit were made explicit through annotation. On the other hand, it provides some lexical analysis, to bring out the linguistic features of the messages collected in the corpus, and experiments for validating this annotation scheme and its automatic application to other corpora in the future. The main expected outcome is to shed some light on the usefulness of this scheme for training tools that automatically detect and label stereotypes in Italian.",2023-01-01,Journal,Article,Information Processing and Management,12689,0,60,Detecting racial stereotypes: An Italian social media corpus where psychology meets NLP,1,true,10.1016/j.ipm.2022.103118,Elsevier Ltd,5,Information Processing & Management,2023.0,35.0,0.0,,34705135,C. Bosco,1787198,V. Patti,7675229,Simona Frenda,29909892,A. T. Cignarella,5532680,M. Paciello,1393658299,Francesca D’Errico,143.0,3206.0,28.0,220.0,4576.0,36.0,19.0,265.0,8.0,27.0,324.0,11.0,83.0,2279.0,27.0,131.0,1392.0,19.0,Computer Science
6,"© 2023 Tech Science Press. All rights reserved.Communication in society had developed within cultural and geographical boundaries prior to the invention of digital technology. The latest advancements in communication technology have significantly surpassed the conventional constraints for communication with regards to time and location. These new platforms have ushered in a new age of user-generated content, online chats, social network and comprehensive data on individual behavior. However, the abuse of communication software such as social media websites, online communities, and chats has resulted in a new kind of online hostility and aggressive actions. Due to widespread use of the social networking platforms and technological gadgets, conventional bullying has migrated from physical form to online, where it is termed as Cyberbullying. However, recently the digital technologies as machine learning and deep learning have been showing their efficiency in identifying linguistic patterns used by cyberbullies and cyberbullying detection problem. In this research paper, we aimed to evaluate shallow machine learning and deep learning methods in cyberbullying detection problem. We deployed three deep and six shallow learning algorithms for cyberbullying detection problems. The results show that bidirectional long-short-term memory is the most efficient method for cyberbullying detection, in terms of accuracy and recall.",2023-01-01,Journal,Article,"Computers, Materials and Continua",24364,0,74,Cyberbullying-related Hate Speech Detection Using Shallow-to-deep Learning,1,true,10.32604/cmc.2023.032993,Tech Science Press,6,"Computers, Materials &amp; Continua",,0.0,0.0,,1387502231,Daniyar Sultan,2057093969,Aigerim Toktarova,2471208,A. Zhumadillayeva,2180752494,Sapargali Aldeshov,73124723,Shynar Mussiraliyeva,2057093775,G. Beissenova,6.0,11.0,2.0,5.0,2.0,1.0,21.0,65.0,5.0,3.0,1.0,1.0,21.0,50.0,4.0,8.0,5.0,2.0,
7,"© 2022 The Society for the Scientific Study of Sexuality.Both the ownership and development of sex dolls and robots are passionately debated, with skeptics suspecting that their increasing human-likeness and the accompanying anthropomorphization (i.e., attributing human-likeness) reinforce the objectification of, and hostility toward, women. As empirical data are largely lacking, we scrutinized this hypothesis in a pre-registered study among doll owners (N = 217), comparing two user groups: “toy group” (n = 104; doll as sex toy) and “partner group” (n = 113; doll as partner). We related their objectification tendencies (i.e., seeing women merely as objects, e.g., to promote sexual desire) as well as their hostility toward women, to the anthropomorphization of their doll. Additionally, we collected qualitative data on how participants perceived their doll usage affected their attitudes toward women. The partner group expressed greater levels of hostility and anthropomorphization, moderate in magnitude. Objectification mediated the influence of anthropomorphization on hostility and a higher percentage described a change in attitudes toward women in response to doll use. These data provide the first empirical evidence that the tendency to anthropomorphize dolls is related to negative attitudes toward women. Given the ongoing development of sex robots designed to surpass dolls in human-likeness and anthropomorphization, this finding seems highly significant.",2023-01-01,Journal,Article,Journal of Sex Research,30084,0,60,Is the Anthropomorphization of Sex Dolls Associated with Objectification and Hostility Toward Women? A Mixed Method Study among Doll Users,0,false,10.1080/00224499.2022.2103071,Taylor and Francis Ltd.,7,Journal of Sex Research,2022.0,70.0,0.0,,2179540455,Jeanne C Desbuleux,2179540644,Johannes Fuss,,,,,,,,,1.0,1.0,1.0,1.0,1.0,1.0,,,,,,,,,,,,,Medicine
8,"© The Author(s) 2022.The present study intends to contribute to the analysis of digital discursive practices of hate speech expressed throughout the so-called ‘Manosphere’, a group of online communities in which men express their considerations about masculinity. Through qualitative and quantitative analysis, it investigates how one of the main Manosphere groups, the Incels, creates its in-group/out-group discourse through its representations of women and of themselves. Driven by Critical Discourse Studies and studies on the ideological function of metaphors, the first part of the analysis reveals a conflation of apparently sarcastic metaphors, dark humour, and misogyny used to talk about women, while the second section of the study focuses on the peculiar self-representations of the men who participate in the forum, which breach Van Dijk’s ‘us vs them’ identity square pattern: rather than emphasising the positive traits of the in-group, incels describe themselves through self-derogative nominations and predications that give way to a spiral of self-pitying and self-contempt, which might be used to create fraternal bonds within the community.",2023-01-01,Journal,Article,Discourse and Society,13524,0,34,An analysis of self-other representations in the incelosphere: Between online misogyny and self-contempt,0,false,10.1177/09579265221099380,SAGE Publications Ltd,8,Discourse &amp; Society,2022.0,39.0,0.0,,146843835,Giuseppina Scotto di Carlo,,,,,,,,,,,10.0,15.0,2.0,,,,,,,,,,,,,,,,
9,"© The Author(s) 2022.The digital sphere has become a space in which misogyny-laden discourses are constantly presented. In fact, in Mexico persists a rape culture that justifies violent acts against women and blames the victims of the crimes through social opinions. The present study proposed an approach based on the Theory of Social Representations. In this sense, this study aimed to analyze the discourses that emerge in the digital sphere when users give their opinion on five types of crimes against women: femicide, rape, enforced disappearance, abuse, and sexual harassment. The results revealed that there are four types of discourse (representations) framed within rape culture: disbelief of rape, blaming the victim, revictimization, and disempowering women. It is concluded that Mexican society maintains a representation that stereotypes and devalues the image of women, which allows us to understand the aggressions that women suffer in their daily lives.",2023-01-01,Journal,Article,Journal of Interpersonal Violence,20374,0,38,"Rape Culture, Revictimization, and Social Representations: Images and Discourses on Sexual and Violent Crimes in the Digital Sphere in Mexico",0,false,10.1177/08862605221084747,SAGE Publications Inc.,9,Journal of Interpersonal Violence,2022.0,101.0,0.0,,2085349122,Hiram Reyes-Sosa,2160968910,Sonia Martínez-Cueva,115237513,Nahia Idoiaga Mondragón,,,,,,,8.0,33.0,4.0,1.0,0.0,0.0,28.0,576.0,10.0,,,,,,,,,,Medicine
10,"© 2022 Elsevier B.V.The analysis and detection of offensive content in textual information have become a great challenge for the Natural Language Processing community. Most of the research conducted so far on offensive language detection have addressed this task as a sole optimization objective. However, other linguistic phenomena that are arguably correlated with offensive language and therefore could be beneficial to recognize this type of problematic content on the Web, have not been explored in depth so far. Thus, the goal of this study is to investigate whether explicit and implicit concepts involved in the expression of offensive language help in the detection of this phenomenon and how to incorporate these concepts in a computational system. We propose a multi-task learning approach that includes such concepts according to the relevance shown by a feature selection method called mutual information. Our experiments show that some phenomena such as constructiveness, target group and person, figurative language (sarcasm and mockery), insults, improper language, and emotions combined together help to optimize the offensive language detection task, outperforming a state-of-the-art method (the transformer BETO) that we use as our baseline to compare the results.",2022-12-22,Journal,Article,Knowledge-Based Systems,24772,0,258,Integrating implicit and explicit linguistic phenomena via multi-task learning for offensive language detection,0,false,10.1016/j.knosys.2022.109965,Elsevier B.V.,10,Knowledge-Based Systems,2022.0,47.0,0.0,,3455118,Flor Miriam Plaza del Arco,1398823104,M. Molina-González,145200121,L. A. U. López,51183850,M. T. M. Valdivia,,,,,33.0,216.0,6.0,32.0,432.0,9.0,180.0,2788.0,27.0,36.0,327.0,9.0,,,,,,,Computer Science
11,"© 2022, The Author(s).“Misogynoir” is a term that refers to the anti-Black forms of misogyny that Black women experience. To explore how current automated hate speech detection approaches perform in detecting this type of hate, we evaluated the performance of two state-of-the-art detection tools, HateSonar and Google’s Perspective API, on a balanced dataset of 300 tweets, half of which are examples of misogynoir and half of which are examples of supporting Black women and an imbalanced dataset of 3138 tweets of which 162 tweets are examples of misogynoir and 2976 tweets are examples of allyship tweets. We aim to determine if these tools flag these messages under any of their classifications of hateful speech (e.g. “hate speech”, “offensive language”, “toxicity” etc.). Close analysis of the classifications and errors shows that current hate speech detection tools are ineffective in detecting misogynoir. They lack sensitivity to context, which is an essential component for misogynoir detection. We found that tweets likely to be classified as hate speech explicitly reference racism or sexism or use profane or aggressive words. Subtle tweets without references to these topics are more challenging to classify. We find that the lack of sensitivity to context may make such tools not only ineffective but potentially harmful to Black women.",2022-12-01,Journal,Article,Social Network Analysis and Mining,19700177337,0,12,Misogynoir: challenges in detecting intersectional hate,1,true,10.1007/s13278-022-00993-7,Springer,11,Social Network Analysis and Mining,2022.0,52.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'It is found that tweets likely to be classified as hate speech explicitly reference racism or sexism or use profane or aggressive words are more challenging to classify, and the lack of sensitivity to context may make such tools not only ineffective but potentially harmful to Black women.'}",74733212,J. Kwarteng,3448651,S. Perfumi,145118333,T. Farrell,2190195962,Aisling Third,152179862,Miriam Fernández,,,7.0,6.0,1.0,14.0,49.0,4.0,26.0,87.0,5.0,2.0,0.0,0.0,91.0,2045.0,20.0,,,,Computer Science
12,"© 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.Proud Boys, a contemporary radical extremist group has exploited the convenience and reach of social media platforms to spread its hateful ideology. To combat this spread, this paper analyzes social media dialogue surrounding Proud Boys protests from multiple perspectives to understand: (i) the outlook and profiles of users who support and reject Proud Boys; (ii) the network structure to determine influencers and communities; and (iii) the degree of engagement of tweets and the activity of their authors. The analyses indicate that conservative, religious, right-wing segments of the populace support Proud Boys, and their support is rooted in patriotism and defense of American values. Socialists and progressives oppose their radical and hateful ideology. Proud Boys’ topic network is fragmented with low density and is comprised of distinct, small communities. Authors of opposing tweets have a more extensive set of friends and followers, and their tweets receive more likes and retweets. Based on these results, it can be inferred that tweets endorsing Proud Boys’ ideology do not appear to proliferate virally, but instead reach limited audiences through smaller clusters. These analyses and results then form the basis of a classification framework, which can accurately detect tweets supportive of Proud Boys with an accuracy of 0.84 and AUC ROC of 0.89. The capability of the framework to identify and demote supporting tweets offers an extra layer of mitigation that can be employed to stem their spread. The research showcases the promise of mining social media feeds to understand why and how radical extremism spreads and is a gateway for future researchers.",2022-12-01,Journal,Article,Social Network Analysis and Mining,19700177337,0,12,Analyzing extremist social media content: a case study of Proud Boys,0,false,10.1007/s13278-022-00940-6,Springer,12,Social Network Analysis and Mining,2022.0,47.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'Analyzes social media dialogue surrounding Proud Boys protests from multiple perspectives to understand the outlook and profiles of users who support and reject Proud Boys; the network structure to determine influencers and communities; and the degree of engagement of tweets and the activity of their authors to form a classification framework.'}",2110580052,Hieu Nguyen,1724704,S. Gokhale,,,,,,,,,10.0,5.0,1.0,229.0,3447.0,28.0,,,,,,,,,,,,,
13,"© 2022 Owner/Author.Growing evidence suggests that YouTube's recommendation algorithm plays a role in online radicalization via surfacing extreme content. Radical Islamist groups, in particular, have been profiting from the global appeal of YouTube to disseminate hate and jihadist propaganda. In this quantitative, data-driven study, we investigate the prevalence of religiously intolerant Arabic YouTube videos, the tendency of the platform to recommend such videos, and how these recommendations are affected by demographics and watch history. Based on our deep learning classifier developed to detect hateful videos and a large-scale dataset of over 350K videos, we find that Arabic videos targeting religious minorities are particularly prevalent in search results (30%) and first-level recommendations (21%), and that 15% of overall captured recommendations point to hateful videos. Our personalized audit experiments suggest that gender and religious identity can substantially affect the extent of exposure to hateful content. Our results contribute vital insights into the phenomenon of online radicalization and facilitate curbing online harmful content.",2022-11-11,Journal,Article,Proceedings of the ACM on Human-Computer Interaction,21100908414,0,6,"Deradicalizing YouTube: Characterization, Detection, and Personalization of Religiously Intolerant Arabic Videos",1,true,10.1145/3555618,Association for Computing Machinery,13,Proc. ACM Hum. Comput. Interact.,2022.0,94.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This quantitative, data-driven study investigates the prevalence of religiously intolerant Arabic YouTube videos, the tendency of the platform to recommend such videos, and how these recommendations are affected by demographics and watch history, and develops a deep learning classifier developed to detect hateful videos.'}",67096342,Nuha Albadi,66081097,Maram Kurdi,1681816,Shivakant Mishra,,,,,,,9.0,202.0,4.0,10.0,202.0,4.0,216.0,5436.0,35.0,,,,,,,,,,Computer Science
14,"© 2022 The Author(s)Homophobia or Transphobia can be defined as the hatred, discomfort, or dislike of lesbian, gay, transgender or bisexual people. Studies have shown that these individuals were more likely to develop mental health issues, likely due to being subjected to more forms of abuse on social media. Hence there is an ardent need to develop automated abusive speech detection systems to tackle the abusive content on social media. There has been an elevation in hate speech or abuse and this paper focuses on the LGBTQIA+ community. Due to the shortage of resources in the said study area, we hypothesize that data augmentation via Pseudolabeling by transliterating the code-mixed text to the parent language will improve the models’ performances on the newly constructed dataset. We put our hypothesis into testing, and studied the performances of several multilingual language models for our cause.",2022-11-01,Journal,Article,International Journal of Information Management Data Insights,21101081610,1,2,How can we detect Homophobia and Transphobia? Experiments in a multilingual code-mixed setting for social media governance,1,true,10.1016/j.jjimei.2022.100119,Elsevier B.V.,14,Int. J. Inf. Manag. Data Insights,2022.0,79.0,0.0,,117018834,Bharathi Raja Chakravarthi,2029654648,Adeep Hande,2081604665,R. Ponnusamy,2081605433,P. Kumaresan,1996839134,R. Priyadharshini,,,92.0,2283.0,27.0,20.0,354.0,10.0,20.0,295.0,8.0,17.0,206.0,6.0,43.0,1087.0,18.0,,,,Computer Science
15,"© 2022 ACM.Game developers, researchers, and players recognize the harm of toxic behaviour in online games-yet toxicity persists. Players' coping strategies are limited to tools that focus on punishing toxic players (e.g., muting, blocking, reporting), which are inadequate and often misused. To address the needs of players experiencing toxicity, we took inspiration from research in other online spaces that provide support tools for targets of harassment. We iteratively designed and evaluated in-game tools to support targets of toxicity. While we found that most players prefer tools that explicitly address toxicity and increase feelings of control, we also found that tools that solely provide social or emotional support also decrease stress, increase feelings of control, and increase positive affect. Our findings suggest that players may benefit from variety in toxicity support tools that both explicitly address toxicity in the moment and help players cope after it has occurred.",2022-10-29,Journal,Article,Proceedings of the ACM on Human-Computer Interaction,21100908414,1,6,Feeling Good and In Control: In-game Tools to Support Targets of Toxicity,0,false,10.1145/3549498,Association for Computing Machinery,15,Proc. ACM Hum. Comput. Interact.,2022.0,92.0,0.0,,2054429931,Elizabeth Reid,1788745,R. Mandryk,2089411254,Nicole A. Beres,2413306,Madison Klarkowski,1995636,Julian Frommel,,,6.0,40.0,3.0,259.0,10273.0,46.0,6.0,21.0,2.0,34.0,322.0,10.0,53.0,744.0,13.0,,,,Computer Science
16,"© 2022 Marjanovic et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Despite attempts to increase gender parity in politics, global efforts have struggled to ensure equal female representation. This is likely tied to implicit gender biases against women in authority. In this work, we present a comprehensive study of gender biases that appear in online political discussion. To this end, we collect 10 million comments on Reddit in conversations about male and female politicians, which enables an exhaustive study of automatic gender bias detection. We address not only misogynistic language, but also other manifestations of bias, like benevolent sexism in the form of seemingly positive sentiment and dominance attributed to female politicians, or differences in descriptor attribution. Finally, we conduct a multi-faceted study of gender bias towards politicians investigating both linguistic and extra-linguistic cues. We assess 5 different types of gender bias, evaluating coverage, combinatorial, nominal, sentimental and lexical biases extant in social media language and discourse. Overall, we find that, contrary to previous research, coverage and sentiment biases suggest equal public interest in female politicians. Rather than overt hostile or benevolent sexism, the results of the nominal and lexical analyses suggest this interest is not as professional or respectful as that expressed about male politicians. Female politicians are often named by their first names and are described in relation to their body, clothing, or family; this is a treatment that is not similarly extended to men. On the now banned far-right subreddits, this disparity is greatest, though differences in gender biases still appear in the right and left-leaning subreddits. We release the curated dataset to the public for future studies.",2022-10-01,Journal,Article,PLoS ONE,10600153309,0,17,Quantifying gender biases towards politicians on Reddit,1,true,10.1371/journal.pone.0274317,Public Library of Science,16,PLoS ONE,2021.0,88.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'It is found that, contrary to previous research, coverage and sentiment biases suggest equal public interest in female politicians, however, the results of the nominal and lexical analyses suggest this interest is not as professional or respectful as that expressed about male politicians.'}",2146694845,S. Marjanovic,82563120,Karolina Stańczak,1736067,Isabelle Augenstein,,,,,,,3.0,2.0,1.0,6.0,36.0,2.0,116.0,3565.0,29.0,,,,,,,,,,"Computer Science, Medicine"
17,"© 2022In this paper we present a benchmark dataset generated as part of a project for automatic identification of misogyny within online content, which focuses in particular on memes. The benchmark here described is composed of 800 memes collected from the most popular social media platforms, such as Facebook, Twitter, Instagram and Reddit, and consulting websites dedicated to collection and creation of memes. To gather misogynistic memes, specific keywords that refer to misogynistic content have been considered as search criterion, considering different manifestations of hatred against women, such as body shaming, stereotyping, objectification and violence. In parallel, memes with no misogynist content have been manually downloaded from the same web sources. Among all the collected memes, three domain experts have selected a dataset of 800 memes equally balanced between misogynistic and non-misogynistic ones. This dataset has been validated through a crowdsourcing platform, involving 60 subjects for the labelling process, in order to collect three evaluations for each instance. Two further binary labels have been collected from both the experts and the crowdsourcing platform, for memes evaluated as misogynistic, concerning aggressiveness and irony. Finally for each meme, the text has been manually transcribed. The dataset provided is thus composed of the 800 memes, the labels given by the experts and those obtained by the crowdsourcing validation, and the transcribed texts. This data can be used to approach the problem of automatic detection of misogynistic content on the Web relying on both textual and visual cues, facing phenomenons that are growing every day such as cybersexism and technology-facilitated violence.",2022-10-01,Journal,Data Paper,Data in Brief,21100372856,0,44,Benchmark dataset of memes with text transcriptions for automatic detection of multi-modal misogynistic content,1,true,10.1016/j.dib.2022.108526,Elsevier Inc.,17,Data in Brief,2021.0,12.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A benchmark dataset generated as part of a project for automatic identification of misogyny within online content, which focuses in particular on memes, is presented, composed of 800 memes collected from the most popular social media platforms and consulting websites dedicated to collection and creation of memes.'}",2032578,F. Gasparini,104163189,Giuliano Rizzi,51228436,Aurora Saibene,1847803,E. Fersini,,,,,181.0,5035.0,38.0,11.0,73.0,4.0,15.0,89.0,4.0,110.0,2476.0,23.0,,,,,,,"Medicine, Computer Science"
18,"© 2022 Elsevier LtdDue to Coronavirus diseases in 2020, all the countries departed into lockdown to combat the spread of the pandemic situation. Schools and institutions remain closed and students’ screen time surged. The classes for the students are moved to the digital platform which leads to an increase in social media usage. Many children had become sufferers of cyber harassment which includes threatening comments on young students, sexual torture through a digital platform, people insulting one another, and the use of fake accounts to harass others. The rising effort on automated cyber harassment detection utilizes many AI-related components Natural language processing techniques and machine learning approaches. Though machine learning models using different algorithms fail to converge with higher accuracy, it is much more important to use significant natural language processes and efficient classifiers to detect cyberbullying comments on social media. In this proposed work, the lexical meaning of the text is analysed by the conventional scheme and the word order of the text is performed by the Fast Text model to improve the computational efficacy of the model. The intention of the text is analysed by various feature extraction methods. The score for intention detection is calculated using the frequency of words with a bully-victim participation score. Finally, the proposed model's performance is measured by different evaluation metrics which illustrate that the accuracy of the model is higher than many other existing classification methods. The error rate is lesser for the detection model.",2022-10-01,Journal,Article,Engineering Applications of Artificial Intelligence,24182,0,115,Identification of cyber harassment and intention of target users on social media platforms,1,true,10.1016/j.engappai.2022.105283,Elsevier Ltd,18,Engineering applications of artificial intelligence,2022.0,37.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The proposed model’s performance is measured by different evaluation metrics which illustrate that the accuracy of the model is higher than many other existing classification methods, and the error rate is lesser for the detection model.'}",2388884,S. Abarna,2097904,J. I. Sheeba,2103235973,S. Jayasrilakshmi,9095137,S. Devaneyan,,,,,40.0,93.0,7.0,35.0,226.0,6.0,2.0,2.0,1.0,27.0,75.0,4.0,,,,,,,Medicine
19,"© 2022 ACM.Contemporary software development organizations are dominated by straight males and lack diversity. As a result, people from other demographic such as women and LGBTQ+ often encounter bias, sexism, and misogyny. Due to negative experiences, many women switch careers. Therefore, biases pose barriers to promote diversity and inclusion. To get benefits from diverse pools of talents and reduce the attrition rate of minorities, we need to identify the degree and effect of various biases and develop mitigation strategies. Therefore, my dissertation study aims at promoting diversity and inclusion among software development organizations by identifying the manifestation, magnitude, and frequency of various gender biases. For this purpose, I plan to investigate i) the effect of gender of the contributors in the code review process of Free/Libre Open Source Software (FLOSS) projects, ii) the frequency of different dimensions of gender bias and their effect, and iii) develop a tool to identify sexist and misogynistic and derogatory (SMD) texts.",2022-09-19,Conference Proceeding,Conference Paper,ACM International Conference Proceeding Series,21101132416,0,,Identification and Mitigation of Gender Biases to Promote Diversity and Inclusion among Open Source Communities,1,true,10.1145/3551349.3559571,Association for Computing Machinery,19,International Conference on Automated Software Engineering,2022.0,45.0,0.0,,2117276459,Sayma Sultana,,,,,,,,,,,7.0,13.0,2.0,,,,,,,,,,,,,,,,Computer Science
20,"© 2022 ACM.Being extremely dominated by men, software development organizations lack diversity. People from other groups often encounter sexist, misogynistic, and discriminatory (SMD) speech during communication. To identify SMD contents, I aim to build an automatic misogyny identification (AMI) tool for the domain of software developers. On this goal, I built a dataset of 10,138 pull request comments mined from Github based on a keyword-based selection, followed by manual validation. Using ten-fold cross-validation, I evaluated ten machine learning algorithms for automatic identification. The best performing model achieved 80% precision, 67.07% recall, 72.5% f-score, and 95.96% accuracy.",2022-09-19,Conference Proceeding,Conference Paper,ACM International Conference Proceeding Series,21101132416,0,,Identifying Sexism and Misogyny in Pull Request Comments,1,true,10.1145/3551349.3559515,Association for Computing Machinery,20,International Conference on Automated Software Engineering,2022.0,29.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This work aims to build an automatic misogyny identification (AMI) tool for the domain of software developers using a dataset of pull request comments mined from Github based on a keyword-based selection, followed by manual validation.'}",2117276459,Sayma Sultana,,,,,,,,,,,7.0,13.0,2.0,,,,,,,,,,,,,,,,Computer Science
21,"© 2022 Totem Publisher, Inc.With the rise in the usage of different social media platforms, social intimidation has increasingly spread into these forums as it has given us endless chances to post anything for anyone. Previous studies have confirmed that exposure to this online social intimidation can have very serious offline consequences. With the growth of these multimodal social media platforms, there is an urgent requirement of some device methods for social intimidation detection and prevention. However, most of the prior research has focused on only textual posts for one or two topics of intimidation, namely sexism and racism. The principal objective of this research is to recognize social intimidation from multimodal posts such as text, memes, videos and audio and to target various social media networks such as Instagram, Twitter, and Facebook for several topics of harassment, namely religion based, personal attack, racism, sexism, physical appearance, etc. Previous research has stopped at detection, but this research has taken one step ahead to test the severity based on hate prediction score. The research study is performed using a combination of big data technology, namely Apache Spark, and several deep learning methods which are described below. The system is validated on five public datasets i.e., MLMA Hate Speech Dataset, MMHS150K Dataset, Hateful Memes Dataset, Instagram, Vine Dataset and measured on the basis of precision, recall and f1-score. Performance of the system has been inspected individually for every category of post under three subsections. The results attained specify that the proposed approach gives more feasible solution for social intimidation detection and its severity in online social networking platforms.",2022-09-01,Journal,Article,International Journal of Performability Engineering,17500155116,1,18,Portable Learning Approach towards Capturing Social Intimidating Activities using Big Data and Deep Learning Technologies,0,false,10.23940/ijpe.22.09.p8.668678,Totem Publishers Ltd,21,International Journal of Performability Engineering,2022.0,0.0,0.0,,2057093464,Mansi Mahendru,1788776,S. Dubey,,,,,,,,,5.0,13.0,1.0,192.0,1528.0,19.0,,,,,,,,,,,,,Computer Science
22,"© 2022 University of Piura. All rights reserved.The spread of hate speech through social media contributes to poisoning the public sphere and undermining the quality of liberal democracies. This type of discourse is particularly virulent against the political class and against feminism. Taking this reality as a starting point, this research will attempt to identify the gender bias in hate speech in the political sphere: do female politicians receive more verbal attacks than their male counterparts, not because they are politicians, but because they are women? Do female politicians receive more emotional polarity in the mentions they receive on Twitter than their male counterparts? Through discourse analysis using PLN techniques for emotion detection and text mining on a corpus of 3,483,232 tweets collected from 20 accounts of Spanish politicians, it is found that the messages received by women politicians concentrate more emotional polarity than men’s, but not more hatred, which is slightly higher in men. It also confirms that sexist and misogynist expressions are used to denigrate women and, by extension, feminism, which makes hate speech a type of information disorder.",2022-09-01,Journal,Article,Revista de Comunicacion,21100863482,0,21,Polarization and hate speech with gender bias associated with politics: analysis of interactions on Twitter Polarización y discurso de odio con sesgo de género asociado a la política: análisis de las interacciones en Twitter,1,true,10.26441/RC21.2-2022-A2,University of Piura,22,Revista de Comunicación,2022.0,19.0,0.0,,2021583549,Ignacio Blanco-Alfonso,1412343274,Leticia Rodríguez-Fernández,1450705085,Sergio Arce-García,,,,,,,4.0,16.0,3.0,9.0,64.0,3.0,3.0,4.0,1.0,,,,,,,,,,
23,"© 2022 Sociedad Española para el Procesamiento del Lenguaje Natural.This paper presents an overview of the DETESTS shared task as part of the IberLEF 2022 Workshop on Iberian Languages Evaluation Forum, within the framework of the SEPLN 2022 conference. We proposed two hierarchical subtasks: For subtask 1, participants had to determine the presence of stereotypes in sentences. For subtask 2, participants had to classify the sentences labeled with stereotypes into ten categories. The DETESTS dataset contains 5,629 sentences in comments in response to newspaper articles related to immigration in Spanish. 51 teams signed up to participate, of which 39 sent runs, and 5 of them sent their working notes. In this paper, we provide information about the training and test datasets, the systems used by the participants, the evaluation metrics of the systems and their results.",2022-09-01,Journal,Review,Procesamiento del Lenguaje Natural,21100195304,5,69,Overview of DETESTS at IberLEF 2022: DETEction and classification of racial STereotypes in Spanish Resumen de la tarea de DETESTS en IberLEF 2022: DETEcción y clasificación de eSTereotipos raciales en eSpañol,,,10.26342/2022-69-19,Sociedad Espanola para el Procesamiento del Lenguaje Natural,23,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
24,"© 2022 Sociedad Española para el Procesamiento del Lenguaje Natural.The paper describes the organization, goals, and results of the sEXism Identification in Social neTworks (EXIST)2022 challenge, a shared task proposed for the second year at IberLEF. EXIST 2022 consists of two challenges: sexism identification and sexism categorization of tweets and gabs, both in Spanish and English. We have received a total of 45 runs for the sexism identification task and 29 runs for the sexism categorization task, submitted by 19 different teams. In this paper, we present the dataset, the evaluation methodology, an overview of the proposed systems, and the results obtained. The final dataset consists of more than 12,000 annotated texts from two social networks (Twitter and Gab) labelled following two different procedures: external contributors and trained experts.",2022-09-01,Journal,Review,Procesamiento del Lenguaje Natural,21100195304,17,69,Overview of EXIST 2022: sEXism Identification in Social neTworks Overview de EXIST 2022: Identificación de Sexismo en Redes Sociales,,,10.26342/2022-69-20,Sociedad Espanola para el Procesamiento del Lenguaje Natural,24,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
25,"© 2022 The Author(s)Social media platforms allow users worldwide to create and share information, forging vast sensing networks that allow information on certain topics to be collected, stored, mined, and analyzed in a rapid manner. During the COVID-19 pandemic, extensive social media mining efforts have been undertaken to tackle COVID-19 challenges from various perspectives. This review summarizes the progress of social media data mining studies in the COVID-19 contexts and categorizes them into six major domains, including early warning and detection, human mobility monitoring, communication and information conveying, public attitudes and emotions, infodemic and misinformation, and hatred and violence. We further document essential features of publicly available COVID-19 related social media data archives that will benefit research communities in conducting replicable and reproducible studies. In addition, we discuss seven challenges in social media analytics associated with their potential impacts on derived COVID-19 findings, followed by our visions for the possible paths forward in regard to social media-based COVID-19 investigations. This review serves as a valuable reference that recaps social media mining efforts in COVID-19 related studies and provides future directions along which the information harnessed from social media can be used to address public health emergencies.",2022-09-01,Journal,Article,International Journal of Applied Earth Observation and Geoinformation,39563,3,113,"Social media mining under the COVID-19 context: Progress, challenges, and opportunities",1,true,10.1016/j.jag.2022.102967,Elsevier B.V.,25,International Journal of Applied Earth Observation and Geoinformation,2022.0,233.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This review summarizes the progress of social media data mining studies in the COVID-19 contexts and categorizes them into six major domains, including early warning and detection, human mobility monitoring, communication and information conveying, public attitudes and emotions, infodemic and misinformation, and hatred and violence.'}",47933250,Xiao Huang,3240905,Siqin Wang,1500675300,Mengxi Zhang,152264546,T. Hu,2317042,A. Hohl,49338962,Bing She,45.0,258.0,7.0,60.0,358.0,10.0,29.0,232.0,8.0,24.0,379.0,9.0,27.0,556.0,10.0,36.0,416.0,11.0,Medicine
26,"© 2022 The AuthorsIntimate partner violence (IPV) is a preventable public health problem that affects millions of people worldwide. Approximately one in four women are estimated to be or have been victims of severe violence at some point in their lives, irrespective of age, ethnicity, and economic status. Victims often report IPV experiences on social media, and automatic detection of such reports via machine learning may enable improved surveillance and targeted distribution of support and/or interventions for those in need. However, no artificial intelligence systems for automatic detection currently exists, and we attempted to address this research gap. We collected posts from Twitter using a list of IPV-related keywords, manually reviewed subsets of retrieved posts, and prepared annotation guidelines to categorize tweets into IPV-report or non-IPV-report. We annotated 6,348 tweets in total, with the inter-annotator agreement (IAA) of 0.86 (Cohen's kappa) among 1,834 double-annotated tweets. The class distribution in the annotated dataset was highly imbalanced, with only 668 posts (∼11%) labeled as IPV-report. We then developed an effective natural language processing model to identify IPV-reporting tweets automatically. The developed model achieved classification F1-scores of 0.76 for the IPV-report class and 0.97 for the non-IPV-report class. We conducted post-classification analyses to determine the causes of system errors and to ensure that the system did not exhibit biases in its decision making, particularly with respect to race and gender. Our automatic model can be an essential component for a proactive social media-based intervention and support framework, while also aiding population-level surveillance and large-scale cohort studies.",2022-09-01,Journal,Article,Array,21101080486,0,15,Natural language model for automatic identification of Intimate Partner Violence reports from Twitter,1,true,10.1016/j.array.2022.100217,Elsevier B.V.,26,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
27,"© 2022 Elsevier LtdHate speech on online social media platforms is now at a level that has been considered a serious concern by governments, media outlets, and scientists, especially because it is easily spread, promoting harm to individuals and society, and made it virtually impossible to tackle with using just human analysis. Automatic approaches using machine learning and natural language processing are helpful for detection. For such applications, amongst several different approaches, it is essential to investigate the systems’ robustness to deal with biases towards identity terms (gender, race, religion, for example). In this work, we analyse gender bias in different datasets and proposed a ensemble learning approach based on different feature spaces for hate speech detection with the aim that the model can learn from different abstractions of the problem, namely unintended bias evaluation metrics. We have used nine different feature spaces to train the pool of classifiers and evaluated our approach on a publicly available corpus, and our results demonstrate its effectiveness compared to state-of-the-art solutions.",2022-09-01,Journal,Article,Expert Systems with Applications,24201,2,201,Unintended bias evaluation: An analysis of hate speech detection and gender bias mitigation on social media using ensemble learning,0,false,10.1016/j.eswa.2022.117032,Elsevier Ltd,27,Expert systems with applications,2022.0,62.0,0.0,,2061490804,Francimaria Rayanne dos Santos Nascimento,1805618,George D. C. Cavalcanti,1405598963,Márjory Da Costa-Abreu,,,,,,,2.0,2.0,1.0,214.0,3156.0,28.0,66.0,567.0,13.0,,,,,,,,,,Computer Science
28,"© 2022, The Author(s), under exclusive licence to Springer Nature B.V.In this article, we guide readers through a narrative tour of the Cesare Lombroso Museum of Criminal Anthropology (Museo di Antropologia Criminale Cesare Lombroso) in Turin, Italy. We describe and analyze the museum’s displays, pointing to the rhetorical devices and narrative strategies employed to “whitewash” Lombroso’s historical legacy and the destructive pseudoscientific endeavor of criminal anthropology. The museum is imbued with an apologist narrative that reinforces the myth of Western progress as humanity’s consummate achievement and largely dismisses Lombroso’s white supremacy and misogyny as “flaws” in his work rather than symptomatic of dominant ideology. We argue that, by eliding discussions of the sexism, racism, and colonial logic inherent to Lombroso’s work, as well as the countless social harms that have resulted from his legacy, the museum, itself, perpetuates social harm.",2022-09-01,Journal,Article,Critical Criminology,145137,1,30,Whitewashing Criminology: A Critical Tour of Cesare Lombroso’s Museum of Criminal Anthropology,0,false,10.1007/s10612-021-09604-x,Springer Science and Business Media B.V.,28,Critical Criminology,2022.0,60.0,0.0,,3751771,Tammi Arford,7190436,Eric Madfis,,,,,,,,,18.0,219.0,4.0,47.0,634.0,14.0,,,,,,,,,,,,,
29,"© Edinburgh University Press.The paper presents a two-part forensic linguistic analysis of an historic collection of abuse letters, sent to individuals in the public eye and individuals’ private homes between 2007 and 2009. We employ the technique of structural topic modelling (STM) to identify distinctions in the core topics of the letters, gauging the value of this relatively under-used methodology in forensic linguistics. Four key topics were identified in the letters, ‘Politics A’ and ‘B’, ‘Healthcare’ and ‘Immigration’, and their coherence, correlation and shifts in topic were evaluated. Following the STM, a qualitative corpus linguistic analysis was undertaken, coding concordance lines according to topic, with the reliability between coders tested. This coding demonstrated that various connected statements within the same topic tend to gain or lose prevalence over time, and ultimately confirmed the consistency of content within the four topics identified through STM throughout the letter series. The discussion and conclusions to the paper reflect on the findings and also consider the utility of these methodologies for linguistics and forensic linguistics in particular. The study demonstrates real value in revisiting a forensic linguistic dataset such as this to test and develop methodologies for the field.",2022-08-01,Journal,Article,Corpora,6200158425,1,17,Operation Heron: latent topic changes in an abusive letter series,2,,10.3366/cor.2022.0255,Edinburgh University Press,29,Corpora,2021.0,40.0,0.0,,145778984,Lucia Busso,94952574,Márton Petykó,2055967483,S. Atkins,49364012,Tim D. Grant,,,,,22.0,23.0,3.0,7.0,8.0,2.0,6.0,17.0,3.0,96.0,1211.0,22.0,,,,,,,History
30,"© The Author(s) 2022.The phrase “the personal is political” is commonly associated with 1970s feminists, for whom it denoted the relationship between personal experiences and broad systems of inequality. However, considering bell hooks’ argument that feminists have lost the power analysis fundamental to the relationship between the personal and the political, we assess the relevance of the notion the ‘personal is political,’ to our work as feminist criminologists. Building on hooks’ insight, we argue there is a need to take up an intersectional and anti-racist feminist praxis that centers multiple forms of oppression in scholarship and seeks greater accountability for sexism, racism, and transphobia both within and beyond academic spaces. We elaborate our ideas by, first, outlining the intellectual history and evolution of feminist criminology. Second, we examine how the relationship between the personal and political figures in the work of minoritized scholars. Third, we discuss the necessary discomforts associated with working towards an intersectional and antiracist feminist criminology.",2022-07-01,Journal,Article,Race and Justice,21100817648,1,12,"The Personal is Political and so is Discomfort: Intersectional, Anti-Racist Praxis in Feminist Criminology",0,false,10.1177/21533687221101793,SAGE Publications Inc.,30,Race and Justice,2022.0,114.0,0.0,,5448562,V. Rajah,38853405,Jane E. Palmer,144010988,M. Duggan,,,,,,,32.0,875.0,15.0,47.0,345.0,9.0,96.0,386.0,8.0,,,,,,,,,,
31,"© 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.Machine learning models are known to perpetuate and even amplify the biases present in the data. However, these data biases frequently do not become apparent until after the models are deployed. Our work tackles this issue and enables the preemptive analysis of large-scale datasets. REvealing VIsual biaSEs (REVISE) is a tool that assists in the investigation of a visual dataset, surfacing potential biases along three dimensions: (1) object-based, (2) person-based, and (3) geography-based. Object-based biases relate to the size, context, or diversity of the depicted objects. Person-based metrics focus on analyzing the portrayal of people within the dataset. Geography-based analyses consider the representation of different geographic locations. These three dimensions are deeply intertwined in how they interact to bias a dataset, and REVISE sheds light on this; the responsibility then lies with the user to consider the cultural and historical context, and to determine which of the revealed biases may be problematic. The tool further assists the user by suggesting actionable steps that may be taken to mitigate the revealed biases. Overall, the key aim of our work is to tackle the machine learning bias problem early in the pipeline. REVISE is available at https://github.com/princetonvisualai/revise-tool.",2022-07-01,Journal,Article,International Journal of Computer Vision,72242,0,130,REVISE: A Tool for Measuring and Mitigating Bias in Visual Datasets,2,,10.1007/s11263-022-01625-5,Springer,31,International Journal of Computer Vision,2020.0,119.0,3.0,"{'model': 'tldr@v2.0.0', 'text': 'The key aim of the work is to tackle the machine learning bias problem early in the pipeline, and enables the preemptive analysis of large-scale datasets.'}",46991154,Angelina Wang,47735253,A. Narayanan,2192178,Olga Russakovsky,,,,,,,13.0,259.0,7.0,138.0,16637.0,51.0,59.0,33048.0,26.0,,,,,,,,,,Computer Science
32,"© 2022 The Author(s)While social media offers freedom of self-expression, abusive language carry significant negative social impact. Driven by the importance of the issue, research in the automated detection of abusive language has witnessed growth and improvement. However, these detection models display a reliance on strongly indicative keywords, such as slurs and profanity. This means that they can falsely (1a) miss abuse without such keywords or (1b) flag non-abuse with such keywords, and that (2) they perform poorly on unseen data. Despite the recognition of these problems, gaps and inconsistencies remain in the literature. In this study, we analyse the impact of keywords from dataset construction to model behaviour in detail, with a focus on how models make mistakes on (1a) and (1b), and how (1a) and (1b) interact with (2). Through the analysis, we provide suggestions for future research to address all three problems.",2022-07-01,Journal,Article,Online Social Networks and Media,21100901582,1,30,Hidden behind the obvious: Misleading keywords and implicitly abusive language on social media,1,true,10.1016/j.osnem.2022.100210,Elsevier B.V.,32,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33,"© 2022, Kauno Technologijos Universitetas. All rights reserved.Homophobic expressions are a form of insulting the sexual orientation or personality of people. Severe psychological traumas may occur in people who are exposed to this type of communication. It is important to develop automatic classification systems based on language models to examine social media content and distinguish homophobic discourse. This study aims to present a pre-trained Multilingual Bidirectional Encoder Representations from Transformers (M-BERT) model that can successfully detect whether Turkish comments on social media contain homophobic or related hate comments (i.e., sexist, severe humiliation, and defecation expressions). Comments in the Homophobic-Abusive Turkish Comments (HATC) dataset were collected from Instagram to train the detection models. The HATC dataset was manually labeled at the sentence level and combined with the Abusive Turkish Comments (ATC) dataset that has developed in our previous study. The HATC dataset has been balanced using the resampling method and two forms of the dataset (i.e., resHATC and original HATC) were used in the experiments. Afterward, the M-BERT model was compared with DL-based models (i.e., Long-Short Term Memory, Bidirectional Long-Short Term Memory (BiLSTM), Gated Recurrent Unit), Traditional Machine Learning (TML) classifiers (i.e., Support Vector Machine, Naive Bayes, Random Forest) and Ensemble Classifiers (i.e., Adaptive Boosting, eXtreme Gradient Boosting, Gradient Boosting) for the best model selection. The performance of the detection models was evaluated using F1-score, precision, and recall performance metrics. Results showed the best performance (homophobic F1-score: 82.64%, hateful F1-score: 91.75%, neutral F1-score: 96.08%, average F1-score: 90.15%) were achieved with the M-BERT model on the HATC dataset. The M-BERT detection model can increase the effectiveness of filters in detecting Turkish homophobic and related hate speech in social networks. It can be used to detect homophobic and related hate speech for different languages since the M-BERT model has multilingual pre-trained data.",2022-06-23,Journal,Article,Information Technology and Control,19700174611,1,51,Homophobic and Hate Speech Detection Using Multilingual-BERT Model on Turkish Social Media,1,true,10.5755/j01.itc.51.2.29988,Kauno Technologijos Universitetas,33,Information Technology and Control,2022.0,98.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A pre-trained Multilingual Bidirectional Encoder Representations from Transformers (M-BERT) model that can successfully detect whether Turkish comments on social media contain homophobic or related hate comments and increase the effectiveness of filters in detecting Turkish homophobic and related hate speech in social networks is presented.'}",95925384,Habibe Karayigit,2236535,A. Akdagli,28336630,C. Aci,,,,,,,5.0,15.0,2.0,85.0,1260.0,18.0,25.0,269.0,8.0,,,,,,,,,,Computer Science
34,"© 2022 ACM.The ""Decentralised Web""(DW) is an evolving concept, which encompasses technologies aimed at providing greater transparency and openness on the web. The DW relies on independent servers (aka instances) that mesh together in a peer-to-peer fashion to deliver a range of services (e.g. micro-blogs, image sharing, video streaming). However, toxic content moderation in this decentralised context is challenging. This is because there is no central entity that can define toxicity, nor a large central pool of data that can be used to build universal classifiers. It is therefore unsurprising that there have been several high-profile cases of the DW being misused to coordinate and disseminate harmful material. Using a dataset of 9.9M posts from 117K users on Pleroma (a popular DW microblogging service), we quantify the presence of toxic content. We find that toxic content is prevalent and spreads rapidly between instances. We show that automating per-instance content moderation is challenging due to the lack of sufficient training data available and the effort required in labelling. We therefore propose and evaluate ModPair, a model sharing system that effectively detects toxic content, gaining an average per-instance macro-F1 score 0.89.",2022-06-01,Journal,Article,Proceedings of the ACM on Measurement and Analysis of Computing Systems,21101048533,1,6,Toxicity in the Decentralized Web and the Potential for Model Sharing,2,,10.1145/3530901,Association for Computing Machinery,34,Proceedings of the ACM on Measurement and Analysis of Computing Systems,2022.0,85.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'ModPair is proposed and evaluated, a model sharing system that effectively detects toxic content and gains an average per-instance macro-F1 score 0.89, which shows that automating per- instance content moderation is challenging due to the lack of sufficient training data available and the effort required in labelling.'}",2066010806,Haris Bin Zia,37594946,Aravindh Raman,2085689125,Ignacio Castro,2173928449,Ishaku Hassan Anaobi,2064581974,Emiliano De Cristofaro,2440079,Nishanth R. Sastry,11.0,54.0,5.0,37.0,295.0,9.0,18.0,238.0,6.0,1.0,0.0,0.0,22.0,316.0,7.0,150.0,2254.0,26.0,Computer Science
35,"© 2022 by the authors. Licensee MDPI, Basel, Switzerland.Online toxic discourses could result in conflicts between groups or harm to online communities. Hate speech is complex and multifaceted harmful or offensive content targeting individuals or groups. Existing literature reviews have generally focused on a particular category of hate speech, and to the best of our knowledge, no review has been dedicated to hate speech datasets. This paper systematically reviews textual hate speech detection systems and highlights their primary datasets, textual features, and machine learning models. The results of this literature review are integrated with content analysis, resulting in several themes for 138 relevant papers. This study shows several approaches that do not provide consistent results in various hate speech categories. The most dominant sets of methods combine more than one deep learning model. Moreover, the analysis of several hate speech datasets shows that many datasets are small in size and are not reliable for various tasks of hate speech detection. Therefore, this study provides the research community with insights and empirical evidence on the intrinsic properties of hate speech and helps communities identify topics for future work.",2022-06-01,Journal,Review,Information (Switzerland),21100223111,5,13,A Literature Review of Textual Hate Speech Detection Methods and Datasets,1,true,10.3390/info13060273,MDPI,35,Inf.,2022.0,160.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This study shows several approaches that do not provide consistent results in various hate speech categories and shows that many datasets are small in size and are not reliable for various tasks of hate speech detection.'}",2032196403,Fatimah Alkomah,2140407137,Xiaogang Ma,,,,,,,,,3.0,8.0,2.0,9.0,11.0,2.0,,,,,,,,,,,,,Computer Science
36,"© 2021 Association for Computing Machinery.Authorship attribution refers to examining the writing style of authors to determine the likelihood of the original author of a document from a given set of potential authors. Due to the wide range of authorship attribution applications, a plethora of studies have been conducted for various Western, as well as Asian, languages. However, authorship attribution research in the Urdu language has just begun, although Urdu is widely acknowledged as a prominent South Asian language. Furthermore, the existing studies on authorship attribution in Urdu have addressed a considerably easier problem of having less than 20 candidate authors, which is far from the real-world settings. Therefore, the findings from these studies may not be applicable to the real-world settings. To that end, we have made three key contributions: First, we have developed a large authorship attribution corpus for Urdu, which is a low-resource language. The corpus is composed of over 2.6 million tokens and 21,938 news articles by 94 authors, which makes it a closer substitute to the real-world settings. Second, we have analyzed hundreds of stylometry features used in the literature to identify 194 features that are applicable to the Urdu language and developed a taxonomy of these features. Finally, we have performed 66 experiments using two heterogeneous datasets to evaluate the effectiveness of four traditional and three deep learning techniques. The experimental results show the following: (a) Our developed corpus is many folds larger than the existing corpora, and it is more challenging than its counterparts for the authorship attribution task, and (b) Convolutional Neutral Networks is the most effective technique, as it achieved a nearly perfect F1 score of 0.989 for an existing corpus and 0.910 for our newly developed corpus.",2022-05-01,Journal,Article,ACM Transactions on Asian and Low-Resource Language Information Processing,21100784666,0,21,Authorship Attribution for a Resource Poor Language-Urdu,0,false,10.1145/3487061,Association for Computing Machinery,36,ACM Trans. Asian Low Resour. Lang. Inf. Process.,2021.0,65.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A large authorship attribution corpus for Urdu is developed and hundreds of stylometry features used in the literature are identified that are applicable to the Urdu language and developed a taxonomy of these features.'}",2145364729,Zulqarnain Nazir,2060568902,Khurram Shahzad,49012522,M. K. Malik,65860614,Waheed Anwar,2798654,Imran Sarwar Bajwa,145685057,Khawar Mehmood,1.0,0.0,0.0,33.0,80.0,3.0,52.0,527.0,13.0,14.0,148.0,8.0,190.0,1616.0,21.0,17.0,128.0,5.0,Computer Science
37,"© 2022 The Author(s)This paper presents a novel deep learning architecture for identifying outliers in the context of intelligent transportation systems. The use of a convolutional neural network with an efficient decomposition strategy is explored to find the anomalous behavior of urban traffic flow data. The urban traffic flow data set is decomposed into similar clusters, each containing homogeneous data. The convolutional neural network is used for each data cluster. In this way, different models are trained, each learned from highly correlated data. A merging strategy is finally used to fuse the results of the obtained models. To validate the performance of the proposed framework, intensive experiments were conducted on urban traffic flow data. The results show that our system outperforms the competition on several accuracy criteria.",2022-05-01,Journal,Article,Computer Communications,13681,1,189,Intelligent deep fusion network for urban traffic flow anomaly identification,1,true,10.1016/j.comcom.2022.03.021,Elsevier B.V.,37,Computer Communications,2022.0,48.0,0.0,,2816085,Y. Djenouri,2210067,Asma Belhadi,2145278783,Hsing-Chung Chen,2146245811,Chun-Wei Lin,,,,,159.0,2181.0,26.0,70.0,792.0,16.0,5.0,33.0,3.0,5.0,11.0,1.0,,,,,,,Computer Science
38,"© 2021 The Author(s)In general, people are usually more reluctant to follow advice and directions from politicians who do not have their ideology. In extreme cases, people can be heavily biased in favour of a political party at the same time that they are in sharp disagreement with others, which may lead to irrational decision making and can put people's lives at risk by ignoring certain recommendations from the authorities. Therefore, considering political ideology as a psychographic trait can improve political micro-targeting by helping public authorities and local governments to adopt better communication policies during crises. In this work, we explore the reliability of determining psychographic traits concerning political ideology. Our contribution is twofold. On the one hand, we release the PoliCorpus-2020, a dataset composed by Spanish politicians’ tweets posted in 2020. On the other hand, we conduct two authorship analysis tasks with the aforementioned dataset: an author profiling task to extract demographic and psychographic traits, and an authorship attribution task to determine the author of an anonymous text in the political domain. Both experiments are evaluated with several neural network architectures grounded on explainable linguistic features, statistical features, and state-of-the-art transformers. In addition, we test whether the neural network models can be transferred to detect the political ideology of citizens. Our results indicate that the linguistic features are good indicators for identifying fine-grained political affiliation, they boost the performance of neural network models when combined with embedding-based features, and they preserve relevant information when the models are tested with ordinary citizens. Besides, we found that lexical and morphosyntactic features are more effective on author profiling, whereas stylometric features are more effective in authorship attribution.",2022-05-01,Journal,Article,Future Generation Computer Systems,12264,25,130,Psychographic traits identification based on political ideology: An author analysis study on Spanish politicians’ tweets posted in 2020,1,true,10.1016/j.future.2021.12.011,Elsevier B.V.,38,Future generations computer systems,2021.0,54.0,1.0,,1409250207,J. García-Díaz,40622419,Ricardo Colomo Palacios,1398759108,R. Valencia-García,,,,,,,53.0,294.0,9.0,255.0,4982.0,38.0,208.0,3480.0,32.0,,,,,,,,,,Computer Science
39,"© 2020 SAGE Publications.The instance of image-based abuse that ended in the victim’s suicide, known as the “Iveco case,” had an unprecedented social impact in Spain in 2019. This case provoked a great social reaction and became particularly viral on social networks such as Twitter. The present research investigates how this case has been dealt with through Twitter discourse. In particular, this study aimed to identify the main elements that could explain how people engaged with the problem of nonconsensual sharing of sexually explicit images in general, and with this case in particular. In total, 1,895 tweets with the word “Iveco” written in Spain were selected by streaming API, and their content was analyzed by lexical analysis using Iramuteq software (Reinert method). This software carries out an automatic lexical classification cluster analysis that groups the most significant words and text segments according to their co-occurrence. The results revealed that, on Twitter, it was stressed that the victim was a married woman with children who had practiced sexting. However, in response to this initial description, many voices also emerged that labelled this image-based abuse as gender-based online violence. Criticism was aimed at both the passivity of the company, and the attitude of hundreds of thousands of people who share the sexting video by WhatsApp groups without permission. Consequently, several feminist mobilizations emerged, framing this case within a sexist and patriarchal society and asking for accountability. However, in contrast, countermovements such as the #NotAllMen also emerged.",2022-05-01,Journal,Article,Journal of Interpersonal Violence,20374,6,37,Image-based Abuse: Debate and Reflections on the “Iveco Case” in Spain on Twitter,0,false,10.1177/0886260520967143,SAGE Publications Inc.,39,Journal of Interpersonal Violence,2020.0,105.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The present research investigates how the Iveco case has been dealt with through Twitter discourse, and identifies the main elements that could explain how people engaged with the problem of nonconsensual sharing of sexually explicit images in general and with this case in particular.'}",115237513,Nahia Idoiaga Mondragón,2066449581,M. Santamaría,2096971721,Maitane Belasko Txertudi,2074132255,Israel Alonso Sáez,,,,,28.0,576.0,10.0,9.0,150.0,6.0,3.0,27.0,3.0,3.0,14.0,2.0,,,,,,,"Medicine, Sociology"
40,"© 2022, The Author(s).Satirical content on social media is hard to distinguish from real news, misinformation, hoaxes or propaganda when there are no clues as to which medium these news were originally written in. It is important, therefore, to provide Information Retrieval systems with mechanisms to identify which results are legitimate and which ones are misleading. Our contribution for satire identification is twofold. On the one hand, we release the Spanish SatiCorpus 2021, a balanced dataset that contains satirical and non-satirical documents. On the other hand, we conduct an extensive evaluation of this dataset with linguistic features and embedding-based features. All feature sets are evaluated separately and combined using different strategies. Our best result is achieved with a combination of the linguistic features and BERT with an accuracy of 97.405%. Besides, we compare our proposal with existing datasets in Spanish regarding satire and irony.",2022-04-01,Journal,Article,Complex and Intelligent Systems,21101095931,10,8,Compilation and evaluation of the Spanish SatiCorpus 2021 for satire identification using linguistic features and transformers,1,true,10.1007/s40747-021-00625-1,Springer International Publishing,40,Complex & Intelligent Systems,2022.0,26.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The Spanish SatiCorpus 2021 is released, a balanced dataset that contains satirical and non-satirical documents and an extensive evaluation of this dataset with linguistic features and embedding-based features for satire identification is conducted.'}",1409250207,J. García-Díaz,1398759108,R. Valencia-García,,,,,,,,,53.0,294.0,9.0,208.0,3480.0,32.0,,,,,,,,,,,,,
41,"© 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.Cyberbullying is a menace in today’s socially networked world. It can have damaging physical and mental effects on the victims and hence, it needs to be tackled efficiently—several detection approaches are proposed in literature but those are mostly standalone. In this paper, we revisit the distributed and collaborative approach for detecting cyberbullying behavior using machine learning algorithms—a comprehensive enhancement of our past work—that uses many local and cloud-based collaborative configurations and different datasets. It contains a set of nodes, called detection nodes, which can identify cyberbullying employing Machine Learning classification algorithms and collaborate with each other as needed. Several experiments, consisting of various collaborative patterns, different scales, and failure scenarios, have been carried out using different Twitter© datasets in this study. The empirical results obtained from the experimentation show that the proposed approach is generic (i.e., allows the incorporation of different learning and collaborative techniques), and achieves better recall and precision values when compared with the stand-alone paradigm.",2022-04-01,Journal,Article,Cluster Computing,24596,1,25,Enhancing collaborative detection of cyberbullying behavior in Twitter data,0,false,10.1007/s10586-021-03483-1,Springer,41,,2022.0,0.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The empirical results obtained from the experimentation show that the proposed distributed and collaborative approach for detecting cyberbullying behavior using machine learning algorithms is generic, and achieves better recall and precision values when compared with the stand-alone paradigm.'}",,Amrita Mangaonkar,144528637,Rohit Pawar,,Nahida Sultana Chowdhury,,Rajeev R. Raje,,,,,,,,6.0,74.0,3.0,,,,,,,,,,,,,
42,"© 2022 by the authors. Licensee MDPI, Basel, Switzerland.Hate Speech is a frequent problem occurring among Internet users. Recent regulations are being discussed by U.K. representatives (“Online Safety Bill”) and by the European Commission, which plans on introducing Hate Speech as an “EU crime”. The recent legislation having passed in order to combat this kind of speech places the burden of identification on the hosting websites and often within a tight time frame (24 h in France and Germany). These constraints make automatic Hate Speech detection a very important topic for major social media platforms. However, recent literature on Hate Speech detection lacks a benchmarking system that can evaluate how different approaches compare against each other regarding the prediction made concerning different types of text (short snippets such as those present on Twitter, as well as lengthier fragments). This paper intended to deal with this issue and to take a step forward towards the standardization of testing for this type of natural language processing (NLP) application. Furthermore, this paper explored different transformer and LSTM-based models in order to evaluate the performance of multi-task and transfer learning models used for Hate Speech detection. Some of the results obtained in this paper surpassed the existing ones. The paper concluded that transformer-based models have the best performance on all studied Datasets.",2022-03-01,Journal,Article,Mathematics,21100830702,1,10,Towards a Benchmarking System for Comparing Automatic Hate Speech Detection with an Intelligent Baseline Proposal,1,true,10.3390/math10060945,MDPI,42,Mathematics,2022.0,17.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper explored different transformer and LSTM- based models in order to evaluate the performance of multi-task and transfer learning models used for Hate Speech detection and concluded that transformer-based models have the best performance on all studied Datasets.'}",118617079,Stefan Dascalu,1774257,Florentina Hristea,,,,,,,,,3.0,2.0,1.0,29.0,338.0,10.0,,,,,,,,,,,,,
43,"© 2022 ACM.While the rise in popularity of social media is seen as a hugely positive development, it is also accompanied by a proliferation of hate speech, which has recently become a major concern. On the one hand, hateful content creates an unsafe environment for certain members of society. On the other hand, manual moderation causes distress to content moderators, and the volume of harmful content is far beyond what human moderators can manually flag and react to. Thus, researchers in machine learning, social computing, and other areas have worked on developing tools to help automate the process. While initially studied as a text classification problem, over time, researchers realized that hate speech is multi-faceted and requires analysis of the role of linguistic expressions, context, and network structure, while using inspiration from psychology and user behavior, among others. With this in mind, we provide a holistic view of what the research community has explored so far, and what we believe are promising future research directions.",2022-02-11,Conference Proceeding,Conference Paper,WSDM 2022 - Proceedings of the 15th ACM International Conference on Web Search and Data Mining,21101079204,0,,"Half-day tutorial on combating online hate speech: The role of content, networks, psychology, user behavior, etc",0,false,10.1145/3488560.3501392,"Association for Computing Machinery, Inc",43,Web Search and Data Mining,2022.0,64.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A holistic view of what the research community has explored so far in hate speech, and what it believes are promising future research directions is provided.'}",36715403,Sarah Masud,2154453198,Pinkesh Pinkesh,48806891,Amitava Das,2109835812,Manish Gupta,2026545715,Preslav Nakov,144054829,Tanmoy Chakraborty,9.0,70.0,5.0,1.0,0.0,0.0,98.0,1586.0,20.0,4.0,0.0,0.0,63.0,756.0,16.0,279.0,3052.0,28.0,Computer Science
44,"© 2022 AUFOP. All rights reserved.In our schools, sex education is a matter that still needs to be addressed. Above all, if we consider that its objectives should include the development of a responsible sexuality, free from prejudice and respectful of differences and not only focused on the preventive model. An essential part of this content should be the analysis of sexism present in our society and its consequences in daily life, among other things. This work analyses the knowledge and attitudes of 668 students at the University of Huelva regarding sexism, double standards and the erotophilia/erotophobia dimension, conducts that favour the appearance of undesirable behaviours such as discrimination on the basis of sex. To this end, they filled in a sociodemographic inventory and three specific questionnaires (EROS scale, Double Standard scale and Ambivalent Sexism questionnaire). The results are consistent with those of other studies in which heterosexual males scored significantly higher on all the studied variables, notably the hostile sexism scale, especially in students carrying out their training in the area of physical education and sport who declared their heterosexuality and right-leaning political orientation. In turn, the erotophilia variable is identified as a predictor of achieving lower scores in double standards and in sexism, allowing us to conclude that a positive attitude towards sexuality that encourages increasing knowledge of the same makes us less prejudicial and less discriminatory. They thus provide new evidence of the importance of training in sexuality for future educators if the aim is to transfer tolerant and egalitarian attitudes to the classroom.",2022-01-01,Journal,Article,Revista Electronica Interuniversitaria de Formacion del Profesorado,21100902635,0,25,Training of university students in gender and sexuality as a preventive strategy against classroom sexism La formación del alumnado universitario en género y sexualidad como estrategia preventiva del sexismo en las aulas,1,true,10.6018/reifop.533411,AUFOP,44,Revista Electronica Interuniversitaria de Formación del Profesorado,2022.0,0.0,0.0,,2188122986,Antonio Daniel García Rojas,2188120808,F. J. Del Río Olvera,2188121840,Carmen Santín Vilariño,,,,,,,2.0,0.0,0.0,2.0,0.0,0.0,1.0,0.0,0.0,,,,,,,,,,
45,"© 2022 IEEE.Freedom of speech on social media is often abused to express inappropriate speech against individuals or groups. One form of social media abuse is misogyny utterance. Misogyny is hatred directed at women. The number of misogyny utterances on social media keeps increasing. Detection of misogyny needs to be done to prevent misogyny utterances. This work examines misogyny on Twitter and proposes a method to detect it. The dataset used comes from tweets on social media Twitter related to women. The experiment in this work was done by comparing the effect of BERT Embedding for Logistic Regression, Convolutional Neural Network, and Long Short-Term Memory. The performance of the methods tested was evaluated based on the resulting accuracy. This work showed that BERT with LSTM surpassed other methods with 86.15% accuracy. The model could outperform other methods because it understands more about the context of the data.",2022-01-01,Conference Proceeding,Conference Paper,"ICOIACT 2022 - 5th International Conference on Information and Communications Technology: A New Way to Make AI Useful for Everyone in the New Normal Era, Proceeding",21101129749,0,,Misogyny Speech Detection Using Long Short-Term Memory and BERT Embeddings,0,false,10.1109/ICOIACT55506.2022.9972171,Institute of Electrical and Electronics Engineers Inc.,45,2022 5th International Conference on Information and Communications Technology (ICOIACT),2022.0,18.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This work examines misogyny on Twitter and proposes a method to detect it by comparing the effect of BERT Embedding for Logistic Regression, Convolutional Neural Network, and Long Short-Term Memory.'}",2196746400,Rizkyta Shainy Angeline,1854311,Dade Nurjanah,9453258,Hani Nurrahmi,,,,,,,1.0,0.0,0.0,34.0,146.0,7.0,8.0,35.0,3.0,,,,,,,,,,
53,"© 2022 Wolters Kluwer Medknow Publications. All rights reserved.Cyberbullying is a kind of bullying that takes place via social media with digital gadgets. It may cause significant, long-lasting trauma and difficulties with mental and physical issues. This condition may also result in difficulties in personal lives. Because of this, detecting and reporting such offensive posts may help avoid the harmful repercussions of cyberbullying. Some studies are available in this context, and it was found that deep learning algorithms are more efficient in detecting abusive texts on social media. Some studies were carried out on deep learning algorithms. The issue was not solved, and more studies are needed to find the most efficient model to control this problem. It was observed from the literature survey that the performance of Recurrent Neural Network (RNN) architectures is good. Therefore, the objective of this study was to find and develop an efficient model to detect cyberbullying texts on social media. For this research, the Twitter dataset was used, which was uploaded by Munki Albright in Kaggle. The dataset consists suspicious, cyberbullying, hate and suicidal classifications. This research was focused on cyberbullying texts. Sentiment analysis was implemented to classify the cyberbullying posts. For that, sexism (Class 2), racism (Class 1) and either (Class 0) classification were analyzed. Researchers applied the LSTM, GRU and Bidirectional LSTM architectures of RNN to perform the sentiment analysis. All models gave somewhat similar results. When we consider f1, GRU shows a better F1 score for all the classes when compared to others (Class 0 was 95%, Class 1-70%, and Class 0 was 56%). GRU shows the best results for this data set compared to other models. Based on the Accuracy, all three architectures were obtained at around 90%. However, GRU has outperformed the other two models in accuracy as well. After that, researchers developed an ensemble model using all three models. In the ensemble, each model has been given weight. Since the GRU is the best performing model, it was given 0.4, and the other two models were assigned 0.3 each. The ensemble model performed well in F1 measurement (57%) and accuracy (91.17%). When we compared the previous works against the proposed model, our ensemble model obtained the highest values and performed well in detecting cyberbullying in sentiment analysis.",2022-01-01,Journal,Article,Journal of Pharmaceutical Negative Results,21100216519,0,13,Detection of Cyberbullying in Social Media to Control Users' Mental Health Issues Using Recurrent Neural Network Architectures,1,true,10.47750/pnr.2022.13.S03.072,ResearchTrentz Academy Publishing Education Services,53,Journal of Pharmaceutical Negative Results,2022.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
54,"© 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.Recent research indicates that some young people initially learn about sexual choking through Internet memes. Thus, a qualitative content analysis was performed on 316 visual and textual memes collected from various social media websites and online searches to assess salient categories related to choking during sex. We identified nine main categories: communication, gendered dynamics, choking as dangerous, choking as sexy, sexualization of the nonsexual, shame and worry, romance/rough sex juxtaposition, choking and religious references, instructional/informational. Given that memes, through their humor, can make difficult topics more palatable and minimize potential harm in the phenomenon they depict, more concerted, synergistic effort that integrates media literacy into sexuality education programming on the potential risks that may ensue for those engaging in sexual choking is warranted.",2022-01-01,Journal,Article,Archives of Sexual Behavior,27562,0,,#ChokeMeDaddy: A Content Analysis of Memes Related to Choking/Strangulation During Sex,1,true,10.1007/s10508-022-02502-5,Springer,54,Archives of Sexual Behavior,2022.0,67.0,0.0,,51912336,D. Herbenick,1400053956,L. Guerra-Reyes,2048134231,Callie L. Patterson,80376069,Jodi Wilson,2118830551,Yael R Rosenstock Gonzalez,1596566397,Eva Voorheis,242.0,5791.0,39.0,49.0,566.0,12.0,14.0,61.0,4.0,6.0,2.0,1.0,7.0,27.0,3.0,7.0,35.0,3.0,Medicine
56,"© 2022 Taylor and Francis.The seventh edition of this field-leading textbook provides an accessible and rigorous presentation of major theories of persuasion and their applications to a variety of real-world contexts. In addition to presenting established theories and models, this text encourages students to develop and apply general conclusions about persuasion in real-world settings. Along the way, students are introduced to the practice of social influence in an array of contexts (e.g., advertising, marketing, politics, interpersonal relationships, social media, groups) and across a variety of topics (e.g., credibility, personality, deception, motivational appeals, visual persuasion). The new edition features expanded treatment of digital and social media; up-to-date research on theory and practice; an increased number of international cases; and new and expanded discussions of topics such as online influencers, disinformation and ‘fake news, ' deepfakes, message framing, normative influence, stigmatized language, and inoculation theory. This is the ideal textbook for courses on persuasion in communication, psychology, advertising, and marketing programs. Instructors can also use the book’s downloadable test bank, instructor’s manual, and PowerPoint slides in preparing course material.",2022-01-01,Book,Book,"Persuasion: Social Influence and Compliance Gaining, Seventh Edition",21101120295,0,,"Persuasion: Social Influence and Compliance Gaining, Seventh Edition",0,false,10.4324/9781003081388,Taylor and Francis,56,,2022.0,0.0,0.0,,49273166,R. Gass,3958081,John S. Seiter,,,,,,,,,70.0,726.0,8.0,148.0,1371.0,17.0,,,,,,,,,,,,,
58,"© 2022 Taylor & Francis.The new, sixth edition of Human Behavior in the Social Environment: Perspectives on Development and the Life Course deepens students’ understanding of the major theories, themes, and issues related to people and how they interact and change over the life span and with respect to their social environments. The new edition has been updated to reflect and build on new developments and awareness related to systemic racism and social justice and mental health and healthrelated concerns that were exacerbated and exposed by the pandemic. The text also comes with a rich companion website that includes support materials and six unique cases that encourage students to learn by doing and to apply their knowledge of human behavior to practice. The book works to: Provide balanced, thorough, and accessible coverage of the major theories and perspectives that social workers utilize to understand and address the myriad problems their clients encounter. Integrate crucial information on life course development, associated development phases, and related problem areas into a single, engaging framework. Stimulate classroom discussion and application around key concepts, themes, and issues. The content in this text is supported by a range of fully updated instructor-led and student resources- including presentations, sample test questions, recommended readings, and links for further study/ applications to current events- that are available on its companion website, www.routledgesw.com. Comprehensive, engaging, and filled with examples for students to learn how to apply their burgeoning knowledge to realistic practice issues, the new edition of Human Behavior in the Social Environment remains invaluable as a tool for courses by the same name in undergraduate and graduate curriculums.",2022-01-01,Book,Book,"Human Behavior in the Social Environment: Perspectives on Development and the Life Course, Sixth Edition",21101116283,0,,"Human Behavior in the Social Environment: Perspectives on Development and the Life Course, Sixth Edition",0,false,10.4324/9781003195542,Taylor and Francis,58,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
59,"© 2022, Emerald Publishing Limited.Purpose: This paper aims to draw upon extant theory and research to delineate the fundamental factors that impact how women evaluate disparaging humor directed at them. The conceptual framework presented outlines the most fundamental organizational-, interpersonal- and individual-level factors that influence the accuracy of such evaluation. Design/methodology/approach: This is a conceptual paper that offers both a review of extant humor and gender research and theory and the presentation of a theoretical model that classifies sources of influence on evaluations of sexist humor from the perspective of the target. Findings: Organization-, interpersonal- and individual-level factors are identified as sources of influence on women’s perception and evaluation of sexist humor leveled at them. This classification identifies factors including organizational power dynamics, egalitarian norms, interpersonal trust, target self-esteem and feminist identity. Research limitations/implications: This paper offers a conceptual framework to guide future studies in more systematically examining the sources of influence on female targets’ capacity to recognize when they are the “punchline” of sexist humor. Practical implications: The conceptual model developed in this paper offers important implications for managers and leaders in organizations in assisting targets to recognize instances of sexist humor directed at them. The aim is to arm potential victims with the knowledge necessary to foster awareness of their treatment in the workplace and to improve the accuracy of evaluation of workplace attitudes that may often nurture a sense of approval or apathy regarding displays of sexist humor. Originality/value: This paper presents a novel classification of sources of influence on female targets’ evaluation of sexist humor in the workplace.",2022-01-01,Journal,Article,Gender in Management,11700154719,0,,Do you know when you are the punchline? Gender-based disparagement humor and target perceptions,0,false,10.1108/GM-01-2021-0026,Emerald Publishing,59,Gender in Management,2022.0,99.0,0.0,,5522652,A. Tabassum,1738163,L. Karakowsky,,,,,,,,,43.0,327.0,9.0,47.0,1188.0,20.0,,,,,,,,,,,,,
61,"© 2022, Springer Nature Switzerland AG.Social media have been growing rapidly during past years. They changed different aspects of human life, especially how people communicate and also how people access information. However, along with the important benefits, social media causes a number of significant challenges since they were introduced. Spreading of fake news and hate speech are among the most challenging issues which have attracted a lot of attention by researchers in past years. Different models based on natural language processing are developed to combat these phenomena and stop them in the early stages before mass spreading. Considering the difficulty of the task of automated harmful information detection (i.e., fake news and hate speech detection), every single step of the detection process could have a sensible impact on the performance of models. In this paper, we study the importance of word embedding on the overall performance of deep neural network architecture on the detection of fake news and hate speech on social media. We test various approaches for converting raw input text into vectors, from random weighting to state-of-the-art contextual word embedding models. In addition, to compare different word embedding approaches, we also analyze different strategies to get the vectors from contextual word embedding models (i.e., get the weights from the last layer, against averaging weights of the last layers). Our results show that XLNet embedding outperforms the other embedding approaches on both tasks related to harmful information identification.",2022-01-01,Book Series,Conference Paper,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),25674,0,13502 LNAI,On the Importance of Word Embedding in Automated Harmful Information Detection,0,false,10.1007/978-3-031-16270-1_21,Springer Science and Business Media Deutschland GmbH,61,"International Conference on Text, Speech and Dialogue",2022.0,0.0,0.0,,3314336,Salar Mohtaj,2111743667,Sebastian Möller,,,,,,,,,30.0,190.0,8.0,31.0,67.0,5.0,,,,,,,,,,,,,Computer Science
64,"© 2022 CommIT Journal. All rights reserved.To avoid citizen disputes, hate speech on social media, such as Twitter, must be automatically detected. The current research in Indonesian Twitter focuses on developing better hate speech detection models. However, there is limited study on the explainability aspects of hate speech detection. The research aims to explain issues that previous researchers have not detailed and attempt to answer the shortcomings of previous researchers. There are 13,169 tweets in the dataset with labels like ""hate speech"" and ""abusive language"". The dataset also provides binary labels on whether hate speech is directed to individual, group, religion, race, physical disability, and gender. In the research, classification is performed by using traditional machine learning models, and the predictions are evaluated using an Explainable AI model, such as Local Interpretable Model-Agnostic Explanations (LIME), to allow users to comprehend why a tweet is regarded as a hateful message. Moreover, models that perform well in classification perceive incorrect words as contributing to hate speech. As a result, such models are unsuitable for deployment in the real world. In the investigation, the combination of XGBoost and logical LIME explanations produces the most logical results. The use of the Explainable AI model highlights the importance of choosing the ideal model while maintaining users trust in the deployed model.",2022-01-01,Journal,Article,CommIT Journal,21101070780,1,16,An Explainable AI Model for Hate Speech Detection on Indonesian Twitter,1,true,10.21512/commit.v16i2.8343,Bina Nusantara University,64,Journal,2022.0,22.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The use of the Explainable AI model highlights the importance of choosing the ideal model while maintaining users’ trust in the deployed model, and the combination of XGBoost and logical LIME explanations produces the most logical results.'}",2183083803,Muhammad Amien Ibrahim,2057792398,S. Arifin,114243075,I. Yudistira,108685323,R. Nariswari,2078153621,Abdul Azis Abdillah,2091102369,N. Murnaka,2.0,0.0,0.0,111.0,130.0,6.0,6.0,2.0,1.0,11.0,27.0,3.0,8.0,22.0,2.0,12.0,11.0,3.0,
104,"© 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.Misogyny is a form of hate against women and has been spreading exponentially through the Web, especially in social media platforms. Hateful contents may be expressed through popular communication tools, like memes. A meme is an image characterised by a pictorial content with an overlaying text introduced a posteriori, and its main aim is originally to be funny and/or ironic. However, the use of memes to convey misogynous messages has increased and thus an automatic detection of these contents seems to be necessary to counteract this phenomenon. This task is particularly challenging, having that (1) different memes can present the same image, but different texts and vice versa, (2) two memes with the same image but different texts can convey a misogynous and not misogynous message, respectively, (3) misogyny can be expressed by image alone, text alone or their combination. In this paper both unimodal and multimodal approaches are investigated whose classifiers are trained and tested on a dataset of in the wild memes, which present both experts and perceived labels. The proposed multimodal approach provides better results compared to the unimodal ones and the VisualBERT state-of-the-art benchmark.",2022-01-01,Book Series,Conference Paper,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),25674,0,13196 LNAI,Misogynous MEME Recognition: A Preliminary Study,0,false,10.1007/978-3-031-08421-8_19,Springer Science and Business Media Deutschland GmbH,104,International Conference of the Italian Association for Artificial Intelligence,2021.0,0.0,0.0,,1847803,E. Fersini,104163189,Giuliano Rizzi,51228436,Aurora Saibene,2032578,F. Gasparini,,,,,110.0,2476.0,23.0,11.0,73.0,4.0,15.0,89.0,4.0,181.0,5035.0,38.0,,,,,,,Computer Science
107,"© 2022, The Author(s).The rise of social networks has allowed misogynistic, xenophobic, and homophobic people to spread their hate-speech to intimidate individuals or groups because of their gender, ethnicity or sexual orientation. The consequences of hate-speech are devastating, causing severe depression and even leading people to commit suicide. Hate-speech identification is challenging as the large amount of daily publications makes it impossible to review every comment by hand. Moreover, hate-speech is also spread by hoaxes that requires language and context understanding. With the aim of reducing the number of comments that should be reviewed by experts, or even for the development of autonomous systems, the automatic identification of hate-speech has gained academic relevance. However, the reliability of automatic approaches is still limited specifically in languages other than English, in which some of the state-of-the-art techniques have not been analyzed in detail. In this work, we examine which features are most effective in identifying hate-speech in Spanish and how these features can be combined to develop more accurate systems. In addition, we characterize the language present in each type of hate-speech by means of explainable linguistic features and compare our results with state-of-the-art approaches. Our research indicates that combining linguistic features and transformers by means of knowledge integration outperforms current solutions regarding hate-speech identification in Spanish.",2022-01-01,Journal,Article,Complex and Intelligent Systems,21101095931,14,,Evaluating feature combination strategies for hate-speech detection in Spanish using linguistic features and transformers,1,true,10.1007/s40747-022-00693-x,Springer International Publishing,107,Complex &amp; Intelligent Systems,2022.0,14.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'Which features are most effective in identifying hate-speech in Spanish and how these features can be combined to develop more accurate systems are examined and research indicates that combining linguistic features and transformers by means of knowledge integration outperforms current solutions regarding hate- speech identification in Spanish.'}",1409250207,J. García-Díaz,1738607071,Salud María Jiménez-Zafra,1403861271,M. Á. García-Cumbreras,1398759108,R. Valencia-García,,,,,53.0,294.0,9.0,11.0,50.0,4.0,26.0,113.0,7.0,208.0,3480.0,32.0,,,,,,,
108,"© 2022 Dana Schowalter, Shannon Stevens, and Daniel L. Horvath.This book is an exploration of the political struggle for visibility engendered by the growing number of women-centered popular films and a critical analysis of the intensifying misogynistic backlash that have accompanied such advances in the depiction of women on screen. The book draws from a variety of theoretical and methodological tools to provide critical cultural analysis and alternative readings of women-strong films and their important role in society. The authors engage with popular culture and the popular press, media studies, and rhetorical criticism examining new modes of communication while providing historical context to help make sense of these oppositional readings. The book includes case studies on Mad Max: Fury Road, Wonder Woman, Atomic Blonde, Star Wars, and Ghostbusters to analyze critical responses, men’s-rights activist boycotting campaigns, online harassment, and the political economy that precede and accompany the creation and presentation of these films. This is an accessible and timely analysis of the rise of feminist-friendly and women-led films and the inevitable counterculture of misogyny. It is suitable for students and researchers in Media and Communication Studies, Gender and Media, and Cultural Studies.",2022-01-01,Book,Book,The Misogynistic Backlash Against Women-Strong Films,21101090762,0,,The Misogynistic Backlash Against Women-Strong Films,0,false,10.4324/9780429291975,Taylor and Francis,108,,2021.0,0.0,0.0,,114674117,Dana Schowalter,116757857,S. Stevens,2136578699,Dániel Horváth,,,,,,,14.0,20.0,2.0,12.0,51.0,2.0,8.0,3.0,1.0,,,,,,,,,,
109,"© 2022 American Psychological AssociationGender diverse people in the United States are uniquely vulnerable to deleterious health outcomes because of long-enshrined systems of oppression and marginalization in American society. Trans young adults are especially vulnerable to these deleterious outcomes owing to their unique position in the life course. However, more research is needed on the mechanisms through which this marginalization contributes to mental health disparities in trans populations. Using a minority stress framework and online crosssectional survey design, the current study examines potential mediators of the relationship between transgender identity-related distal stress and psychological distress from late May to early July 2020 in a sample of transgender young adults (N = 239; ages 18–29). More than half the sample scored above the K6 cutoff for severe psychological distress. Distal stress had a significant direct (b =.17, SE =.04, t = 2.76, p =.006) and indirect effect on psychological distress. Distal stress was indirectly associated with psychological distress through gender dysphoria (b =.04; 95% CI [.001,.10]) and emotion dysregulation (b =.16; 95% CI [.09,.23]). COVID-19 pandemic stressors were also positively associated with psychological distress (b =.36, SE =.12, t = 5.95, p <.001). Results highlight the significant mental health burden facing the trans community especially in the COVID-19 context, support a conceptualization of gender dysphoria as connected to experiences of oppression, and affirm the relevance of emotion dysregulation within minority stress frameworks. Mental health resources cognizant of the specific challenges experienced by trans young adults as well as policy changes that seek to address underlying structural transphobia in American culture and institutions are urgently needed",2022-01-01,Journal,Article,Psychology of Sexual Orientation and Gender Diversity,21100830172,0,,"Minority Stress, Pandemic Stress, and Mental Health Among Gender Diverse Young Adults: Gender Dysphoria and Emotion Dysregulation as Mediators",0,false,10.1037/sgd0000574,American Psychological Association,109,Psychology of Sexual Orientation and Gender Diversity,2022.0,0.0,0.0,,47370338,M. Pease,143639234,Thomas P. Le,3983322,D. Iwamoto,,,,,,,12.0,180.0,5.0,29.0,113.0,7.0,86.0,2236.0,26.0,,,,,,,,,,Medicine
111,"© 2022 Abdullah Y. Muaad et al.Social media networking is a prominent topic in real life, particularly at the current moment. The impact of comments has been investigated in several studies. Twitter, Facebook, and Instagram are just a few of the social media networks that are used to broadcast different news worldwide. In this paper, a comprehensive AI-based study is presented to automatically detect the Arabic text misogyny and sarcasm in binary and multiclass scenarios. The key of the proposed AI approach is to distinguish various topics of misogyny and sarcasm from Arabic tweets in social media networks. A comprehensive study is achieved for detecting both misogyny and sarcasm via adopting seven state-of-the-art NLP classifiers: ARABERT, PAC, LRC, RFC, LSVC, DTC, and KNNC. To fine tune, validate, and evaluate all of these techniques, two Arabic tweets datasets (i.e., misogyny and Abu Farah datasets) are used. For the experimental study, two scenarios are proposed for each case study (misogyny or sarcasm): binary and multiclass problems. For misogyny detection, the best accuracy is achieved using the AraBERT classifier with 91.0% for binary classification scenario and 89.0% for the multiclass scenario. For sarcasm detection, the best accuracy is achieved using the AraBERT as well with 88% for binary classification scenario and 77.0% for the multiclass scenario. The proposed method appears to be effective in detecting misogyny and sarcasm in social media platforms with suggesting AraBERT as a superior state-of-the-art deep learning classifier.",2022-01-01,Journal,Article,Computational Intelligence and Neuroscience,7000153240,6,2022,Artificial Intelligence-Based Approach for Misogyny and Sarcasm Detection from Arabic Texts,1,true,10.1155/2022/7937667,Hindawi Limited,111,Computational Intelligence and Neuroscience,2022.0,42.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The proposed method appears to be effective in detecting misogyny and sarcasm in social media platforms with suggesting AraBERT as a superior state-of-the-art deep learning classifier.'}",2123504137,A. Y. Muaad,2033710,Prof. Jayappa(J) Hanumanthappa Davanagere,21585888,J. V. B. Benifa,2890322,Amerah Alabrah,2160488490,Mufeed Ahmed Naji Saif,34783221,D. Pushpa,24.0,116.0,6.0,57.0,146.0,6.0,23.0,109.0,6.0,27.0,94.0,6.0,1.0,6.0,1.0,10.0,13.0,2.0,Medicine
112,"© Copyright 2022 Benítez-Andrades et alWith the growth that social networks have experienced in recent years, it is entirely impossible to moderate content manually. Thanks to the different existing techniques in natural language processing, it is possible to generate predictive models that automatically classify texts into different categories. However, a weakness has been detected concerning the language used to train such models. This work aimed to develop a predictive model based on BERT, capable of detecting racist and xenophobic messages in tweets written in Spanish. A comparison was made with different Deep Learning models. A total of five predictive models were developed, two based on BERT and three using other deep learning techniques, CNN, LSTM and a model combining CNN + LSTM techniques. After exhaustively analyzing the results obtained by the different models, it was found that the one that got the best metrics was BETO, a BERT-based model trained only with texts written in Spanish. The results of our study show that the BETO model achieves a precision of 85.22% compared to the 82.00% precision of the mBERT model. The rest of the models obtained between 79.34% and 80.48% precision. On this basis, it has been possible to justify the vital importance of developing native transfer learning models for solving Natural Language Processing (NLP) problems in Spanish. Our main contribution is the achievement of promising results in the field of racism and hate speech in Spanish by applying different deep learning techniques",2022-01-01,Journal,Article,PeerJ Computer Science,21100830173,2,8,"Detecting racism and xenophobia using deep learning models on Twitter data: CNN, LSTM and BERT",1,true,10.7717/PEERJ-CS.906,PeerJ Inc.,112,PeerJ Computer Science,2022.0,55.0,2.0,"{'model': 'tldr@v2.0.0', 'text': 'This work aimed to develop a predictive model based on BERT, capable of detecting racist and xenophobic messages in tweets written in Spanish, and found that the one that got the best metrics was BETO, a BERT-based model trained only with texts written inSpanish.'}",1404826354,J. Benítez-Andrades,1422297076,Á. González-Jiménez,2156892423,Álvaro López-Brea,1417005548,José Aveleira-Mata,1411032718,José-Manuel Alija-Pérez,1403838858,María Teresa García-Ordás,51.0,258.0,9.0,12.0,57.0,5.0,2.0,4.0,1.0,14.0,57.0,2.0,9.0,13.0,3.0,55.0,385.0,11.0,"Computer Science, Medicine"
113,"© 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.This article explores the portrayal of Harvey Weinstein, Kevin Spacey and Louis C.K. in Internet memes at the height of #MeToo. Investigating how they are portrayed on social media platforms that encourage humorous content, the article explores how this humorous discursive space frames sexual violence within a “just a joke” discourse. The portrayal of the three men reveals a discursive construction of sexual violence as “just sex” and puts the blame and the responsibility on the victims. Bringing together feminist theories of sexual violence with digital media methods, the article investigates the discourse unique to the Internet meme. The article demonstrates how certain notions about gender and sexuality are discursively reproduced in online spaces that privilege heterosexual men and exclude women and homosexual men. The article traces how sexual violence is characterized in different ways depending on who the men are: Weinstein as a monstrous other, Spacey as a perverted homosexual and pedophile, and C.K. as an antihero.",2022-01-01,Journal,Article,Feminist Media Studies,5700168400,1,,"A monster, a pervert, and an anti-hero: the discursive construction of Harvey Weinstein, Kevin Spacey, and Louis C.K. in humorous #MeToo memes",1,true,10.1080/14680777.2022.2047089,Routledge,113,Feminist Media Studies,2022.0,25.0,0.0,,115297741,Maja Brandt Andreasen,,,,,,,,,,,4.0,12.0,1.0,,,,,,,,,,,,,,,,
114,"© 2022, The Author(s).Swearing plays an ubiquitous role in everyday conversations among humans, both in oral and textual communication, and occurs frequently in social media texts, typically featured by informal language and spontaneous writing. Such occurrences can be linked to an abusive context, when they contribute to the expression of hatred and to the abusive effect, causing harm and offense. However, swearing is multifaceted and is often used in casual contexts, also with positive social functions. In this study, we explore the phenomenon of swearing in Twitter conversations, by automatically predicting the abusiveness of a swear word in a tweet as the main investigation perspective. We developed the Twitter English corpus SWAD (Swear Words Abusiveness Dataset), where abusive swearing is manually annotated at the word level. Our collection consists of 2577 instances in total from two phases of manual annotation. We developed models to automatically predict abusive swearing, to provide an intrinsic evaluation of SWAD and confirm the robustness of the resource. We model this prediction task as three different tasks, namely sequence labeling, text classification, and target-based swear word abusiveness prediction. We experimentally found that our intention to model the task similarly to aspect-based sentiment analysis leads to promising results. Subsequently, we employ the classifier to improve the prediction of abusive language in several standard benchmarks. The results of our experiments show that additional abusiveness feature of the swear words is able to improve the performance of abusive language detection models in several benchmark datasets.",2022-01-01,Journal,Article,Language Resources and Evaluation,145663,1,,Investigating the role of swear words in abusive language detection tasks,1,true,10.1007/s10579-022-09582-8,Springer Science and Business Media B.V.,114,Language Resources and Evaluation,2022.0,25.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The results of the experiments show that additional abusiveness feature of the swear words is able to improve the performance of abusive language detection models in several benchmark datasets.'}",9278845,Endang Wahyu Pamungkas,3101511,Valerio Basile,1787198,V. Patti,,,,,,,19.0,334.0,11.0,123.0,2883.0,25.0,220.0,4576.0,36.0,,,,,,,,,,
115,"© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.Offensive content is pervasive in social media and a reason for concern to companies and government organizations. Several studies have been recently published investigating methods to detect the various forms of such content (e.g., hate speech, cyberbullying, and cyberaggression). The clear majority of these studies deal with English partially because most annotated datasets available contain English data. In this article, we take advantage of available English datasets by applying cross-lingual contextual word embeddings and transfer learning to make predictions in low-resource languages. We project predictions on comparable data in Arabic, Bengali, Danish, Greek, Hindi, Spanish, and Turkish. We report results of 0.8415 F1 macro for Bengali in TRAC-2 shared task [23], 0.8532 F1 macro for Danish and 0.8701 F1 macro for Greek in OffensEval 2020 [58], 0.8568 F1 macro for Hindi in HASOC 2019 shared task [27], and 0.7513 F1 macro for Spanish in in SemEval-2019 Task 5 (HatEval) [7], showing that our approach compares favorably to the best systems submitted to recent shared tasks on these three languages. Additionally, we report competitive performance on Arabic and Turkish using the training and development sets of OffensEval 2020 shared task. The results for all languages confirm the robustness of cross-lingual contextual embeddings and transfer learning for this task.",2022-01-01,Journal,Article,ACM Transactions on Asian and Low-Resource Language Information Processing,21100784666,3,21,Multilingual Offensive Language Identification for Low-resource Languages,2,,10.1145/3457610,Association for Computing Machinery,115,ACM Trans. Asian Low Resour. Lang. Inf. Process.,2021.0,59.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'Results for all languages confirm the robustness of cross-lingual contextual embeddings and transfer learning for this task, and project predictions on comparable data in Arabic, Bengali, Danish, Greek, Hindi, Spanish, and Turkish.'}",134805041,Tharindu Ranasinghe,145130358,Marcos Zampieri,,,,,,,,,48.0,794.0,15.0,141.0,6736.0,38.0,,,,,,,,,,,,,Computer Science
116,"© 2013 IEEE.Automatic detection of abusive online content such as hate speech, offensive language, threats, etc. has become prevalent in social media, with multiple efforts dedicated to detecting this phenomenon in English. However, detecting hatred and abuse in low-resource languages is a non-trivial challenge. The lack of sufficient labeled data in low-resource languages and inconsistent generalization ability of transformer-based multilingual pre-trained language models for typologically diverse languages make these models inefficient in some cases. We propose a meta learning-based approach to study the problem of few-shot hate speech and offensive language detection in low-resource languages that will allow hateful or offensive content to be predicted by only observing a few labeled data items in a specific target language. We investigate the feasibility of applying a meta learning approach in cross-lingual few-shot hate speech detection by leveraging two meta learning models based on optimization-based and metric-based (MAML and Proto-MAML) methods. To the best of our knowledge, this is the first effort of this kind. To evaluate the performance of our approach, we consider hate speech and offensive language detection as two separate tasks and make two diverse collections of different publicly available datasets comprising 15 datasets across 8 languages for hate speech and 6 datasets across 6 languages for offensive language. Our experiments show that meta learning-based models outperform transfer learning-based models in a majority of cases, and that Proto-MAML is the best performing model, as it can quickly generalize and adapt to new languages with only a few labeled data points (generally, 16 samples per class yields an effective performance) to identify hateful or offensive content.",2022-01-01,Journal,Article,IEEE Access,21100374601,0,10,Cross-Lingual Few-Shot Hate Speech and Offensive Language Detection Using Meta Learning,1,true,10.1109/ACCESS.2022.3147588,Institute of Electrical and Electronics Engineers Inc.,116,IEEE Access,2022.0,83.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A meta learning-based approach to study the problem of few-shot hate speech and offensive language detection in low-resource languages that will allow hateful or offensive content to be predicted by only observing a few labeled data items in a specific target language is proposed.'}",2639305,Marzieh Mozafari,2633697,R. Farahbakhsh,145107973,N. Crespi,,,,,,,6.0,266.0,3.0,84.0,1524.0,20.0,424.0,5513.0,33.0,,,,,,,,,,Computer Science
117,"© 2013 IEEE.Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU) are a class of Recurrent Neural Networks (RNN) suitable for sequential data processing. Bidirectional LSTM (BLSTM) enables a better understanding of context by learning the future time steps in a bidirectional manner. Moreover, GRU deploys reset and update gates in the hidden layer, which is computationally more efficient than a conventional LSTM. This paper proposes an efficient network model based on deep BLSTM-GRU for ciphertext classification aiming to mark the category to which the ciphertext belongs. The proposed model performance was evaluated using well-known evaluation metrics on two publicly available datasets encrypted with various classical cipher methods and performance was compared against one-dimensional convolutional neural network (1D-CNN) and various other deep learning-based approaches. The experimental results showed that the BLSTM-GRU cell unit network model achieved a high classification accuracy of up to 95.8%. To the best of our knowledge, this is the first time an RNN-based model has been applied for the ciphertext classification.",2022-01-01,Journal,Article,IEEE Access,21100374601,4,10,A Deep Bidirectional LSTM-GRU Network Model for Automated Ciphertext Classification,1,true,10.1109/ACCESS.2022.3140342,Institute of Electrical and Electronics Engineers Inc.,117,IEEE Access,2022.0,36.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes an efficient network model based on hybrid BLSTM-GRU for ciphertext classification aiming to mark the category to which the ciphertext belongs, the first time an RNN-based model has been applied for the cipher text classification.'}",38598921,Ezat Ahmadzadeh,2117986245,Hyunil Kim,2086803317,Ongee Jeong,2152143246,N. Kim,2059253447,Inkyu Moon,,,9.0,32.0,3.0,6.0,23.0,2.0,5.0,10.0,2.0,14.0,11.0,2.0,9.0,8.0,2.0,,,,Computer Science
118,"© 2021Online sexism has become an increasing concern in social media platforms as it has affected the healthy development of the Internet and can have negative effects in society. While research in the sexism detection domain is growing, most of this research focuses on English as the language and on Twitter as the platform. Our objective here is to broaden the scope of this research by considering the Chinese language on Sina Weibo. We propose the first Chinese sexism dataset – Sina Weibo Sexism Review (SWSR) dataset –, as well as a large Chinese lexicon SexHateLex made of abusive and gender-related terms. We introduce our data collection and annotation process, and provide an exploratory analysis of the dataset characteristics to validate its quality and to show how sexism is manifested in Chinese. The SWSR dataset provides labels at different levels of granularity including (i) sexism or non-sexism, (ii) sexism category and (iii) target type, which can be exploited, among others, for building computational methods to identify and investigate finer-grained gender-related abusive language. We conduct experiments for the three sexism classification tasks making use of state-of-the-art machine learning models. Our results show competitive performance, providing a benchmark for sexism detection in the Chinese language, as well as an error analysis highlighting open challenges needing more research in Chinese NLP. The SWSR dataset and SexHateLex lexicon are publicly available.1",2022-01-01,Journal,Article,Online Social Networks and Media,21100901582,3,27,SWSR: A Chinese dataset and lexicon for online sexism detection,2,,10.1016/j.osnem.2021.100182,Elsevier B.V.,118,Online Soc. Networks Media,2021.0,64.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The first Chinese sexism dataset – Sina Weibo Sexism Review (SWSR) dataset – is proposed and an exploratory analysis of the dataset characteristics is provided to validate its quality and to show how sexism is manifested in Chinese.'}",144294552,Aiqi Jiang,2143390495,Xiaohan Yang,2152798564,Yang Liu,2805349,A. Zubiaga,,,,,9.0,25.0,4.0,9.0,12.0,2.0,7.0,22.0,3.0,163.0,4980.0,36.0,,,,,,,Computer Science
119,"© 2021 Informa UK Limited, trading as Taylor & Francis Group.Following a series of deadly attacks, and increasingly in recent years, incels have entered not only the public lexicon but also piqued scholarly interest, especially in terrorism research and programmes aimed at countering violent extremism (CVE). However, much of the current analyses largely interpret incel communities as homogenous, and in doing so ignore the complex and often contradictory nature of incel communities. CVE recommendations made by these scholars are often founded on misconceptions of incel identity and community. Through a critical feminist lens, in this article we argue that the focus on incels should seek to understand the role of male supremacy, antifeminism, and misogyny in society. Additionally, we argue against the trend of attempting to classify and securitise incels as a unique form of misogynistic violence, and identify the dangers of a lack of focus on male supremacy.",2022-01-01,Journal,Article,Critical Studies on Terrorism,19700201448,1,15,Interrogating the “incel menace”: assessing the threat of male supremacy in terrorism studies,0,false,10.1080/17539153.2021.2005099,Routledge,119,Critical Studies on Terrorism,2021.0,106.0,0.0,,3426568,J. DeCook,153907801,Megan L. Kelly,,,,,,,,,25.0,170.0,6.0,11.0,7.0,2.0,,,,,,,,,,,,,
120,"© 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.Low sexual desire in women partnered with men is typically presumed to be a problem—one that exists in women and encourages a research agenda on causation and treatment targeting women. In this paper, we present a distinct way forward for research on low sexual desire in women partnered with men that attends to a more structural explanation: heteronormativity. A heteronormative worldview assumes that relationships and structures are heterosexual, gender (usually conflated with sex) is binary and complementary, and gender roles fit within narrow bounds including nurturant labor for women. We propose the heteronormativity theory of low sexual desire in women partnered with men, arguing that heteronormative gender inequities are contributing factors. We outline four hypotheses and their predictions related to: inequitable divisions of household labor, blurring of partner and mother roles, objectification of women, and gender norms surrounding sexual initiation. We discuss some mechanisms—social, physiological, and otherwise—for the heteronormativity theory, especially related to stress, objectification, and nurturance. We close by noting some limitations of our paper and the ways that the heteronormativity theory of low sexual desire in women partnered with men provides a rigorous, generative, and empirical way forward.",2022-01-01,Journal,Article,Archives of Sexual Behavior,27562,13,51,The Heteronormativity Theory of Low Sexual Desire in Women Partnered with Men,1,true,10.1007/s10508-021-02100-x,Springer,120,Archives of Sexual Behavior,2021.0,0.0,0.0,,4552203,Sari M. van Anders,51912336,D. Herbenick,6382706,L. Brotto,33600041,Emily A. Harris,8624929,Sara B. Chadwick,,,87.0,1944.0,24.0,242.0,5791.0,39.0,333.0,9595.0,51.0,25.0,1380.0,10.0,24.0,257.0,9.0,,,,
121,"© 2021, The Author(s).Hate Speech and harassment are widespread in online communication, due to users' freedom and anonymity and the lack of regulation provided by social media platforms. Hate speech is topically focused (misogyny, sexism, racism, xenophobia, homophobia, etc.), and each specific manifestation of hate speech targets different vulnerable groups based on characteristics such as gender (misogyny, sexism), ethnicity, race, religion (xenophobia, racism, Islamophobia), sexual orientation (homophobia), and so on. Most automatic hate speech detection approaches cast the problem into a binary classification task without addressing either the topical focus or the target-oriented nature of hate speech. In this paper, we propose to tackle, for the first time, hate speech detection from a multi-target perspective. We leverage manually annotated datasets, to investigate the problem of transferring knowledge from different datasets with different topical focuses and targets. Our contribution is threefold: (1) we explore the ability of hate speech detection models to capture common properties from topic-generic datasets and transfer this knowledge to recognize specific manifestations of hate speech; (2) we experiment with the development of models to detect both topics (racism, xenophobia, sexism, misogyny) and hate speech targets, going beyond standard binary classification, to investigate how to detect hate speech at a finer level of granularity and how to transfer knowledge across different topics and targets; and (3) we study the impact of affective knowledge encoded in sentic computing resources (SenticNet, EmoSenticNet) and in semantically structured hate lexicons (HurtLex) in determining specific manifestations of hate speech. We experimented with different neural models including multitask approaches. Our study shows that: (1) training a model on a combination of several (training sets from several) topic-specific datasets is more effective than training a model on a topic-generic dataset; (2) the multi-task approach outperforms a single-task model when detecting both the hatefulness of a tweet and its topical focus in the context of a multi-label classification approach; and (3) the models incorporating EmoSenticNet emotions, the first level emotions of SenticNet, a blend of SenticNet and EmoSenticNet emotions or affective features based on Hurtlex, obtained the best results. Our results demonstrate that multi-target hate speech detection from existing datasets is feasible, which is a first step towards hate speech detection for a specific topic/target when dedicated annotated data are missing. Moreover, we prove that domain-independent affective knowledge, injected into our models, helps finer-grained hate speech detection.",2022-01-01,Journal,Article,Cognitive Computation,19400158515,10,14,Emotionally Informed Hate Speech Detection: A Multi-target Perspective,1,true,10.1007/s12559-021-09862-5,Springer,121,Cognitive Computation,2021.0,0.0,0.0,"{'model': 'tldr@v2.0.0', 'text': ""This paper proposes to tackle, for the first time, hate speech detection from a multi-target perspective, and proves that domain-independent affective knowledge, injected into the authors' models, helps finer-grainedhate speech detection.""}",73773451,Patricia Chiril,9278845,Endang Wahyu Pamungkas,3350632,F. Benamara,2975481,Véronique Moriceau,1787198,V. Patti,,,9.0,84.0,5.0,19.0,334.0,11.0,87.0,1794.0,23.0,69.0,928.0,18.0,220.0,4576.0,36.0,,,,
122,"© 2021 Informa UK Limited, trading as Taylor & Francis Group.The first general women’s strikes to demand gender equality in Spain took place on 8 March 2018 and 2019. Both calls were an amazing success, becoming world references for feminism. This research investigates how the strikes were dealt with through Twitter by a Collective Symbolic Coping (CSC) process. Discourses on Twitter were analysed on both years, 4,384 tweets were selected and their content was analysed by lexical analysis. The results from 2018 indicated the CSC phases of 1) awareness; 2) divergence, where feminist demands and the role of men in the strike were debated; and 3) convergence, where the success of the strike was highlighted. However, in 2019 the feminists on Twitter were forced to cope with a great deal of trolling against them. This trolling was maintained in the awareness and divergence phases, making it difficult to reach a convergent discourse regarding the success of the strike. Moreover, the results also demonstrated that there was no reference hashtag in the strikes. It is concluded that discourse on social networks has become a key factor in feminist social mobilizations and that this feminist digital activism will be critical in the continued dissemination of the claims for gender equality in Spain.",2022-01-01,Journal,Article,Journal of Gender Studies,23704,4,31,#8M women’s strikes in Spain: following the unprecedented social mobilization through twitter,0,false,10.1080/09589236.2021.1881461,Routledge,122,Journal of Gender Studies,2021.0,116.0,0.0,,115237513,Nahia Idoiaga Mondragón,1864030417,Naiara Berasategi Sancho,2124098494,Nekane Beloki Arizti,2124096951,Maitane Belasko Txertudi,,,,,28.0,576.0,10.0,12.0,116.0,6.0,1.0,4.0,1.0,2.0,6.0,2.0,,,,,,,Sociology
123,"© 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.The dramatic growth of the Web has motivated researchers to extract knowledge from enormous repositories and to exploit the knowledge in myriad applications. In this study, we focus on natural language processing (NLP) and, more concretely, the emerging field of affective computing to explore the automation of understanding human emotions from texts. This paper continues previous efforts to utilize and adapt affective techniques into different areas to gain new insights. This paper proposes two novel feature extraction methods that use the previous sentic computing resources AffectiveSpace and SenticNet. These methods are efficient approaches for extracting affect-aware representations from text. In addition, this paper presents a machine learning framework using an ensemble of different features to improve the overall classification performance. Following the description of this approach, we also study the effects of known feature extraction methods such as TF-IDF and SIMilarity-based sentiment projectiON (SIMON). We perform a thorough evaluation of the proposed features across five different datasets that cover radicalization and hate speech detection tasks. To compare the different approaches fairly, we conducted a statistical test that ranks the studied methods. The obtained results indicate that combining affect-aware features with the studied textual representations effectively improves performance. We also propose a criterion considering both classification performance and computational complexity to select among the different methods.",2022-01-01,Journal,Article,Cognitive Computation,19400158515,9,14,An Ensemble Method for Radicalization and Hate Speech Detection Online Empowered by Sentic Computing,0,false,10.1007/s12559-021-09845-6,Springer,123,Cognitive Computation,2021.0,87.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes two novel feature extraction methods that use the previous sentic computing resources AffectiveSpace and SenticNet, and proposes a machine learning framework using an ensemble of different features to improve the overall classification performance.'}",1999125,Óscar Araque,1697135,C. Iglesias,,,,,,,,,34.0,858.0,11.0,152.0,3106.0,28.0,,,,,,,,,,,,,
124,"© 2021Social media platforms generate an enormous amount of data every day. Millions of users engage themselves with the posts circulated on these platforms. Despite the social regulations and protocols imposed by these platforms, it is difficult to restrict some objectionable posts carrying hateful content. Automatic hate speech detection on social media platforms is an essential task that has not been solved efficiently despite multiple attempts by various researchers. It is a challenging task that involves identifying hateful content from social media posts. These posts may reveal hate outrageously, or they may be subjective to the user or a community. Relying on manual inspection delays the process, and the hateful content may remain available online for a long time. The current state-of-the-art methods for tackling hate speech perform well when tested on the same dataset but fail miserably on cross-datasets. Therefore, we propose an ensemble learning-based adaptive model for automatic hate speech detection, improving the cross-dataset generalization. The proposed expert model for hate speech detection works towards overcoming the strong user-bias present in the available annotated datasets. We conduct our experiments under various experimental setups and demonstrate the proposed model's efficacy on the latest issues such as COVID-19 and US presidential elections. In particular, the loss in performance observed under cross-dataset evaluation is the least among all the models. Also, while restricting the maximum number of tweets per user, we incur no drop in performance.",2021-12-15,Journal,Article,Expert Systems with Applications,24201,7,185,Combating hate speech using an adaptive ensemble learning model with a case study on COVID-19,1,true,10.1016/j.eswa.2021.115632,Elsevier Ltd,124,Expert systems with applications,2021.0,32.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'An ensemble learning-based adaptive model for automatic hate speech detection that works towards overcoming the strong user-bias present in the available annotated datasets is proposed, improving the cross-dataset generalization.'}",51443250,Shivang Agarwal,145173345,C. R. Chowdary,,,,,,,,,12.0,157.0,5.0,55.0,606.0,9.0,,,,,,,,,,,,,Medicine
125,"© 2021 ACM.In recent years, given the exponential increase in social media content also led to an increase in online hate speech. We need automatic hate speech detection methods due to the volume of data on the web. Various approaches have been proposed to address hate speech and offensive content on social media. This paper surveys how neural-based models have rapidly evolved to address hate speech on multilingual code-mixed data. We discuss the current state of the research in hate speech and offensive language detection on code-mixed Indian datasets.",2021-12-13,Conference Proceeding,Conference Paper,ACM International Conference Proceeding Series,11600154611,1,,A Survey of Recent Neural Network Models on Code-Mixed Indian Hate Speech Data,0,false,10.1145/3503162.3503168,Association for Computing Machinery,125,Fire,2021.0,48.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper surveys how neural-based models have rapidly evolved to address hate speech on multilingual code-mixed data in India and discusses the current state of the research in hate speech and offensive language detection on code- mixed Indian datasets.'}",32404638,Suman Dowlagar,1829635,R. Mamidi,,,,,,,,,16.0,63.0,5.0,151.0,954.0,14.0,,,,,,,,,,,,,Computer Science
126,"© 2021, The Author(s).Sexism, a permeate form of oppression, causes profound suffering through various manifestations. Given the increasing number of experiences of sexism shared online, categorizing these recollections automatically can support the battle against sexism, since it can promote successful evaluations by gender studies researchers and government representatives engaged in policy making. In this paper, we examine the fine-grained, multi-label classification of accounts (reports) of sexism. To the best of our knowledge, we consider substantially more categories of sexism than any related prior work through our 23-class problem formulation. Moreover, we present the first semi-supervised work for the multi-label classification of accounts describing any type(s) of sexism. We devise self-training-based techniques tailor-made for the multi-label nature of the problem to utilize unlabeled samples for augmenting the labeled set. We identify high textual diversity with respect to the existing labeled set as a desirable quality for candidate unlabeled instances and develop methods for incorporating it into our approach. We also explore ways of infusing class imbalance alleviation for multi-label classification into our semi-supervised learning, independently and in conjunction with the method involving diversity. In addition to data augmentation methods, we develop a neural model which combines biLSTM and attention with a domain-adapted BERT model in an end-to-end trainable manner. Further, we formulate a multi-level training approach in which models are sequentially trained using categories of sexism of different levels of granularity. Moreover, we devise a loss function that exploits any label confidence scores associated with the data. Several proposed methods outperform various baselines on a recently released dataset for multi-label sexism categorization across several standard metrics.",2021-12-01,Journal,Article,Data Science and Engineering,21100901150,3,6,Fine-Grained Multi-label Sexism Classification Using a Semi-Supervised Multi-level Neural Approach,1,true,10.1007/s41019-021-00168-y,Springer Science and Business Media Deutschland GmbH,126,Data Science and Engineering,2021.0,51.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A neural model which combines biLSTM and attention with a domain-adapted BERT model in an end-to-end trainable manner is developed and a multi-level training approach in which models are sequentially trained using categories of sexism of different levels of granularity is formulated.'}",3442296,Harika Abburi,36328737,Pulkit Parikh,2954043,Niyati Chhaya,1704709,Vasudeva Varma,,,,,15.0,118.0,5.0,21.0,96.0,5.0,63.0,633.0,10.0,296.0,4835.0,34.0,,,,,,,Computer Science
127,"© 2021 The Authors. Scandinavian Journal of Psychology published by Scandinavian Psychological Associations and John Wiley & Sons Ltd.In this study we examined how people perceive social-sexual behavior of women and men, and how these perceptions were associated with beliefs about the outcomes of the #MeToo movement, sexism, traditional values, and gender equality. In addition, we examined the effect of having experienced sexual harassment on such perceptions. Analyses were performed on a Norwegian snowball social media sample covering 321 women and 168 men, aged 18–59 (M = 33.1). Outcome variables covered perceptions of scenarios that described opposite-sex social-sexual behaviors performed by female and male actors within the workplace environment. Path analysis showed that negative beliefs about the outcomes of the #MeToo movement was the principal predictor for perception of female and male social-sexual behavior as sexual harassment for women and men participants. Traditional values, gender equality, and hostile sexism toward women were all associated with perception of social-sexual behavior as sexual harassment, however the effects of these variables were only indirect and fully accounted for by the effect of negative #MeToo beliefs. For women, having experienced sexual harassment was associated with hostile sexism toward men, but had no effect on the perceptions over and above the effect of the other variables in the model. The predictors on participants’ perceptions were highly similar for women and men and for evaluations of female and male actors. Theoretical and methodological implications are discussed.",2021-12-01,Journal,Article,Scandinavian Journal of Psychology,14775,3,62,Perception of workplace social-sexual behavior as sexual harassment post #MeToo in Scandinavia,1,true,10.1111/sjop.12763,John Wiley and Sons Inc,127,Scandinavian Journal of Psychology,2021.0,51.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'Path analysis showed that negative beliefs about the outcomes of the #MeToo movement was the principal predictor for perception of female and male social-sexual behavior as sexual harassment for women and men participants.'}",83863478,Andrea Kessler,7782230,L. Kennair,1399824905,T. V. Grøntvedt,1485808333,Ida Bjørkheim,2085639500,Idun Drejer,6373711,Mons Bendixen,9.0,45.0,3.0,91.0,1667.0,23.0,22.0,252.0,8.0,2.0,12.0,2.0,2.0,12.0,2.0,53.0,1242.0,19.0,Medicine
128,"© 2021, The Author(s), under exclusive licence to Springer Nature B.V. part of Springer Nature.With the increasing popularity of user-generated content on social media, the number of toxic texts is also on the rise. Such texts cause adverse effects on users and society at large, therefore, the identification of toxic comments is a growing need of the day. While toxic comment classification has been studied for resource-rich languages like English, no work has been done for Roman Urdu despite being a widely used language on social media in South Asia. This paper addresses the challenge of Roman Urdu toxic comment detection by developing a first-ever large labeled corpus of toxic and non-toxic comments. The developed corpus, called RUT (Roman Urdu Toxic), contains over 72 thousand comments collected from popular social media platforms and has been labeled manually with a strong inter-annotator agreement. With this dataset, we train several classification models to detect Roman Urdu toxic comments, including classical machine learning models with the bag-of-words representation and some recent deep models based on word embeddings. Despite the success of the latter in classifying toxic comments in English, the absence of pre-trained word embeddings for Roman Urdu prompted to generate different word embeddings using Glove, Word2Vec and FastText techniques, and compare them with task-specific word embeddings learned inside the classification task. Finally, we propose an ensemble approach, reaching our best F1-score of 86.35%, setting the first-ever benchmark for toxic comment classification in Roman Urdu.",2021-12-01,Journal,Article,Language Resources and Evaluation,145663,7,55,Roman Urdu toxic comment classification,0,false,10.1007/s10579-021-09530-y,Springer Science and Business Media B.V.,128,Language Resources and Evaluation,2021.0,58.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A first-ever large labeled corpus of toxic and non-toxic comments in Roman Urdu, called RUT (Roman Urdu Toxic), contains over 72 thousand comments collected from popular social media platforms and has been labeled manually with a strong inter-annotator agreement.'}",1737785262,Hafiz Hassaan Saeed,2089761086,Muhammad Haseeb Ashraf,2054808,F. Kamiran,49634717,Asim Karim,1709830,T. Calders,,,3.0,44.0,3.0,2.0,5.0,1.0,55.0,2897.0,19.0,90.0,2607.0,25.0,170.0,6246.0,34.0,,,,Computer Science
129,"© 2020 Vidgen, Derczynski.Data-driven and machine learning based approaches for detecting, categorising and measuring abusive content such as hate speech and harassment have gained traction due to their scalability, robustness and increasingly high performance. Making effective detection systems for abusive content relies on having the right training datasets, reflecting a widely accepted mantra in computer science: Garbage In, Garbage Out. However, creating training datasets which are large, varied, theoretically-informed and that minimize biases is difficult, laborious and requires deep expertise. This paper systematically reviews 63 publicly available training datasets which have been created to train abusive language classifiers. It also reports on creation of a dedicated website for cataloguing abusive language data hatespeechdata.com. We discuss the challenges and opportunities of open science in this field, and argue that although more dataset sharing would bring many benefits it also poses social and ethical risks which need careful consideration. Finally, we provide evidencebased recommendations for practitioners creating new abusive content training datasets.",2021-12-01,Journal,Review,PLoS ONE,10600153309,71,15,"Directions in abusive language training data, a systematic review: Garbage in, garbage out",1,true,10.1371/journal.pone.0243300,Public Library of Science,129,PLoS ONE,2020.0,160.0,5.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper systematically reviews 63 publicly available training datasets which have been created to train abusive language classifiers and reports on creation of a dedicated website for cataloguing abusive language data hatespeechdata.com.'}",2737827,Bertie Vidgen,113320522,Leon Derczynski,,,,,,,,,35.0,842.0,12.0,134.0,4322.0,28.0,,,,,,,,,,,,,"Medicine, Computer Science"
130,"© 2021 ACM.Violence Against Women is a phenomenon that has grown in the last decades. In this research we address this phenomenon in Digital Space as Digital Violence Against Women. We trained a Support Vector Machine Classifier that predicted a 20.16% presence of Digital Violence Against Women in a Self-constructed Tweet dataset containing over 10 Million Spanish-language tweets in Mexico. A time series was constructed on the percentage of Digital Violence Against Women in tweets per day. Findings indicate increasing presence of violence on specific dates of fight for Women's Rights, such as 25th of November and 8th of March. Finally, forecasts under an ARIMA model gave a Root Mean Squared Error of 0.0062.",2021-11-19,Conference Proceeding,Conference Paper,ACM International Conference Proceeding Series,11600154611,0,,Digital Violence AgainstWomen: A Time Series Analysis,0,false,10.1145/3501774.3501797,Association for Computing Machinery,130,Esse,2021.0,0.0,0.0,,2121589587,Gregorio Arturo Reyes González,2162056102,Francisco J. Cantú Ortiz,,,,,,,,,2.0,3.0,1.0,1.0,0.0,0.0,,,,,,,,,,,,,Computer Science
131,"© 2021 ACM.""Misogynoir""refers to the specific forms of misogyny that Black women experience, which couple racism and sexism together. To better understand the online manifestations of this type of hate, and to propose methods that can automatically identify it, in this paper, we conduct a study on 4 cases of Black women in Tech reporting experiences of misogynoir on the Twitter platform. We follow the reactions to these cases (both supportive and non-supportive responses), and categorise them within a model of misogynoir that highlights experiences of Tone Policing, White Centring, Racial Gaslighting and Defensiveness. As an intersectional form of abusive or hateful speech, we investigate the possibilities and challenges to detect online instances of misogynoir in an automated way. We then conduct a closer qualitative analysis on messages of support and non-support to look at some of these categories in more detail. The purpose of this investigation is to understand responses to misogynoir online, including doubling down on misogynoir, engaging in performative allyship, and showing solidarity with Black women in tech.",2021-11-08,Conference Proceeding,Conference Paper,"Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2021",21101075630,1,,Misogynoir: Public online response towards self-reported misogynoir,2,,10.1145/3487351.3488342,"Association for Computing Machinery, Inc",131,Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,2021.0,10.0,0.0,,74733212,J. Kwarteng,3448651,S. Perfumi,145118333,T. Farrell,2109697381,Miriam Fernández,,,,,7.0,6.0,1.0,14.0,49.0,4.0,26.0,87.0,5.0,4.0,0.0,0.0,,,,,,,
132,"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.Xenophobia is a social and political behavior that has been present in our societies since the beginning of humanity. The feeling of hatred, fear, or resentment is present before people from different communities from ours. With the rise of social networks like Twitter, hate speeches were swift because of the pseudo feeling of anonymity that these platforms provide. Sometimes this violent behavior on social networks that begins as threats or insults to third parties breaks the Internet barriers to become an act of real physical violence. Hence, this proposal aims to correctly classify xenophobic posts on social networks, specifically on Twitter. In addition, we collected a xenophobic tweets database from which we also extracted new features by using a Natural Language Processing (NLP) approach. Then, we provide an Explainable Artificial Intelligence (XAI) model, allowing us to understand better why a post is considered xenophobic. Consequently, we provide a set of contrast patterns describing xenophobic tweets, which could help decision-makers prevent acts of violence caused by xenophobic posts on Twitter. Finally, our interpretable results based on our new feature representation approach jointly with a contrast pattern-based classifier obtain similar classification results than other feature representations jointly with prominent machine learning classifiers, which are not easy to understand by an expert in the application area.",2021-11-01,Journal,Article,Applied Sciences (Switzerland),21100829268,3,11,An explainable artificial intelligence model for detecting xenophobic tweets,1,true,10.3390/app112210801,MDPI,132,Applied Sciences,2021.0,59.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A set of contrast patterns describing xenophobic tweets, which could help decision-makers prevent acts of violence caused by xenophobic posts on Twitter, and an Explainable Artificial Intelligence model, allowing us to understand better why a post is considered xenophobic.'}",2141072745,Gabriel Ichcanziho Pérez-Landa,1390024239,O. Loyola-González,1390016409,M. A. Medina-Pérez,,,,,,,1.0,3.0,1.0,50.0,788.0,14.0,63.0,707.0,15.0,,,,,,,,,,
133,"© 2021 IEEE Computer Society. All rights reserved.Background: As contemporary software development organizations are dominated by males, occurrences of misogynistic and sexist remarks are abundant in many communities. Such remarks are barriers to promoting diversity and inclusion in the software engineering (SE) domain. Aims: This study aims to develop a rubric to identify misogynistic remarks and sexist jokes specifically from software developer communications. Method: We have followed the systematic literature review protocol to identify 10 primary studies that have characterized misogynistic and sexist texts in various domains. Results: Based on our syntheses of the primary studies, we have developed a rubric to manually identity various categories of misogynistic or sexist remarks.We have also provided SE domain specific examples of those categories. Conclusions: Our annotation guideline will pave the path towards building automated misogynistic text classifier for the SE domain.",2021-10-11,Conference Proceeding,Conference Paper,International Symposium on Empirical Software Engineering and Measurement,21100199538,1,,A Rubric to identify misogynistic and sexist texts from software developer communications,0,false,10.1145/3475716.3484189,IEEE Computer Society,133,International Symposium on Empirical Software Engineering and Measurement,2021.0,45.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A rubric to identify misogynistic remarks and sexist jokes specifically from software developer communications is developed and will pave the path towards building automated misogynistic text classifier for the SE domain.'}",2117276459,Sayma Sultana,1471434369,Jaydeb Sarker,2517154,Amiangshu Bosu,,,,,,,7.0,13.0,2.0,7.0,26.0,2.0,40.0,1181.0,16.0,,,,,,,,,,Computer Science
134,"© 2021, Bristol University Press. All rights reserved.Technologically-facilitated violence (TFV) can take many shapes and forms, In this thought piece, we reflect on TFV from structural and intersectional perspectives, examining how these might change our understanding of TFV, with particular attention to gender-based TFV. We are motivated to engage in this reflection for two main reasons. First, traditional understandings of violence, including gender-based violence, tend to prioritise physical acts (whether in word or in application), contributing to a trivialisation of the kinds of harms effected through digitised communications networks (Dunn, 2021). Second, if TFV is understood primarily in terms of individual interpersonal acts, our ability to understand how intersecting oppressions such as sexism, racism, homophobia, transphobia, colonialism affect the likelihood of being targeted and the experience of violence will be compromised. As Black feminist and critical race scholars such as Crenshaw (1991), Hill Collins (2017), and Jiwani, Berman and Cameron (2010) have ably demonstrated, individualistic single axis accounts of violence outside of technologised contexts have resulted in exclusionary and dangerous outcomes that selectively harm members of equality-seeking communities. The result of these individualised understandings of violence is that structural oppressions are ‘erased, trivialised, or contained within categories that evacuate the violation of [structural] violence’ (Jiwani, 2006, xi–xii). Among other effects, such erasure risks rendering invisible opportunities to intervene with respect to violence not carried out by individuals, often resulting in ‘remedies’ that emphasise interventions by the state against individual actors (for example, through criminal law), powers that already disproportionately target members of equality-seeking communities, and misses the potential need to intervene on capitalistic corporate systems and behaviours. In both cases, the prospect of achieving justice recedes.",2021-10-01,Journal,Article,Journal of Gender-Based Violence,21101028118,2,5,Tech-facilitated violence: thinking structurally and intersectionally,0,false,10.1332/239868021X16286662118554,Bristol University Press,134,Journal of Gender-Based Violence,2021.0,0.0,0.0,,1827690,Jane Bailey,2137739975,Jacquie Burkell,,,,,,,,,59.0,514.0,11.0,2.0,1.0,1.0,,,,,,,,,,,,,
135,"© 2021, El Profesional de la Informacion. All rights reserved.During the last decade, the Internet, and the social networks in particular, have gained relevance as spaces for interaction and socialization. The multiplication and penetration of social media, as well as the volume and intensity of interactions, have led to a migration of the public sphere towards these platforms. In this (apparently neutral) virtual context, where social networks contribute to the construction or amplification of social relations, the Internet is configured as a space of inequality where power relations and patriarchal practices are reproduced, amplified by the sensation of anonymity and its disinhibiting effect. This paper analyzes the presence of hate speech and misogyny in the Twitter conversation around 50 Spanish women with public visibility online and in the real world, belonging to diverse professional fields: science, communication, culture, sports, business, and politics. Based on an automated search for insults and other hate terms, a content analysis of the direct interactions and indirect mentions received by these women on this social platform over a period of 1 year was carried out. The results of this study highlight the toxicity of the Twittersphere for female users. Thus, 15% of direct interactions and 10% of indirect interactions directed at these women included some kind of insult or disqualification, although not necessarily of a sexist or misogynist nature. This violence is especially evident against women representatives of those areas with greater visibility and social influence such as communication and politics.",2021-09-09,Journal,Article,Profesional de la Informacion,6200180164,4,30,Step outside and say that: Analysis of hate speech against women on twitter Eso no me lo dices en la calle. Análisis del discurso del odio contra las mujeres en twitter,0,false,10.3145/epi.2021.sep.02,El Profesional de la Informacion,135,El Profesional de la Informacion,2021.0,45.0,0.0,,1403613501,Teresa Piñeiro-Otero,1405092928,X. Martínez-Rolán,,,,,,,,,97.0,219.0,8.0,17.0,74.0,5.0,,,,,,,,,,,,,
136,"© 2021 Orgeira-Crespo et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Inclusive language focuses on using the vocabulary to avoid exclusion or discrimination, specially referred to gender. The task of finding gender bias in written documents must be performed manually, and it is a time-consuming process. Consequently, studying the usage of non-inclusive language on a document, and the impact of different document properties (such as author gender, date of presentation, etc.) on how many non-inclusive instances are found, is quite difficult or even impossible for big datasets. This research analyzes the gender bias in academic texts by analyzing a study corpus of more than 12,000 million words obtained from more than one hundred thousand doctoral theses from Spanish universities. For this purpose, an automated algorithm was developed to evaluate the different characteristics of the document and look for interactions between age, year of publication, gender or the field of knowledge in which the doctoral thesis is framed. The algorithm identified information patterns using a CNN (convolutional neural network) by the creation of a vector representation of the sentences. The results showed evidence that there was a greater bias as the age of the authors increased, who were more likely to use non-inclusive terms; it was concluded that there is a greater awareness of inclusiveness in women than in men, and also that this awareness grows as the candidate is younger. The results showed evidence that the age of the authors increased discrimination, with men being more likely to use noninclusive terms (up to an index of 23.12), showing that there is a greater awareness of inclusiveness in women than in men in all age ranges (with an average of 14.99), and also that this awareness grows as the candidate is younger (falling down to 13.07). In terms of field of knowledge, the humanities are the most biased (20.97), discarding the subgroup of Linguistics, which has the least bias at all levels (9.90), and the field of science and engineering, which also have the least influence (13.46). Those results support the assumption that the bias in academic texts (doctoral theses) is due to unconscious issues: Otherwise, it would not depend on the field, age, gender, and would occur in any field in the same proportion. The innovation provided by this research lies mainly in the ability to detect, within a textual document in Spanish, whether the use of language can be considered non-inclusive, based on a CNN that has been trained in the context of the doctoral thesis. A significant number of documents have been used, using all accessible doctoral theses from Spanish universities of the last 40 years; this dataset is only manageable by data mining systems, so that the training allows identifying the terms within the context effectively and compiling them in a novel dictionary of non-inclusive terms.",2021-09-01,Journal,Article,PLoS ONE,10600153309,1,16,An analysis of unconscious gender bias in academic texts by means of a decision algorithm,1,true,10.1371/journal.pone.0257903,Public Library of Science,136,PLoS ONE,2021.0,98.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'An automated algorithm was developed to evaluate the different characteristics of the document and look for interactions between age, year of publication, gender or the field of knowledge in which the doctoral thesis is framed, showing evidence that the bias in academic texts (doctoral theses) is due to unconscious issues.'}",1995519339,Pedro Orgeira-Crespo,1403905031,C. Míguez-Álvarez,1402004955,Miguel Cuevas-Alonso,1422199198,Elena Rivo-López,,,,,7.0,20.0,2.0,29.0,116.0,5.0,12.0,32.0,4.0,27.0,88.0,5.0,,,,,,,Medicine
137,"© 2021 Sociedad Española para el Procesamiento del Lenguaje NaturalThe paper describes the organization, goals, and results of the sEXism Identification in Social neTworks (EXIST) challenge, a shared task proposed for the first time at IberLEF 2021. EXIST 2021 proposes two challenges: sexism identification and sexism categorization of tweets and gabs, both in Spanish and English. We have received a total of 70 runs for the sexism identification task and 61 for the sexism categorization challenge, submitted by 31 different teams from 11 countries. We present the dataset, the evaluation methodology, an overview of the proposed systems, and the results obtained. The final dataset consists of more than 11,000 annotated texts from two social networks (Twitter and Gab) and its development has been supervised and monitored by experts in gender issues.",2021-09-01,Journal,Review,Procesamiento del Lenguaje Natural,21100195304,47,67,Overview of EXIST 2021: sEXism Identification in Social neTworks Overview de EXIST 2021: Identificación de Sexismo en Redes Sociales,,,10.26342/2021-67-17,Sociedad Espanola para el Procesamiento del Lenguaje Natural,137,Proces. del Leng. Natural,2021.0,30.0,9.0,"{'model': 'tldr@v2.0.0', 'text': 'The organization, goals, and results of the sEXism Identiﬁcation in Social neTworks (EXIST) challenge, a shared task proposed for the first time at IberLEF 2021, are described.'}",1403518310,F. Rodríguez‐Sánchez,1410230608,Jorge Carrillo-de-Albornoz,145377713,Laura Plaza,1681160,Julio Gonzalo,143752702,Paolo Rosso,2135152230,Miriam Comet,44.0,2701.0,19.0,15.0,218.0,7.0,58.0,1060.0,20.0,189.0,5239.0,33.0,646.0,16149.0,63.0,1.0,66.0,1.0,Computer Science
138,"© 2021 The Author(s)Analysis of subjective texts like offensive content or hate speech is a great challenge, especially regarding annotation process. Most of current annotation procedures are aimed at achieving a high level of agreement in order to generate a high quality reference source. However, the annotation guidelines for subjective content may restrict the annotators’ freedom of decision making. Motivated by a moderate annotation agreement in offensive content datasets, we hypothesize that personalized approaches to offensive content identification should be in place. Thus, we propose two novel perspectives of perception: group-based and individual. Using demographics of annotators as well as embeddings of their previous decisions (annotated texts), we are able to train multimodal models (including transformer-based) adjusted to personal or community profiles. Based on the agreement of individuals and groups, we experimentally showed that annotator group agreeability strongly correlates with offensive content recognition quality. The proposed personalized approaches enabled us to create models adaptable to personal user beliefs rather than to agreed offensiveness understanding. Overall, our individualized approaches to offensive content classification outperform classic data-centric methods that generalize offensiveness perception and it refers to all six tested models. Additionally, we developed requirements for annotation procedures, personalization and content processing to make the solutions human-centered.",2021-09-01,Journal,Article,Information Processing and Management,12689,22,58,"Offensive, aggressive, and hate speech analysis: From data-centric to human-centered approach",1,true,10.1016/j.ipm.2021.102643,Elsevier Ltd,138,Information Processing & Management,2021.0,132.0,2.0,"{'model': 'tldr@v2.0.0', 'text': 'This work proposed two novel perspectives of perception: group-based and individual, which outperform classic data-centric methods that generalize offensiveness perception and developed requirements for annotation procedures, personalization and content processing to make the solutions human-centered.'}",2905929,Jan Kocoń,2120746557,Alicja Figas,2120757466,Marcin Gruza,2004053871,Daria Puchalska,1787971,Tomasz Kajdanowicz,1724788,Przemyslaw Kazienko,60.0,301.0,9.0,2.0,32.0,2.0,11.0,46.0,4.0,4.0,34.0,2.0,129.0,1366.0,21.0,237.0,3533.0,31.0,Computer Science
139,"© 2021 Johan Brännmark, published by De Gruyter, Berlin/Boston.In considering patriarchy as potentially institutional and as a characteristic also of contemporary Western societies, a fundamental issue concerns how to make sense of largely informal institutions to begin with. Traditional accounts of institutions have often focused on formalized ones. It is argued here, however, that the principal idea behind one commonly accepted conception of institutions can be developed in a way that better facilitates an explication of informal institutions. When applied to the phenomenon of patriarchy, such an approach can then also allow us to ontologically make sense of gray areas and hierarchies of authority, as well as the intersectionality of social positions.",2021-08-01,Journal,Article,Journal of Social Ontology,21100900143,0,7,Patriarchy as Institutional,1,true,10.1515/jso-2021-0033,Walter de Gruyter GmbH,139,Journal of Social Ontology,2021.0,25.0,0.0,,20878377,Johan Brännmark,,,,,,,,,,,47.0,154.0,7.0,,,,,,,,,,,,,,,,
140,"© 2021 Elsevier LtdInstagram is a free photo-sharing platform where each user has a profile and can upload photos for followers to view, like, and comment. Abusive comments on images can be humiliating and harmful to those who share photos. Developing a comment filter in languages other than English is difficult and time-consuming. This paper proposes a dataset called Abusive Turkish Comments (ATC) to detect abusive Instagram comments in Turkish. It is composed of a large number of Instagram comments posted to tabloid and sports accounts (i.e., 10,528 abusive and 19,826 not-abusive). It is the first public dataset dedicated to detecting abusive Turkish messages, as far as we know. The sentiment annotation has been done in sentence-level by assigning polarity to each comment. The performance of the abusive message detection models was evaluated using several performance metrics: Convolutional Neural Network (CNN), five well-known classifiers (i.e., Naive Bayes, Support Vector Machine, Decision Tree, Random Forest, and Logistic Regression), and two reweighted classifiers (i.e., Adaptive Boosting (AdaBoost), eXtreme Gradient Boosting (XGBoost)) were compared in terms of F1-score, precision, and recall. The results showed that the best performance (i.e., Micro-averaged F1-score: 0.974, Macro-averaged F1-score: 0.973, Kappa-value: 0.946) was yielded by the CNN model on the oversampled ATC dataset. The abusive message detection model proposed in this study can contribute to the development of Turkish comment filters on Instagram. Different model combinations are considered to select the best model that gives better recognition accuracy.",2021-07-15,Journal,Article,Expert Systems with Applications,24201,10,174,Detecting abusive Instagram comments in Turkish using convolutional Neural network and machine learning methods,0,false,10.1016/j.eswa.2021.114802,Elsevier Ltd,140,Expert systems with applications,2021.0,113.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'The abusive message detection model proposed in this study can contribute to the development of Turkish comment filters on Instagram by selecting the best model that gives better recognition accuracy.'}",95925384,Habibe Karayigit,28336630,C. Aci,2236535,A. Akdagli,,,,,,,5.0,15.0,2.0,25.0,269.0,8.0,85.0,1260.0,18.0,,,,,,,,,,Computer Science
142,"© 2021 AI Access Foundation. All rights reserved.The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this technology can cause unintended harms, such as the silencing of under-represented groups. We review a large body of NLP research on automatic abuse detection with a new focus on ethical challenges, organized around eight established ethical principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. In many cases, these principles relate not only to situational ethical codes, which may be context-dependent, but are in fact connected to universal human rights, such as the right to privacy, freedom from discrimination, and freedom of expression. We highlight the need to examine the broad social impacts of this technology, and to bring ethical and human rights considerations to every stage of the application life-cycle, from task formulation and dataset design, to model training and evaluation, to application deployment. Guided by these principles, we identify several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse, including 'nudging', 'quarantining', value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.",2021-07-01,Journal,Review,Journal of Artificial Intelligence Research,24330,12,71,Confronting abusive language online: A survey from the ethical and human rights perspective,1,true,10.1613/JAIR.1.12590,AI Access Foundation,142,Journal of Artificial Intelligence Research,2020.0,240.0,3.0,"{'model': 'tldr@v2.0.0', 'text': 'Several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse are identified, including ‘nudging’, ‘quarantining‘, value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.'}",2886725,Svetlana Kiritchenko,3163125,I. Nejadgholi,2022276,Kathleen C. Fraser,,,,,,,68.0,7885.0,35.0,41.0,355.0,12.0,70.0,1258.0,17.0,,,,,,,,,,Computer Science
143,"© 2021 Association for Computing Machinery.Sexism, an injustice that subjects women and girls to enormous suffering, manifests in blatant as well as subtle ways. In the wake of growing documentation of experiences of sexism on the web, the automatic categorization of accounts of sexism has the potential to assist social scientists and policymakers in studying and thereby countering sexism. The existing work on sexism classification has certain limitations in terms of the categories of sexism used and/or whether they can co-occur. To the best of our knowledge, this is the first work on the multi-label classification of sexism of any kind(s).1 We also consider the related task of misogyny classification. While sexism classification is performed on textual accounts describing sexism suffered or observed, misogyny classification is carried out on tweets perpetrating misogyny. We devise a novel neural framework for classifying sexism and misogyny that can combine text representations obtained using models such as Bidirectional Encoder Representations from Transformers with distributional and linguistic word embeddings using a flexible architecture involving recurrent components and optional convolutional ones. Further, we leverage unlabeled accounts of sexism to infuse domain-specific elements into our framework. To evaluate the versatility of our neural approach for tasks pertaining to sexism and misogyny, we experiment with adapting it for misogyny identification. For categorizing sexism, we investigate multiple loss functions and problem transformation techniques to address the multi-label problem formulation. We develop an ensemble approach using a proposed multi-label classification model with potentially overlapping subsets of the category set. Proposed methods outperform several deep-learning as well as traditional machine learning baselines for all three tasks.",2021-07-01,Journal,Article,ACM Transactions on the Web,5800207369,9,15,Categorizing Sexism and Misogyny through Neural Approaches,0,false,10.1145/3457189,Association for Computing Machinery,143,ACM Transactions on the Web,2021.0,51.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'A novel neural framework for classifying sexism and misogyny that can combine text representations obtained using models such as Bidirectional Encoder Representations from Transformers with distributional and linguistic word embeddings using a flexible architecture involving recurrent components and optional convolutional ones is devised.'}",36328737,Pulkit Parikh,3442296,Harika Abburi,2954043,Niyati Chhaya,46722320,Manish Gupta,145205784,Vasudeva Varma,,,21.0,96.0,5.0,15.0,118.0,5.0,63.0,633.0,10.0,106.0,2044.0,17.0,32.0,151.0,5.0,,,,Computer Science
144,"© 2021 ACM.The exponential rise of online social media has enabled the creation, distribution, and consumption of information at an unprecedented rate. However, it has also led to the burgeoning of various forms of online abuse. Increasing cases of online antisemitism have become one of the major concerns because of its socio-political consequences. Unlike other major forms of online abuse like racism, sexism, etc., online antisemitism has not been studied much from a machine learning perspective. To the best of our knowledge, we present the first work in the direction of automated multimodal detection of online antisemitism. The task poses multiple challenges that include extracting signals across multiple modalities, contextual references, and handling multiple aspects of antisemitism. Unfortunately, there does not exist any publicly available benchmark corpus for this critical task. Hence, we collect and label two datasets with 3,102 and 3,509 social media posts from Twitter and Gab respectively. Further, we present a multimodal deep learning system that detects the presence of antisemitic content and its specific antisemitism category using text and images from posts. We perform an extensive set of experiments on the two datasets to evaluate the efficacy of the proposed system. Finally, we also present a qualitative analysis of our study.",2021-06-21,Conference Proceeding,Conference Paper,ACM International Conference Proceeding Series,11600154611,8,,Subverting the Jewtocracy: Online Antisemitism Detection Using Multimodal Deep Learning,2,,10.1145/3447535.3462502,Association for Computing Machinery,144,Web Science Conference,2021.0,43.0,2.0,"{'model': 'tldr@v2.0.0', 'text': 'This work presents a multimodal deep learning system that detects the presence of antisemitic content and its specific antisemitism category using text and images from posts.'}",32556330,Mohit Chandra,1388051395,D. Pailla,2001006896,Himanshu Bhatia,2028782907,AadilMehdi J. Sanchawala,46722320,Manish Gupta,2045067,Manish Shrivastava,5.0,41.0,4.0,4.0,56.0,3.0,6.0,32.0,3.0,5.0,22.0,2.0,106.0,2044.0,17.0,166.0,1896.0,23.0,Computer Science
149,"© 2021 Elsevier LtdA considerable body of research deals with the automatic identification of hate speech and related phenomena. However, cross-dataset model generalization remains a challenge. In this context, we address two still open central questions: (i) to what extent does the generalization depend on the model and the composition and annotation of the training data in terms of different categories?, and (ii) do specific features of the datasets or models influence the generalization potential? To answer (i), we experiment with BERT, ALBERT, fastText, and SVM models trained on nine common public English datasets, whose class (or category) labels are standardized (and thus made comparable), in intra- and cross-dataset setups. The experiments show that indeed the generalization varies from model to model and that some of the categories (e.g., ‘toxic’, ‘abusive’, or ‘offensive’) serve better as cross-dataset training categories than others (e.g., ‘hate speech’). To answer (ii), we use a Random Forest model for assessing the relevance of different model and dataset features during the prediction of the performance of 450 BERT, 450 ALBERT, 450 fastText, and 348 SVM binary abusive language classifiers (1698 in total). We find that in order to generalize well, a model already needs to perform well in an intra-dataset scenario. Furthermore, we find that some other parameters are equally decisive for the success of the generalization, including, e.g., the training and target categories and the percentage of the out-of-domain vocabulary.",2021-05-01,Journal,Article,Information Processing and Management,12689,32,58,"How well do hate speech, toxicity, abusive and offensive language classification models generalize across datasets?",1,true,10.1016/j.ipm.2021.102524,Elsevier Ltd,149,Information Processing & Management,2021.0,54.0,1.0,,33621471,Paula Fortuna,144340954,Juan Soler,9092408,L. Wanner,,,,,,,16.0,916.0,8.0,22.0,232.0,8.0,83.0,1106.0,18.0,,,,,,,,,,Computer Science
150,"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.The problem of gender-based violence in Mexico has been increased considerably. Many social associations and governmental institutions have addressed this problem in different ways. In the context of computer science, some effort has been developed to deal with this problem through the use of machine learning approaches to strengthen the strategic decision making. In this work, a deep learning neural network application to identify gender-based violence on Twitter messages is presented. A total of 1,857,450 messages (generated in Mexico) were downloaded from Twitter: 61,604 of them were manually tagged by human volunteers as negative, positive or neutral messages, to serve as training and test data sets. Results presented in this paper show the effectiveness of deep neural network (about 80% of the area under the receiver operating characteristic) in detection of gender violence on Twitter messages. The main contribution of this investigation is that the data set was minimally pre-processed (as a difference versus most state-of-the-art approaches). Thus, the original messages were converted into a numerical vector in accordance to the frequency of word’s appearance and only adverbs, conjunctions and prepositions were deleted (which occur very frequently in text and we think that these words do not contribute to discriminatory messages on Twitter). Finally, this work contributes to dealing with gender violence in Mexico, which is an issue that needs to be faced immediately.",2021-04-02,Journal,Article,Mathematics,21100830702,4,9,Deep neural network for gender-based violence detection on twitter messages,1,true,10.3390/math9080807,MDPI AG,150,Mathematics,2021.0,79.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'Results presented in this paper show the effectiveness of deep neural network (about 80% of the area under the receiver operating characteristic) in detection of gender violence on Twitter messages.'}",2077526144,Carlos Castorena,71562371,Itzel Abundez,2578667,R. Alejo,1410653918,E. E. Granda-Gutiérrez,72336479,Eréndira Rendón,2090967961,Octavio Villegas,6.0,43.0,2.0,4.0,497.0,4.0,49.0,735.0,13.0,37.0,200.0,7.0,6.0,534.0,5.0,1.0,6.0,1.0,Computer Science
152,"© The Author(s) 2021.This article discusses the resurgence of the term ‘patriarchy’ in digital culture and reflects on the everyday online meanings of the term in distinction to academic theorisations. In the 1960s–1980s, feminists theorised patriarchy as the systematic oppression of women, with differing approaches to how it worked. Criticisms that the concept was unable to account for intersectional experiences of oppression, alongside the ‘turn to culture’, resulted in a fall from academic grace. However, ‘patriarchy’ has found new life through Internet memes (humorous, mutational images that circulate widely on social media). This article aims to investigate the resurgence of the term ‘patriarchy’ in digital culture. Based on an analysis of memes with the phrase ‘patriarchy’ and ‘smash the patriarchy’, we identify how patriarchy memes are used by two different online communities (feminists and anti-feminists) and consider what this means for the ongoing usefulness of the concept of patriarchy. We argue that, whilst performing important community-forming work, using the term is a risky strategy for feminists for two reasons: first, because memes are by their nature brief, there is little opportunity to address intersections of oppression; secondly, the underlying logic of feminism is omitted in favour of brevity, leaving it exposed to being undermined by the more mainstream logic of masculinism.",2021-04-01,Journal,Article,Feminist Theory,700147308,2,22,‘Smash the patriarchy’: the changing meanings and work of ‘patriarchy’ online,2,,10.1177/1464700120988643,SAGE Publications Ltd,152,,2021.0,111.0,0.0,,49599054,R. Hill,47322618,K. Allen,,,,,,,,,61.0,569.0,11.0,92.0,1328.0,19.0,,,,,,,,,,,,,
153,"© 2020 Elsevier LtdNowadays, due to the great uncontrolled content posted daily on the Web, there has also been a huge increase in the dissemination of hate speech worldwide. Social media, blogs and community forums are examples where people are freely allowed to communicate. However, freedom of expression is not always respectful since offensive or insulting language is sometimes used. Social media companies often rely on users and content moderators to report on this type of content. Nevertheless, due to the large amount of content generated every day on the Web, automatic systems based on Natural Language Processing techniques are required for identifying abusive language online. To date, most of the systems developed to combat this problem are mainly focused on English content, but this issue is a worldwide concern and therefore other languages such as Spanish are involved. In this paper, we address the task of Spanish hate speech identification on social media and provide a deeper understanding of the capabilities of new techniques based on machine learning. In particular, we compare the performance of Deep Learning methods with recently pre-trained language models based on Transfer Learning as well as with traditional machine learning models. Our main contribution is the achievement of promising results in Spanish by applying multilingual and monolingual pre-trained language models such as BERT, XLM and BETO.",2021-03-15,Journal,Article,Expert Systems with Applications,24201,43,166,Comparing pre-trained language models for Spanish hate speech detection,0,false,10.1016/j.eswa.2020.114120,Elsevier Ltd,153,Expert systems with applications,2021.0,59.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper addresses the task of Spanish hate speech identification on social media and provides a deeper understanding of the capabilities of new techniques based on machine learning, including Deep Learning methods with recently pre-trained language models based on Transfer Learning as well as with traditional machine learning models.'}",3455118,Flor Miriam Plaza del Arco,1398823104,M. Molina-González,145200121,L. A. U. López,51183850,M. T. M. Valdivia,,,,,33.0,216.0,6.0,32.0,432.0,9.0,180.0,2788.0,27.0,36.0,327.0,9.0,,,,,,,Computer Science
154,"© 2021 Sociedad Española para el Procesamiento del Lenguaje NaturalMisogyny is a multifaceted phenomenon and can be linguistically manifested in numerous ways. The evaluation campaigns of EVALITA and IberEval in 2018 proposed a shared task of Automatic Misogyny Identification (AMI) based on Italian, English and Spanish tweets. Since the participating teams’ results were pretty low in the misogynistic behaviour categorization, the aim of this study is to investigate the possible causes. We measured the overlap and the homogeneity of the clusters by varying the number of categories. This experiment showed that the clusters overlap. Finally, we tested several machine learning models both using the original data sets and merging together some categories according to their overlap, obtaining an increase in terms of macro F1.",2021-03-01,Journal,Article,Procesamiento del Lenguaje Natural,21100195304,1,66,"Categorizing misogynistic behaviours in Italian, English and Spanish tweets Categorización de comportamientos misóginos en tweets en italiano, inglés y español",,,10.26342/2021-66-5,Sociedad Espanola para el Procesamiento del Lenguaje Natural,154,Proces. del Leng. Natural,2021.0,19.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This experimento probamos varios modelos de aprendizaje automatico utilizando los conjuntos de datos originales and fusionando algunas categorias de acuerdo with consideraciones basadas en medidas de similitud and las matrices de confusion of the modelos, obteniendo un aumento of the F1 macro.'}",2082347079,Silvia Lazzardi,1787198,V. Patti,143752702,Paolo Rosso,,,,,,,2.0,5.0,1.0,220.0,4576.0,36.0,646.0,16149.0,63.0,,,,,,,,,,Computer Science
155,"© The Author(s) 2021.How online social behavior covaries with real-world outcomes remains poorly understood. We examined the relationship between the frequency of misogynistic attitudes expressed on Twitter and incidents of domestic and family violence that were reported to the Federal Bureau of Investigation. We tracked misogynistic tweets in more than 400 areas across 47 American states from 2013 to 2014. Correlation and regression analyses found that misogynistic tweets were related to domestic- and family-violence incidents in those areas. A cross-lagged model showed that misogynistic tweets positively predicted domestic and family violence 1 year later; however, this effect was small. Results were robust to several known predictors of domestic violence. Our findings identify geolocated online misogyny as co-occurring with domestic and family violence. Because the longitudinal relationship between misogynistic tweets and domestic and family violence was small and conducted at the societal level, more research with multilevel data might be useful in the prediction of future violence.",2021-03-01,Journal,Article,Psychological Science,13468,12,32,Misogynistic Tweets Correlate With Violence Against Women,0,false,10.1177/0956797620968529,SAGE Publications Inc.,155,Psychology Science,2021.0,50.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'Because the longitudinal relationship between misogynistic tweets and domestic and family violence was small and conducted at the societal level, more research with multilevel data might be useful in the prediction of future violence.'}",6914117,Khandis R. Blake,1403353978,Siobhan M. O’Dean,2051149227,James Lian,2990169,T. Denson,,,,,67.0,758.0,16.0,13.0,298.0,7.0,4.0,20.0,2.0,131.0,5434.0,41.0,,,,,,,"Psychology, Medicine"
156,"© 2020, The Author(s), under exclusive licence to Springer Nature Limited.In recent years, the dominant Western discourse on “female genital mutilation” (FGM) has increasingly been challenged by scholars. Numerous researchers contest both the terminology used and the empirical claims made in what has come to be called “the standard tale” of FGM (also termed “female genital cutting” [FGC]). The World Health Organization (WHO), a major player in setting the global agenda on this issue, maintains that all medically unnecessary cutting of the external female genitalia, no matter how slight, should be banned as torture and a violation of the human right to bodily integrity. However, the WHO targets only non-Western forms of female-only genital cutting, raising concerns about gender bias and cultural imperialism. Here, we summarize ongoing critiques of the WHO’s terminology, ethicolegal assumptions, and empirical claims, including the claim that non-Western FGC as such constitutes an extreme form of discrimination against women. To this end, we highlight recent comparative studies of medically unnecessary genital cutting of all types, including those affecting adult women and teenagers in Western societies, individuals with differences of sex development (DSD), transgender persons, and males. In so doing, we attempt to clarify the grounds for a growing critical consensus that current anti-FGM laws and policies may be ethically incoherent, empirically unsupportable, and legally unsustainable.",2021-03-01,Journal,Review,International Journal of Impotence Research,19933,21,33,Current critiques of the WHO policy on female genital mutilation,0,false,10.1038/s41443-020-0302-0,Springer Nature,156,International journal of impotence research,2020.0,175.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'Comparing recent comparative studies of medically unnecessary genital cutting of all types, including those affecting adult women and teenagers in Western societies, individuals with differences of sex development (DSD), transgender persons,\xa0and males, are highlighted.'}",5400392,B. Earp,6331835,S. Johnsdotter,,,,,,,,,206.0,3733.0,33.0,104.0,1826.0,26.0,,,,,,,,,,,,,Medicine
161,"© 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.In the autumn of 2018 Greta Thunberg started her school strike. Soon she and the Fridays For Future-movement rose to world-fame, stirring a backlash laying bare the intrinsic climate change denial of Swedish far-right digital media. These outlets had previously been almost silent on climate change, but in 2019, four of the ten most read articles on the site Samhällsnytt were about Thunberg, all of them discrediting the movement and spreading doubt about climate science. Using the conceptualisation of industrial/breadwinner masculinities as developed by Hultman and Pulé [2018. Ecological Masculinities: Theoretical Foundations and Practical Guidance. Routledge Studies in Gender and Environments. New York: Routledge], this article analyses what provoked this reaction. It explores how the hostility to Thunberg was constructed in far-right media discourse in the years 2018–2019, when she became a threat to an imagined industrial, homogenic and patriarchal community. Using conspiracy theories and historical tropes of irrational femininity, the far right was trying to protect the usually hidden environmental privileges, related to unequal carbon emissions and resource use, that Thunberg and her movement made visible.",2021-01-01,Journal,Article,Australian Feminist Studies,23058,0,36,"Dead White men vs. Greta Thunberg: Nationalism, Misogyny, and Climate Change Denial in Swedish far-right Digital Media",1,true,10.1080/08164649.2022.2062669,Routledge,161,Australian feminist studies,2021.0,90.0,0.0,,2117662109,Kjell Vowles,46745938,Martin Hultman,,,,,,,,,2.0,5.0,1.0,47.0,497.0,12.0,,,,,,,,,,,,,
162,"© 2021 IEEE.At every stage of a supervised learning process, harmful biases can arise and be inadvertently introduced, ul-timately leading to marginalization, discrimination, and abuse towards minorities. This phenomenon becomes particularly im-pactful in the sensitive real-world context of abusive language detection systems, where non-discrimination is difficult to assess. In addition, given the opaqueness of their internal behavior, the dynamics leading a model to a certain decision are often not clear nor accountable, and significant problems of trust could emerge. A robust value-oriented evaluation of models' fairness is therefore necessary. In this paper, we present FairShades, a model-agnostic approach for auditing the outcomes of abusive language detection systems. Combining explainability and fairness evaluation, Fair-Shades can identify unintended biases and sensitive categories towards which models are most discriminative. This objective is pursued through the auditing of meaningful counterfactuals generated within CheckList framework. We conduct several ex-periments on BERT-based models to demonstrate our proposal's novelty and effectiveness for unmasking biases.",2021-01-01,Conference Proceeding,Conference Paper,"Proceedings - 2021 IEEE 3rd International Conference on Cognitive Machine Intelligence, CogMI 2021",21101087104,0,,FairShades: Fairness Auditing via Explainability in Abusive Language Detection Systems,0,false,10.1109/CogMI52975.2021.00014,Institute of Electrical and Electronics Engineers Inc.,162,International Conference on Cognitive Machine Intelligence,2021.0,0.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'FairShades is presented, a model-agnostic approach for auditing the outcomes of abusive language detection systems that combines explainability and fairness evaluation, which can identify unintended biases and sensitive categories towards which models are most discriminative.'}",2121386115,Marta Marchiori Manerba,1704327,Riccardo Guidotti,,,,,,,,,4.0,8.0,2.0,116.0,3861.0,20.0,,,,,,,,,,,,,Computer Science
163,"© 2021 IEEE.The influence of sentiment polarization and ex-change in online social networks has been growing and studied by many researchers and organizations worldwide. For example, the sentiments expressed in a text concerning a topic in the discussion tend to influence a community when a Twitter user retweets the original text, causing a chain of reactions within a network. This paper investigates sentiment polarization in Twitter, focusing on tweets with the hashtags #Coronavirus, #ClimateChange #Immigrants, and #MeToo. Specifically, we collect the tweets mentioned above and classify them into five categories: hate speech, offensive, sexism, positive, and neutral. In this context, we address the problem as a multiclass classification problem by using the pre-trained language models ULMFiT and AWD-LSTM, which achieved a Fmicro of 0.85. Finally, we use the classified dataset to conduct a case study in which we capture the sentiment orientation during the network evolution.",2021-01-01,Conference Proceeding,Conference Paper,"2021 8th International Conference on Social Network Analysis, Management and Security, SNAMS 2021",21101083122,0,,Sentiment Polarization in Online Social Networks: The Flow of Hate Speech,0,false,10.1109/SNAMS53716.2021.9732077,Institute of Electrical and Electronics Engineers Inc.,163,"International Conference on Social Networks Analysis, Management and Security",2021.0,42.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper investigates sentiment polarization in Twitter, focusing on tweets with the hashtags #Coronavirus, #ClimateChange #Immigrants, and #MeToo, and classify them into five categories: hate speech, offensive, sexism, positive, and neutral.'}",2545574,K. Katsarou,2159001026,Sukanya Sunder,22814558,Vinicius Woloszyn,2973714,Konstantinos Semertzidis,,,,,13.0,118.0,4.0,1.0,0.0,0.0,24.0,117.0,6.0,19.0,210.0,7.0,,,,,,,Computer Science
164,"© 2021, The Author(s).Hate speech should be tackled and prosecuted based on how it is operationalized. However, the existing theoretical definitions of hate speech are not sufficiently fleshed out or easily operable. To overcome this inadequacy, and with the help of interdisciplinary experts, we propose an empirical definition of hate speech by providing a list of 10 hate speech indicators and the rationale behind them (the indicators refer to specific, observable, and measurable characteristics that offer a practical definition of hate speech). A preliminary exploratory examination of the structure of hate speech, with the focus on comments related to migrants (one of the most reported grounds of hate speech), revealed that two indicators in particular, denial of human rights and promoting violent behavior, occupy a central role in the network of indicators. Furthermore, we discuss the practical implications of the proposed hate speech indicators—especially (semi-)automatic detection using the latest natural language processing (NLP) and machine learning (ML) methods. Having a set of quantifiable indicators could benefit researchers, human right activists, educators, analysts, and regulators by providing them with a pragmatic approach to hate speech assessment and detection.",2021-01-01,Journal,Article,Complex and Intelligent Systems,21101095931,3,,Hate speech operationalization: a preliminary examination of hate speech indicators and their structure,1,true,10.1007/s40747-021-00561-0,Springer International Publishing,164,Complex & Intelligent Systems,2021.0,43.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'An empirical definition of hate speech is proposed by providing a list of 10 hate speech indicators and the rationale behind them (the indicators refer to specific, observable, and measurable characteristics that offer a practical definition ofhate speech).'}",69362038,J. Papcunová,1989585,Marcel Martončik,115714892,D. Fedáková,2091741127,Michal Kentoš,118030620,Miroslava Bozogáňová,2129782,Ivan Srba,7.0,8.0,1.0,31.0,315.0,7.0,22.0,65.0,5.0,12.0,28.0,3.0,16.0,17.0,2.0,35.0,516.0,12.0,
165,"© 2021 IEEE.Hateful and offensive speech on online social media platforms has seen a rise in the recent years. Often used to convey humor through sarcasm or to emphasize a point, offensive speech may also be employed to insult, deride and mock alternate points of view. In turbulent and chaotic circumstances, insults and mockery can lead to violence and unrest, and hence, such speech must be identified and tagged to limit its damage. This paper presents an application of machine learning to detect hateful and offensive content from Twitter feeds shared after the protests by Proud Boys, an extremist, ideological and violent hate group. A comprehensive coding guide, consolidating definitions of what constitutes offensive content based on the potential to trigger and incite people is developed and used to label the tweets. Linguistic, auxiliary and social features extracted from these labeled tweets were used to train machine learning classifiers, which detect offensive content with an accuracy of about 92%. An analysis of the importance scores reveals that offensiveness is pre-dominantly a function of words and their combinations, rather than meta features such as punctuations and quotes. This observation can form the foundation of pre-trained classifiers that can be deployed to automatically detect offensive speech in new and unforeseen circumstances.",2021-01-01,Conference Proceeding,Conference Paper,"Proceedings - 20th IEEE International Conference on Machine Learning and Applications, ICMLA 2021",21101079400,3,,Detecting Offensive Content on Twitter during Proud Boys Riots,0,false,10.1109/ICMLA52953.2021.00253,Institute of Electrical and Electronics Engineers Inc.,165,International Conference on Machine Learning and Applications,2021.0,0.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'An application of machine learning to detect hateful and offensive content from Twitter feeds shared after the protests by Proud Boys, an extremist, ideological and violent hate group is presented.'}",2065405590,M. Fahim,1724704,S. Gokhale,,,,,,,,,6.0,7.0,2.0,229.0,3447.0,28.0,,,,,,,,,,,,,Computer Science
167,"© 2021 IEEE.In an ideal world, deployed machine learning models will enhance our society. We hope that those models will provide unbiased and ethical decisions that will benefit everyone. However, this is not always the case; issues arise during the data preparation process throughout the steps leading to the models' deployment. The continued use of biased datasets and biased processes will adversely damage communities and increase the cost to fix the problem later. In this work, we walk through the decision making process that a researcher should consider before, during, and after a system deployment to understand the broader impacts of their research in the community. Throughout this paper, we discuss fairness, privacy, and ownership issues in the machine learning pipeline, assert the need for a responsible human-over-the-loop methodology to bring accountability into machine learning pipeline, and finally, reflect on the need to explore research agendas that have harmful societal impacts. We examine visual privacy research and draw lessons that can apply broadly to artificial intelligence. Our goal is to provide a systematic analysis of the machine learning pipeline for visual privacy and bias issues. With this pipeline, we hope to raise stakeholder (e.g., researchers, modelers, corporations) awareness as these issues propagate in the various machine learning phases.",2021-01-01,Conference Proceeding,Conference Paper,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",21101077500,0,,Proposing an Interactive Audit Pipeline for Visual Privacy Research,2,,10.1109/BigData52589.2021.9671478,Institute of Electrical and Electronics Engineers Inc.,167,2021 IEEE International Conference on Big Data (Big Data),2021.0,75.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The decision making process that a researcher should consider before, during, and after a system deployment is walked through to understand the broader impacts of their research in the community and raise stakeholder awareness as issues propagate in the various machine learning phases.'}",50978378,Jasmine DeHart,2153077215,Chenguang Xu,2137967742,Lisa Egede,4985351,Christan Earl Grant,,,,,17.0,19.0,3.0,2.0,3.0,1.0,3.0,24.0,1.0,40.0,283.0,10.0,,,,,,,Computer Science
168,"© 2021 IEEE.While most conversations on social media are inspiring and uplifting, a fraction of the users do engage in sharing content that supports extremist, radical philosophies and organizations. Such rhetoric, if left unchecked, can propagate virally on these platforms, ultimately escalating to turbulence and violence in the physical, offline spaces. Identifying such content from the volumes of social media feeds is therefore necessary to prevent the damage that it may cause, yet it is infeasible to undertake manually, calling for an automated approach. This paper demonstrates the potential of machine learning to separate social media feeds that are sympathetic to radical extremism using the example of Proud Boys, a contemporary right-wing group. From the tweets collected after Proud Boys protests in August 2020; linguistic, social and auxiliary features are extracted. Significance tests are used to select a subset of these features that contribute towards separating between extremist and normal content. Several machine learning models are trained based on a combination of these features. These models can identify tweets that support Proud Boys with excellent performance metrics. Artificial Neural Networks offer the best accuracy, precision, recall and F1-score. Feature importance, assessed using the Random Forest model indicates that users rely both on the expressive power of the language and other metadata features such as punctuations, mentions and URLs to voice and spread hateful ideology on online platforms.",2021-01-01,Conference Proceeding,Conference Paper,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",21101077500,0,,Identifying Social Media Content Supporting Proud Boys,0,false,10.1109/BigData52589.2021.9671823,Institute of Electrical and Electronics Engineers Inc.,168,2021 IEEE International Conference on Big Data (Big Data),2021.0,0.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The potential of machine learning to separate social media feeds that are sympathetic to radical extremism using the example of Proud Boys, a contemporary right-wing group is demonstrated.'}",2065405590,M. Fahim,1724704,S. Gokhale,,,,,,,,,6.0,7.0,2.0,229.0,3447.0,28.0,,,,,,,,,,,,,Computer Science
170,"© 2021 IEEE.The important growth of social media and online gaming sites in recent years have increased the challenge of online moderation to keep the internet safe and without toxic content. Today, machine learning techniques play an important role in detecting inappropriate content and help moderate online interaction. Text classification using Natural Language Processing (NLP) methods has been extensively studied using deep learning models and transformers which have shown impressive results. Despite this, specific classification tasks on limited datasets still need to be improved. In this paper, we propose an approach based on an Attention-Based Bidirectional LSTM model and a combination of custom features to enhance automatic misogyny identification (AMI) on social media. We present a multi-lingual study of the phenomena by carrying out different classification experiments. Our study focuses on selecting most important features to improve the model for misogyny detection. The proposed model outperforms many state-of-the-art approaches across multiple datasets.",2021-01-01,Conference Proceeding,Conference Paper,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",145097,1,,Automatic Misogyny Detection in Social Media Platforms using Attention-based Bidirectional-LSTM*,0,false,10.1109/SMC52423.2021.9659158,Institute of Electrical and Electronics Engineers Inc.,170,"IEEE International Conference on Systems, Man and Cybernetics",2021.0,31.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes an approach based on an Attention-Based Bidirectional LSTM model and a combination of custom features to enhance automatic misogyny identification (AMI) on social media and outperforms many state-of-the-art approaches across multiple datasets.'}",2023723083,Abir Rahali,2629166,M. Akhloufi,2149090128,Anne-Marie Therien-Daniel,1410721969,Éloi Brassard-Gourdeau,,,,,7.0,52.0,4.0,139.0,1464.0,22.0,1.0,1.0,1.0,5.0,29.0,2.0,,,,,,,Computer Science
171,"© 2021 Universitat de Valencia, Faculty of Philology, Translation and Communication. All Rights Reserved.Social media platforms such as Twitter play an essential role in politics and social movements nowadays. The aim of this paper is to compare and contrast the language used on Twitter to refer to the candidates of the last UK general election of December 2019 in order to raise awareness of gender inequality in politics. The methodology followed is based on three aspects: (a) a quantitative analysis using Sketch Engine to extract the main collocates from the corpus; (b) a sentiment analysis of the compiled tweets by means of two lexicon classifications: BING (Hu & Liu, 2004) and NRC (Mohammad & Turney, 2013), which classifies words into eight basic emotions and two sentiments (positive and negative); and (c) a qualitative analysis employing a Critical Discourse Analysis approach (Fairclough, 2013) to examine verbal abuse towards women from a linguistics perspective.",2021-01-01,Journal,Article,Quaderns de Filologia: Estudis Linguistics,21101036618,0,26,Gender inequality on Twitter during the UK election of 2019 La desigualtat de gènere en Twitter durant les eleccions britàniques de 2019,1,true,10.7203/QF.0.21982,"Universitat de Valencia, Faculty of Philology, Translation and Communication",171,Quaderns de Filologia: Estudis Lingüístics,2021.0,0.0,0.0,,2147085248,Carla Fernández Melendres,2147082393,Aroa Orrequia Barea,,,,,,,,,1.0,0.0,0.0,2.0,0.0,0.0,,,,,,,,,,,,,
177,"© 2021 by Paige Sweet.For women who have experienced domestic violence, proving that you are a “good victim” is no longer enough. Victims must also show that they are recovering, as if domestic violence were a disease: They must transform from “victims” into “survivors.” Women's access to life-saving resources may even hinge on “good” performances of survivorhood. Through archival and ethnographic research, Paige L. Sweet reveals how trauma discourses and coerced therapy play central roles in women's lives as they navigate state programs for assistance. Sweet uses an intersectional lens to uncover how “resilience” and “survivorhood” can become coercive and exclusionary forces in women's lives. With nuance and compassion, The Politics of Surviving wrestles with questions about the gendered nature of the welfare state, the unintended consequences of feminist mobilizations for anti-violence programs, and the women who are left behind by the limited forms of citizenship we offer them.",2021-01-01,Book,Book,The Politics of Surviving: How Women Navigate Domestic Violence and Its Aftermath,21101077771,6,,The Politics of Surviving: How Women Navigate Domestic Violence and Its Aftermath,1,true,10.1525/luminos.110,University of California Press,177,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
178,"© 2021, Springer Nature Switzerland AG.The emergence of social networks is at a great boom today. Every big news before telecasting on television comes to these forums, therefore raises many dilemmas due to misinterpretation regarding the freedom of speaking. One of this trouble is social intimidation that is very disturbing misbehavior that can cause troubling consequences for the victim. Existing works of social intimidation focuses on only one or two topics of harassment. The main aim of this study is to analyze the hub of social intimidation i.e. twitter, consisting of 25,000 tweets covering five topics of harassment i.e. sexism, racism, appearance related, political and intellectual. Moreover, five machine learning and four deep learning techniques were used namely sequential minimal optimization (SMO), random forest, multinomial naïve bayes, logistic regression (LR), decision tree J48, CNN-CB, CNN-GRU, CNN-LRCN and CNN-Bi-LSTM. Each of the classifiers are evaluated using accuracy, precision, recall and f-measure as a performance metric on the dataset. Results indicate the dominance of CNN-Bi-LSTM and logistic regression among all classifiers used.",2021-01-01,Book Series,Conference Paper,Communications in Computer and Information Science,17700155007,1,1440 CCIS,Performance Analysis of Various Classifiers for Social Intimidating Activities Detection,0,false,10.1007/978-3-030-81462-5_46,Springer Science and Business Media Deutschland GmbH,178,Communications in Computer and Information Science,2021.0,21.0,0.0,,2057093464,Mansi Mahendru,1788776,S. Dubey,,,,,,,,,5.0,13.0,1.0,192.0,1528.0,19.0,,,,,,,,,,,,,
198,"© 2013 IEEE.Violence against women and children is a public health issue of pandemic proportions. It is estimated that one in every three women worldwide has experienced physical, emotional, or sexual violence. Similarly, each year one out of two children are victims of some form of violence including domestic aggression and bullying. Due to the widespread use of the Internet and social media, women and children are now vulnerable to other types of violence such as cyber-bullying and online sexual or emotional harassment. To help alleviate this social problem, the use of computer science and related technologies has been leveraged in recent years. The Internet of Things, artificial intelligence, ubiquitous and mobile computing, pattern recognition, cloud computing and similar technologies, have been used to formulate solutions to detect and prevent violent acts against women and children. In this paper, a systematic review of some of the efforts that can help address the problem of violence against women and children is presented. This paper describes the current state-of-the-art of these contributions and identifies trends, architectures, technologies, and current open challenges. The survey was developed using a literature review of academic documents published from 2010 to 2020. The contributions were categorized into four application domains: online detection, offline detection, safety, and education. These contributions were further categorized based on the computer science approaches and technologies used: artificial intelligence, Internet of Things, and digital serious games.",2021-01-01,Journal,Review,IEEE Access,21100374601,2,9,A Systematic Review of Computer Science Solutions for Addressing Violence against Women and Children,1,true,10.1109/ACCESS.2021.3103459,Institute of Electrical and Electronics Engineers Inc.,198,IEEE Access,2021.0,89.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'A systematic review of some of the efforts that can help address the problem of violence against women and children is presented and identifies trends, architectures, technologies, and current open challenges.'}",2130514463,D. A. Rodríguez,1403247810,A. Díaz-Ramírez,1405041692,J. E. Miranda-Vega,145963958,L. Trujillo,1403234045,Pedro Mejía-Alvarez,,,2.0,2.0,1.0,32.0,189.0,7.0,19.0,56.0,4.0,198.0,2355.0,25.0,45.0,2005.0,16.0,,,,Computer Science
200,"© 2013 IEEE.The rise of social media platforms has significantly changed the way our world communicates, and part of those changes includes a rise in inappropriate behaviors, such as the use of aggressive and hateful language online. Detecting such content is crucial to filtering or blocking inappropriate content on the Web. However, due to the huge amount of data posted every day, automatic methods are essential for identifying this type of content. Seeking to address this issue, the Natural Language Processing community is increasingly involved in testing a wide range of techniques for hate speech detection. While achieving promising results, these techniques consider hate speech detection as the sole optimization objective, without involving other related tasks such as polarity and emotion classification that are strongly linked to offensive behavior. In this paper, we propose the first Multi-task approach that leverages the shared affective knowledge to detect hate speech in Spanish tweets, using a well-known Transformer-based model. Our results show that the combination of both polarity and emotional knowledge helps to detect hate speech more accurately across datasets.",2021-01-01,Journal,Article,IEEE Access,21100374601,8,9,A multi-task learning approach to hate speech detection leveraging sentiment analysis,1,true,10.1109/ACCESS.2021.3103697,Institute of Electrical and Electronics Engineers Inc.,200,IEEE Access,2021.0,64.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This paper proposes the first Multi-task approach that leverages the shared affective knowledge to detect hate speech in Spanish tweets, using a well-known Transformer-based model, and shows that the combination of both polarity and emotional knowledge helps to detecthate speech more accurately across datasets.'}",1410406981,F. Plaza-Del-Arco,1398823104,M. Molina-González,1401976834,L. A. Ureña-López,1397974262,M. Martín-Valdivia,,,,,12.0,89.0,5.0,32.0,432.0,9.0,41.0,222.0,8.0,130.0,2464.0,24.0,,,,,,,Computer Science
201,"© The Author(s) 2021.In the past decade, social networking sites have become central forums for public discourse and political engagement. Of particular interest is the role that Twitter plays in the facilitation of political discourse. To this end, the existing literature argues that a healthy political discussion space is key to maintaining a trusting and robust democratic society. Using Suler’s online disinhibition effect as a theoretical orientation, this study seeks to address the extent of incivility on Twitter in discourse regarding the top three 2020 Democratic primary candidates. A total corpus of 18,237,296 tweets was analyzed in an effort to assess the extent to which incivility dominated Twitter discourse surrounding these candidates. Our results reveal that tweets that mention Senator Elizabeth Warren were associated with higher levels of uncivil discourse than tweets that mentioned Senator Bernie Sanders and former Vice President Joe Biden. Interestingly, there does not appear to be a relationship with anonymity and incivility, as uncivil tweets were just as likely to originate from tweets that identified users’ names as they were to originate from anonymous or pseudonymous accounts. Finally, our findings provide evidence that certain policy issues are more closely related to uncivil discourse than others. Through the use of k-means clustering, our findings illustrate that the issue of gun control and immigration is closely related with mentions of Warren and fiscal policy with Sanders; however, we did not find any policy keywords linked to Biden.",2021-01-01,Journal,Article,Social Media and Society,21100837352,1,7,Politics and Politeness: Analysis of Incivility on Twitter During the 2020 Democratic Presidential Primary,1,true,10.1177/20563051211036939,SAGE Publications Ltd,201,Social Media + Society,2021.0,81.0,0.0,,116344697,B. Trifiro,2132933809,Sejin Paik,2154292855,Zhixin Fang,2152829178,Li Zhang,,,,,16.0,61.0,3.0,9.0,16.0,3.0,2.0,3.0,1.0,3.0,40.0,3.0,,,,,,,Political Science
203,"© 2021 Pelicon et al. All Rights Reserved.Platforms that feature user-generated content (social media, online forums, newspaper comment sections etc.) have to detect and filter offensive speech within large, fast-changing datasets. While many automatic methods have been proposed and achieve good accuracies, most of these focus on the English language, and are hard to apply directly to languages in which few labeled datasets exist. Recent work has therefore investigated the use of cross-lingual transfer learning to solve this problem, training a model in a well-resourced language and transferring to a less-resourced target language; but performance has so far been significantly less impressive. In this paper, we investigate the reasons for this performance drop, via a systematic comparison of pre-trained models and intermediate training regimes on five different languages. We show that using a better pre-trained language model results in a large gain in overall performance and in zero-shot transfer, and that intermediate training on other languages is effective when little target-language data is available. We then use multiple analyses of classifier confidence and language model vocabulary to shed light on exactly where these gains come from and gain insight into the sources of the most typical mistakes.",2021-01-01,Journal,Article,PeerJ Computer Science,21100830173,8,7,Investigating cross-lingual training for offensive language detection,1,true,10.7717/peerj-cs.559,PeerJ Inc.,203,PeerJ Computer Science,2021.0,85.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'It is shown that using a better pre-trained language model results in a large gain in overall performance and in zero-shot transfer, and that intermediate training on other languages is effective when little target-language data is available.'}",146156211,Andraz Pelicon,145543514,Ravi Shekhar,7746943,Blaž Škrlj,1701461,Matthew Purver,1491181728,Senja Pollak,,,19.0,126.0,8.0,21.0,365.0,9.0,86.0,494.0,13.0,210.0,3620.0,32.0,59.0,283.0,10.0,,,,"Computer Science, Medicine"
204,"© 2021. Yin and Zubiaga.Hate speech is one type of harmful online content which directly attacks or promotes hate towards a group or an individual member based on their actual or perceived aspects of identity, such as ethnicity, religion, and sexual orientation. With online hate speech on the rise, its automatic detection as a natural language processing task is gaining increasing interest. However, it is only recently that it has been shown that existing models generalise poorly to unseen data. This survey paper attempts to summarise how generalisable existing hate speech detection models are and the reasons why hate speech models struggle to generalise, sums up existing attempts at addressing the main obstacles, and then proposes directions of future research to improve generalisation in hate speech detection.",2021-01-01,Journal,Article,PeerJ Computer Science,21100830173,26,7,Towards generalisable hate speech detection: a review on obstacles and solutions,1,true,10.7717/PEERJ-CS.598,PeerJ Inc.,204,PeerJ Computer Science,2021.0,140.0,3.0,"{'model': 'tldr@v2.0.0', 'text': 'This survey paper attempts to summarise how generalisable existing hate speech detection models are and the reasons why hate speech models struggle to generalise, sums up existing attempts at addressing the main obstacles, and proposes directions of future research to improve generalisation inhate speech detection.'}",48275690,Wenjie Yin,2805349,A. Zubiaga,,,,,,,,,3.0,59.0,2.0,163.0,4980.0,36.0,,,,,,,,,,,,,"Computer Science, Medicine"
209,"© 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.Different disciplines have studied the content of online user comments in various contexts, using manual qualitative/quantitative or (semi-)automated approaches. The broad spectrum and disciplinary divides make it difficult to grasp an overview of those aspects which have already been examined, e.g. to identify findings related to one’s own research, recommendable methodological approaches, and under-researched topics. We introduce a systematic literature review concerning content analyses of user comments in a journalistic context. Our review covers 192 papers identified through a systematic search focussing on communication studies and computer science. We find that research predominantly concentrates on the comment sections of Anglo-American newspaper brands and on aspects like hate speech, general incivility, or users’ opinions on specific issues, while disregarding media from other parts of the world, comments in social media, propaganda, and constructive comments. From our results we derive a research agenda that addresses research gaps and also highlights potentials for automating analyses as well as for cooperation across disciplines.",2021-01-01,Journal,Article,Digital Journalism,21100430187,2,,Content Analyses of User Comments in Journalism: A Systematic Literature Review Spanning Communication Studies and Computer Science,1,true,10.1080/21670811.2021.1882868,Routledge,209,,2021.0,321.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'Different disciplines have studied the content of online user comments in various contexts, using manual qualitative/quantitative or (semi-)automated approaches.'}",2057733996,Julius Reimer,32218195,Marlo Häring,2067166114,W. Loosen,1706506,W. Maalej,46736494,Lisa Merten,,,8.0,183.0,6.0,8.0,85.0,4.0,33.0,499.0,11.0,143.0,4307.0,34.0,10.0,146.0,5.0,,,,Computer Science
210,"© 2021, Jenny Sundén and Susanna Paasonen.Purpose: According to thesaurus definitions, the absurd translates as “ridiculously unreasonable, unsound, or incongruous”; “extremely silly; not logical and sensible”. As further indicated in the Latin root absurdus, “out of tune, uncouth, inappropriate, ridiculous,” humor in absurd registers plays with that which is out of harmony with both reason and decency. In this article, the authors make an argument for the absurd as a feminist method for tackling heterosexism. Design/methodology/approach: By focusing on the Twitter account “Men Write Women” (est. 2019), the rationale of which is to share literary excerpts from male authors describing women's experiences, thoughts and appearances, and which regularly broadens into social theater in the user reactions, the study explores the critical value of absurdity in feminist social media tactics. Findings: The study proposes the absurd as a means of not merely turning things around, or inside out, but disrupting and eschewing the hegemonic logic on offer. While both absurd humor and feminist activism may begin from a site of reactivity and negative evaluation, it need not remain confined to it. Rather, by turning things preposterous, ludicrous and inappropriate, absurd laughter ends up somewhere different. The feminist value of absurd humor has to do with both its critical edge and with the affective lifts and spaces of ambiguity that it allows for. Originality/value: Research on digital feminist activism has largely focused on the affective dynamics of anger. As there are multiple affective responses to sexism, our article foregrounds laughter and ambivalence as a means of claiming space differently in online cultures rife with hate, sexism and misogyny.",2021-01-01,Journal,Article,Qualitative Research Journal,19400156804,0,21,“We have tiny purses in our vaginas!!! #thanksforthat”: absurdity as a feminist method of intervention,1,true,10.1108/QRJ-09-2020-0108,Emerald Group Holdings Ltd.,210,,2021.0,63.0,0.0,,2366554,Jenny Sundén,3348285,Susanna Paasonen,,,,,,,,,55.0,705.0,12.0,136.0,1546.0,22.0,,,,,,,,,,,,,Sociology
211,"© 2021, Springer Nature Singapore Pte Ltd.Discrimination and manipulation are becoming predominant in social network activities. Comments bearing attitudes, such as distress, hate, and aggression in Social Networking Sites (SNS) add fuel to the process of discrimination. This research aims to classify texts, which are misogynous in nature using Support Vector Machine (SVM) and Long-Short Term Memory (LSTM) for user-generated texts of English and Hindi languages written using the Roman script. Approximately 87% accuracy was achieved while SVM was trained with Term Frequency-Inverse Document Frequency (TF-IDF) feature and for Hindi comments approximately 93.43% accuracy was achieved for English using Bidirectional LSTM (Bi-LSTM).",2021-01-01,Book Series,Conference Paper,Communications in Computer and Information Science,17700155007,0,1367,Misogynous Text Classification Using SVM and LSTM,0,false,10.1007/978-981-16-0401-0_26,Springer Science and Business Media Deutschland GmbH,211,,2021.0,35.0,0.0,,2004698056,Maibam Debina Devi,3314265,Navanath Saharia,,,,,,,,,4.0,5.0,1.0,30.0,195.0,8.0,,,,,,,,,,,,,Computer Science
212,"© 2021 The Australian National University.This study suggests blogging as a practice has unintended cultural and political implications. It can be drawn from the data, derived from multiple qualitative fieldwork methods (2008–2012), that Indonesian women bloggers circumvent cultural constraints. Appropriating the private Bahasa Gaul, women bloggers establish connections and make alliances in public. Further, the utilisation of modes of ‘street language’ in the digital age comprises a distinctive register of sociability, liberated from certain norms and hierarchies.",2021-01-01,Journal,Article,Asia Pacific Journal of Anthropology,18300156709,0,22,Indonesian Women Bloggers: The Role of Bahasa Gaul in Negotiating Public/Private Connections,0,false,10.1080/14442213.2021.1882548,Routledge,212,,2021.0,149.0,0.0,,103602384,Endah Triastuti,,,,,,,,,,,16.0,43.0,3.0,,,,,,,,,,,,,,,,
213,"© 2020 by the authors. Licensee MDPI, Basel, Switzerland.The abundant dissemination of misinformation regarding coronavirus disease 2019 (COVID-19) presents another unprecedented issue to the world, along with the health crisis. Online social network (OSN) platforms intensify this problem by allowing their users to easily distort and fabri-cate the information and disseminate it farther and rapidly. In this paper, we study the impact of misinformation associated with a religious inflection on the psychology and behavior of the OSN users. The article presents a detailed study to understand the reaction of social media users when exposed to unverified content related to the Islamic community during the COVID-19 lockdown period in India. The analysis was carried out on Twitter users where the data were collected using three scraping packages, Tweepy, Selenium, and Beautiful Soup, to cover more users affected by this misinformation. A labeled dataset is prepared where each tweet is assigned one of the four reaction polarities, namely, E (endorse), D (deny), Q (question), and N (neutral). Analysis of collected data was carried out in five phases where we investigate the engagement of E, D, Q, and N users, tone of the tweets, and the consequence upon repeated exposure of such information. The evidence demonstrates that the circulation of such content during the pandemic and lockdown phase had made people more vulnerable in perceiving the unreliable tweets as fact. It was also observed that people absorbed the negativity of the online content, which induced a feeling of hatred, anger, distress, and fear among them. People with similar mindset form online groups and express their negative attitude to other groups based on their opinions, indicating the strong signals of social unrest and public tensions in society. The paper also presents a deep learning-based stance detection model as one of the automated mechanisms for tracking the news on Twitter as being potentially false. Stance classifier aims to predict the attitude of a tweet towards a news headline and thereby assists in determining the veracity of news by monitoring the distribution of different reactions of the users towards it. The proposed model, employing deep learning (convolutional neural network (CNN)) and sentence embedding (bidirectional encoder representations from transformers (BERT)) techniques, outperforms the existing systems. The performance is evaluated on the benchmark SemEval stance dataset. Furthermore, a newly annotated dataset is prepared and released with this study to help the research of this domain.",2021-01-01,Journal,Article,Electronics (Switzerland),21100829272,15,10,Impact of unreliable content on social media users during COVID-19 and stance detection system,1,true,10.3390/electronics10010005,MDPI AG,213,Electronics,2020.0,50.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'The article presents a detailed study to understand the reaction of social media users when exposed to unverified content related to the Islamic community during the COVID-19 lockdown period in India and presents a deep learning-based stance detection model as one of the automated mechanisms for tracking the news on Twitter as being potentially false.'}",15971377,M. A. Wani,35834782,Nancy Agarwal,1688843,Patrick A. H. Bours,,,,,,,28.0,182.0,8.0,14.0,98.0,6.0,121.0,2778.0,28.0,,,,,,,,,,Computer Science
214,"© 2020 Informa UK Limited, trading as Taylor & Francis Group.On 27 September 2018, history was made when Hannah Storm and Andrea Kremer became the first all-female broadcast team to call a major professional men’s team sport–a National Football League game between the Los Angeles Rams and the Minnesota Vikings. Storm provided the play-by-play and Kremer was the analyst for a ‘Thursday Night Football’ livestream on Amazon Prime, which was simulcast alongside a Fox television broadcast with veteran announcers Joe Buck and Troy Aikman. For viewers, the game represented seismic changes to a media landscape that had historically promoted aggression and a disruption to a sports ecosystem that routinely reinforces male-dominated gender norms. To better understand whether differences were advanced in the dialogues of the two broadcast teams, content analyses of the Amazon broadcast and the Fox broadcast were conducted. Attributes of athletic successes, failures, and physicality/personality were coded as verbal descriptors to allow comparison. A total of 777 descriptors showed significant differences in the frequency of the three classification areas, yet only one verbal descriptor difference was detected; the male team disproportionately elevated successes due to athletic ability. Results and the implications of these findings are discussed.",2021-01-01,Journal,Article,Journal of Gender Studies,23704,1,30,Gendering ‘Thursday Night Football’: Examining dialogue differences between all-female and all-male broadcast teams,0,false,10.1080/09589236.2020.1834368,Routledge,214,,2020.0,79.0,0.0,,118020305,Sean R. Sadri,108598019,Travis R. Bell,50585522,A. Billings,,,,,,,14.0,37.0,3.0,29.0,63.0,5.0,239.0,4648.0,36.0,,,,,,,,,,Sociology
215,"© 2020 Elsevier B.V.Online social networks allow powerless people to gain enormous amounts of control over particular people's lives and profit from the anonymity or social distance that the Internet provides in order to harass other people. One of the most frequently targeted groups comprise women, as misogyny is, unfortunately, a reality in our society. However, although great efforts have recently been made to identify misogyny, it is still difficult to distinguish as it can sometimes be very subtle and deep, signifying that the use of statistical approaches is not sufficient. Moreover, as Spanish is spoken worldwide, context and cultural differences can complicate this identification. Our contribution to the detection of misogyny in Spanish is two-fold. On the one hand, we apply Sentiment Analysis and Social Computing technologies for detecting misogynous messages in Twitter. On the other, we have compiled the Spanish MisoCorpus-2020, a balanced corpus regarding misogyny in Spanish, and classified it into three subsets concerning (1) violence towards relevant women, (2) messages harassing women in Spanish from Spain and Spanish from Latin America, and (3) general traits related to misogyny. Our proposal combines a classification based on average word embeddings and linguistic features in order to understand which linguistic phenomena principally contribute to the identification of misogyny. We have evaluated our proposal with three machine-learning classifiers, achieving the best accuracy of 85.175%. Finally the proposed approach is also validated with existing corpora for misogyny and aggressiveness detection such as AMI and HatEval obtaining good results",2021-01-01,Journal,Article,Future Generation Computer Systems,12264,47,114,Detecting misogyny in Spanish tweets. An approach based on linguistics features and word embeddings,0,false,10.1016/j.future.2020.08.032,Elsevier B.V.,215,Future generations computer systems,2021.0,64.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'This work combines a classification based on average word embeddings and linguistic features in order to understand which linguistic phenomena principally contribute to the identification of misogyny.'}",1409250207,J. García-Díaz,1752477854,Mar Cánovas-García,40622419,Ricardo Colomo Palacios,1398759108,R. Valencia-García,,,,,53.0,294.0,9.0,3.0,102.0,2.0,255.0,4982.0,38.0,208.0,3480.0,32.0,,,,,,,Computer Science
216,"© 2021 by IGI Global. All rights reserved.Though the percentage of Hispanics in universities continues to grow, few Hispanic women/Latinas advance into leadership positions; instead, many are constrained by a glass ceiling. Therefore, the voices and experiences of those that have overcome these barriers in higher education are pivotal stories to be told. Ranging from the perceptions of these women's journeys to leadership, to an understanding of the barriers they encounter, to the question of their access to the resources they need, each factor is a critical component to understanding Hispanic women/Latinas in the higher education atmosphere. Comprehensive research in this area is needed to explore the themes of identity in terms of racial/ethic identification, social perception, and gender, along with systemic themes on the institutional level regarding the recruitment, retention, and promotion of a diverse higher education administration. Hispanic Women/Latina Leaders Overcoming Barriers in Higher Education explores the recruitment, promotion, retention process, and the barriers and resilience needed for Hispanic women/Latinas in higher education leadership roles. The chapters use data collected via a qualitative, phenomenological research study including open-ended interviews, field notes, biographical questionnaires, and a researcher's reflective journal. While covering topics surrounding these women's experiences such as identity themes, self-identification, institutional shortcomings, and valuable support systems, this book is ideally intended for Latina educators, informing legislators, educational officials, and higher education administrators along with practitioners, researchers, academicians, and students interested in institutional equality, female empowerment, and Hispanic women/Latinas' journey in higher education.",2020-12-18,Book,Book,Hispanic Women/Latina Leaders Overcoming Barriers in Higher Education,21101103621,0,,Hispanic women/Latina leaders overcoming barriers in higher education,0,false,10.4018/978-1-7998-3763-3,IGI Global,216,,2021.0,0.0,0.0,,2124956382,Daisy Indira Barrón,,,,,,,,,,,1.0,0.0,0.0,,,,,,,,,,,,,,,,Political Science
217,"© 2020 IEEE.Research has shown that Violence Against Women is a pervasive problem which has been increasing. Until a few years ago, it took place both in public and private spaces, but it has now broken into Digital Space, adopting more symbolic expressions. There has been some important related work from Data Science approaches. Mainly about cyberbullying, detection of language patterns through supervised algorithms, a few works on unsupervised learning, and some on violence against women. This article is part of a larger investigation related to the Violence Against Women in Digital Space phenomena in Mexico from Spanish-language interactions in microblogging social network, Twitter. We present the framework to address these phenomena from a Data Science perspective and go through some first stage results. The goal is to give Data Science perspectives and insights related to the understanding of Digital Violence Against Women, with the purpose of generating awareness about this problem by, modifying manners and implementing public policies that could counteract this social problem.",2020-12-01,Conference Proceeding,Conference Paper,"Proceedings - 2020 International Conference on Computational Science and Computational Intelligence, CSCI 2020",21101056901,1,,Understanding Violence against Women in Digital Space from a Data Science Perspective : Full/Regular Research Papers - CSCI-ISNA,0,false,10.1109/CSCI51800.2020.00051,Institute of Electrical and Electronics Engineers Inc.,217,2020 International Conference on Computational Science and Computational Intelligence (CSCI),2020.0,19.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The goal is to give Data Science perspectives and insights related to the understanding of Digital Violence Against Women, with the purpose of generating awareness about this problem by, modifying manners and implementing public policies that could counteract this social problem.'}",2114853264,Gregorio Arturo Reyes González,108259554,Mariana Gabarrot,1403721259,F. J. Cantu-Ortiz,,,,,,,2.0,1.0,1.0,5.0,1.0,1.0,32.0,161.0,7.0,,,,,,,,,,
218,"© 2020 Elsevier LtdThe freedom of expression given by social media has a dark side: the growing proliferation of abusive contents on these platforms. Misogynistic speech is a kind of abusive language, which can be simplified as hate speech targeting women, and it is becoming a more and more relevant issue in recent years. AMI IberEval 2018 and AMI EVALITA 2018 were two shared tasks which mainly focused on tackling the problem of misogyny in Twitter, in three different languages, namely English, Italian, and Spanish. In this paper, we present an in-depth study on the phenomena of misogyny in those three languages, by focusing on three main objectives. Firstly, we investigate the most important features to detect misogyny and the issues which contribute to the difficulty of misogyny detection, by proposing a novel system and conducting a broad evaluation on this task. Secondly, we study the relationship between misogyny and other abusive language phenomena, by conducting a series of cross-domain classification experiments. Finally, we explore the feasibility of detecting misogyny in a multilingual environment, by carrying out cross-lingual classification experiments. Our system succeeded to outperform all state of the art systems in all benchmark AMI datasets both subtask A and subtask B. Moreover, intriguing insights emerged from error analysis, in particular about the interaction between different but related abusive phenomena. Based on our cross-domain experiment, we conclude that misogyny is quite a specific kind of abusive language, while we experimentally found that it is different from sexism. Lastly, our cross-lingual experiments show promising results. Our proposed joint-learning architecture obtained a robust performance across languages, worth to be explored in further investigation.",2020-11-01,Journal,Article,Information Processing and Management,12689,60,57,Misogyny Detection in Twitter: a Multilingual and Cross-Domain Study,0,false,10.1016/j.ipm.2020.102360,Elsevier Ltd,218,Information Processing & Management,2020.0,89.0,8.0,"{'model': 'tldr@v2.0.0', 'text': 'It is concluded that misogyny is quite a specific kind of abusive language, while the experimentally found that it is different from sexism, which is worth to be explored in further investigation.'}",9278845,Endang Wahyu Pamungkas,3101511,Valerio Basile,1787198,V. Patti,,,,,,,19.0,334.0,11.0,123.0,2883.0,25.0,220.0,4576.0,36.0,,,,,,,,,,Computer Science
219,"© 2020 ACM.The comment sections of online news platforms are an important space to indulge in political conversations and to discuss opinions. Although primarily meant as forums where readers discuss amongst each other, they can also spark a dialog with the journalists who authored the article. A small but important fraction of comments address the journalists directly, e.g., with questions, recommendations for future topics, thanks and appreciation, or article corrections. However, the sheer number of comments makes it infeasible for journalists to follow discussions around their articles in extenso. A better understanding of this data could support journalists in gaining insights into their audience and fostering engaging and respectful discussions. To this end, we present a dataset of dialogs in which journalists of The Guardian replied to reader comments and identify the reasons why. Based on this data, we formulate the novel task of recommending reader comments to journalists that are worth reading or replying to, i.e., ranking comments in such a way that the top comments are most likely to require the journalists' reaction. As a baseline, we trained a neural network model with the help of a pair-wise comment ranking task. Our experiment reveals the challenges of this task and we outline promising paths for future work. The data and our code are available for research purposes from: https://hpi.de/naumann/projects/repeatability/text-mining.html.",2020-10-19,Conference Proceeding,Conference Paper,"International Conference on Information and Knowledge Management, Proceedings",21101027248,2,,A Dataset of Journalists' Interactions with Their Readership: When Should Article Authors Reply to Reader Comments?,0,false,10.1145/3340531.3412764,Association for Computing Machinery,219,International Conference on Information and Knowledge Management,2020.0,58.0,0.0,"{'model': 'tldr@v2.0.0', 'text': ""A dataset of dialogs in which journalists of The Guardian replied to reader comments is presented and the novel task of recommending reader comments to journalists that are worth reading or replying to is formulated, i.e., ranking comments in such a way that the top comments are most likely to require the journalists' reaction.""}",1695993,Julian Risch,3264110,Ralf Krestel,,,,,,,,,40.0,584.0,12.0,132.0,1977.0,22.0,,,,,,,,,,,,,Computer Science
220,"© 2019 Informa UK Limited, trading as Taylor & Francis Group.The gang rape known as the “La Manada” case has had an unprecedented social impact in Spain. This research investigates how this case has been dealt with through Twitter by a collective symbolic coping process (Social Representation Theory). Discourse on Twitter was analyzed at two key points in time: the announcement of the judgment and the aggressors’ release from prison. In total 6,592 tweets with the hashtag #lamanada were selected and their content was analyzed by lexical analysis using Iramuteq software. The results reveal both an awareness phase about the issue along with a divergence phase that saw the emergence of various interpretations about this case, which were confronted. In this divergence phase, feminist discourses took on great significance, expressing anger, calling for social mobilizations, criticizing the victim blaming and creating a dialogue against rape culture. However, the anti-feminist and sexist discourses were also present in this space. It is concluded that discourses on Twitter are a symptom of a shift in mentality whilst at the same time serve as an active constructor of this changed knowledge. Thus, the feminist movement should continue to take this into account in order to converge and normalize the discourse against rape culture.",2020-10-02,Journal,Article,Feminist Media Studies,5700168400,8,20,“La Manada” in the digital sphere: coping with a sexual aggression case through Twitter,0,false,10.1080/14680777.2019.1643387,Routledgeinfo@tandf.co.uk,220,Feminist Media Studies,2019.0,64.0,0.0,,115237513,Nahia Idoiaga Mondragón,2130553002,Lorena Gil de Montes Echaide,2130570936,Nagore Asla Alcibar,2130522948,Maider Larrañaga Eguileor,,,,,28.0,576.0,10.0,1.0,10.0,1.0,2.0,10.0,1.0,1.0,10.0,1.0,,,,,,,Psychology
221,"© 2020 Sociedad Espanola para el Procesamiento del Lenguaje Natural. All rights reserved.The general objectives of the project are to address and monitor misinformation (biased and fake news) and miscommunication (aggressive language and hate speech) in social media, as well as to establish a high quality methodological standard for the whole research community (i) by developing rich annotated datasets, a data repository and online evaluation services; (ii) by proposing suitable evaluation metrics; and (iii) by organizing evaluation campaigns to foster research on the above issues.",2020-09-01,Journal,Article,Procesamiento del Lenguaje Natural,21100195304,0,65,MISMIS: Misinformation and Miscommunication in social media: Aggregating information and analysing language MISMIS: Desinformación y agresividad en los medios de comunicación social: agregando información y analizando el lenguaje,,,10.26342/2020-65-13,Sociedad Espanola para el Procesamiento del Lenguaje Natural,221,Proces. del Leng. Natural,2020.0,16.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The general objectives of the project are to address and monitor misinformation and miscommunication in social media, and establish a high quality methodological standard for the whole research community by developing rich annotated datasets, a data repository and online evaluation services.'}",143752702,Paolo Rosso,1696761,F. Casacuberta,1681160,Julio Gonzalo,145377713,Laura Plaza,35008065,J. Albornoz,1688716,Enrique Amigó,646.0,16149.0,63.0,350.0,5222.0,37.0,189.0,5239.0,33.0,58.0,1060.0,20.0,29.0,723.0,13.0,91.0,2299.0,20.0,"Computer Science, Psychology"
222,,2020-09-01,Journal,Article,Signs,24273,1,46,Feminist counterpublics and public feminisms: Advancing a critique of racialized sexualization in london’s public advertising,2,,10.1086/709362,University of Chicago Presssubscriptions@press.uchicago.edu,222,Signs: Journal of Women in Culture and Society,2020.0,48.0,0.0,,73456815,J. Ringrose,8255573,Kaitlyn Regehr,,,,,,,,,126.0,5820.0,40.0,25.0,74.0,5.0,,,,,,,,,,,,,Sociology
223,"© 2020 by the authors.The use of inclusive language, among many other gender equality initiatives in society, has garnered great attention in recent years. Gender equality offices in universities and public administration cannot cope with the task of manually checking the use of non-inclusive language in the documentation that those institutions generate. In this research, an automated solution for the detection of non-inclusive uses of the Spanish language in doctoral theses generated in Spanish universities is introduced using machine learning techniques. A large dataset has been used to train, validate, and analyze the use of inclusive language; the result is an algorithm that detects, within any Spanish text document, non-inclusive uses of the language with error, false positive, and false negative ratios slightly over 10%, and precision, recall, and F-measure percentages over 86%. Results also show the evolution with time of the ratio of non-inclusive usages per document, having a pronounced reduction in the last years under study.",2020-08-01,Journal,Article,Publications,21100836334,0,8,Decision algorithm for the automatic determination of the use of non-inclusive terms in academic texts,1,true,10.3390/PUBLICATIONS8030041,MDPI AGPostfachBaselCH-4005rasetti@mdpi.com,223,Publ.,2020.0,102.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'An automated solution for the detection of non-inclusive uses of the Spanish language in doctoral theses generated in Spanish universities is introduced using machine learning techniques.'}",1995519339,Pedro Orgeira-Crespo,1403905031,C. Míguez-Álvarez,1402004955,Miguel Cuevas-Alonso,1995485679,María Isabel Doval-Ruiz,,,,,7.0,20.0,2.0,29.0,116.0,5.0,12.0,32.0,4.0,3.0,2.0,1.0,,,,,,,Computer Science
224,"© The Author(s) 2020.It is generally accepted within psychology and among trans health providers that transgender people who transition do so because they have a gender identity that is incongruent with their birth-assigned sex, and distinct from their sexual orientation. In contradiction to this standard model, the theory of autogynephilia posits that transgender women’s female gender identities and transitions are merely a by-product of their sexual orientations. While subsequent research has yielded numerous lines of evidence that, taken together, disprove the theory, autogynephilia is still often touted by anti-transgender groups, including trans-exclusionary feminists. Here, I provide an updated overview of the scientific case against autogynephilia. Following that, I will forward an alternative ‘embodiment fantasies’ model that explains all the available findings better than autogynephilia theory, and which is more consistent with contemporary thinking regarding gender and sexual diversity. I will also demonstrate how autogynephilia theory relies on essentialist, heteronormative, and male-centric presumptions about women and LGBTQ+ people, and as such, it is inconsistent with basic tenets of feminism.",2020-07-01,Journal,Article,Sociological Review,18106,8,68,"Autogynephilia: A scientific review, feminist analysis, and alternative ‘embodiment fantasies’ model",0,false,10.1177/0038026120934690,SAGE Publications Ltdinfo@sagepub.co.uk,224,Sociology Review,2020.0,59.0,1.0,,5489876,J. Serano,,,,,,,,,,,15.0,1657.0,10.0,,,,,,,,,,,,,,,,Sociology
225,"© 2020 ACM.Today, misogyny and xenophobia are some of the most important social problems. With the increase in the use of social media, this feeling of hatred toward women and immigrants can be more easily expressed, and therefore it can have harmful effects on social media users. For this reason, it is important to develop systems capable of detecting hateful comments automatically. In this article, we analyze the hate speech in Spanish tweets against women and immigrants conducting classification experiments using different approaches. Moreover, we create appropriate language resources for hate speech detection in Spanish.",2020-05-01,Journal,Article,ACM Transactions on Internet Technology,15773,40,20,Detecting Misogyny and Xenophobia in Spanish Tweets Using Language Technologies,0,false,10.1145/3369869,Association for Computing Machineryacmhelp@acm.org,225,,2020.0,37.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'Today, misogyny and xenophobia are some of the most important social problems, and with the increase in the use of social media, this feeling of hatred toward women and immigrants can be more easily expressed.'}",2007556027,Plaza-Del-ArcoFlor-Miriam,2007107100,Molina-GonzálezM. Dolores,2007562253,Ureña-LópezL. Alfonso,2007174108,Martín-ValdiviaM. Teresa,,,,,1.0,14.0,1.0,1.0,14.0,1.0,1.0,14.0,1.0,1.0,14.0,1.0,,,,,,,Computer Science
226,"© 2020 ACM.Harassment is a persistent problem in contemporary online environments, with women disproportionately experiencing its most severe forms. While critical scholars posit that online gender harassment may be linked to men's anxieties about fulfilling normative masculine gender roles, this relationship has not been examined by empirical research. We survey 264 young men between the ages of 18-24 about their masculinity anxieties and their perceptions of harassment directed at a woman on Twitter. We find that men who perceive themselves as less masculine than average men report higher endorsement of harassment. Further, we find that the relationship between masculinity anxieties and harassment endorsement is mediated by men's adherence to masculine norms and toxic disinhibition. We interpret these results through the lens of social media's specific affordances, and we discuss their implications for technology designers and other practitioners who wish to better detect, prevent, and remediate online harassment by accounting for the role of gender.",2020-04-21,Conference Proceeding,Conference Paper,Conference on Human Factors in Computing Systems - Proceedings,21101021808,15,,"Fragile Masculinity: Men, Gender, and Online Harassment",0,false,10.1145/3313831.3376645,"Association for Computing Machinery2 Penn Plaza, Suite 701New YorkNY 10121-0701acmhelp@acm.org",226,International Conference on Human Factors in Computing Systems,2020.0,96.0,0.0,"{'model': 'tldr@v2.0.0', 'text': ""It is found that men who perceive themselves as less masculine than average men report higher endorsement of harassment, and the relationship between masculinity anxieties and harassment endorsement is mediated by men's adherence to masculine norms and toxic disinhibition.""}",37415113,Jennifer D. Rubin,35019836,Lindsay Blackwell,5572816,T. Conley,,,,,,,32.0,696.0,15.0,16.0,660.0,12.0,91.0,2515.0,25.0,,,,,,,,,,"Psychology, Computer Science"
227,"© 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.The body of literature on underrepresentation and gender inequality is vast. However, despite its potential to perpetuate gender stereotypes, the overrepresentation of women in media has received inadequate attention. This study explores how traditional news media and social media overrepresent females as drivers when discussing traffic accidents, and whether social media could be the ‘new equalizer’ for gender. Focusing on China, we collected 97,120 posts from Weibo, China’s largest microblogging site, and 11,290 newspaper articles dated between January 2010 and November 2018. We analyzed the data through a mixed-methods design and found that female drivers are overrepresented in discussions of traffic accidents, in both newspapers and on Weibo. While the gender bias against female drivers is more prevalent on Weibo than in newspapers, Weibo has provided a platform for gender-aware discussion. Our study closes by offering suggestions for cross-platform and cross-cultural comparisons of gender representation in the digital age.",2020-04-15,Journal,Article,Information Communication and Society,200147110,9,23,The ‘bad women drivers’ myth: the overrepresentation of female drivers and gender bias in China’s media,0,false,10.1080/1369118X.2020.1713843,Routledgeinfo@tandf.co.uk,227,,2020.0,102.0,0.0,,2112144346,Muyang Li,103461220,Zhifan Luo,,,,,,,,,10.0,25.0,3.0,10.0,19.0,3.0,,,,,,,,,,,,,Psychology
228,"© 2020 transcript Verlag, Bielefeld. All rights reserved.The American Gothic novel has been deeply shaped by issues of race and raciality from its origins in British Romanticism to the American Gothic novel in the twenty-first century. Savage Horrors delineates an intrinsic raciality that is discursively sedimented in the Gothic's uniquely binary structure. Corinna Lenhardt uncovers the destructive and lasting impact of the Gothic's anti-Black racism on the cultural discourses in the United States. At the same time, Savage Horrors traces the unflinching Black resistance back to the Gothic's intrinsic raciality. The African American Gothic, however, does not originate there but in the Black Atlantic - roughly a decade before the first Gothic novel was ever written on American soil.",2020-04-02,Book,Book,Savage Horrors: The Intrinsic Raciality of the American Gothic,21101078192,1,,Savage horrors: The intrinsic raciality of the American Gothic,0,false,10.14361/9783839451540,Transcript-Verlag,228,,2020.0,0.0,0.0,,119305632,Corinna Lenhardt,,,,,,,,,,,12.0,78.0,3.0,,,,,,,,,,,,,,,,Art
229,"© 2020 Elsevier LtdThe Breast Size Satisfaction Survey (BSSS) was established to assess women's breast size dissatisfaction and breasted experiences from a cross-national perspective. A total of 18,541 women were recruited from 61 research sites across 40 nations and completed measures of current-ideal breast size discrepancy, as well as measures of theorised antecedents (personality, Western and local media exposure, and proxies of socioeconomic status) and outcomes (weight and appearance dissatisfaction, breast awareness, and psychological well-being). In the total dataset, 47.5 % of women wanted larger breasts than they currently had, 23.2 % wanted smaller breasts, and 29.3 % were satisfied with their current breast size. There were significant cross-national differences in mean ideal breast size and absolute breast size dissatisfaction, but effect sizes were small (η2 = .02–.03). The results of multilevel modelling showed that greater Neuroticism, lower Conscientiousness, lower Western media exposure, greater local media exposure, lower financial security, and younger age were associated with greater breast size dissatisfaction across nations. In addition, greater absolute breast size dissatisfaction was associated with greater weight and appearance dissatisfaction, poorer breast awareness, and poorer psychological well-being across nations. These results indicate that breast size dissatisfaction is a global public health concern linked to women's psychological and physical well-being.",2020-03-01,Journal,Article,Body Image,12159,22,32,The Breast Size Satisfaction Survey (BSSS): Breast size dissatisfaction and its antecedents and outcomes in women from 40 nations,2,,10.1016/j.bodyim.2020.01.006,Elsevier Ltd,229,Body image,2020.0,224.0,1.0,"{'model': 'tldr@v2.0.0', 'text': ""The results of multilevel modelling showed that breast size dissatisfaction is a global public health concern linked to women's psychological and physical well-being.""}",3298993,V. Swami,3526634,U. Tran,144975971,David Barron,52229960,R. Afhami,3315470,A. Aimé,3453082,Carlos A. Almenara,448.0,14657.0,65.0,171.0,3907.0,34.0,68.0,1333.0,20.0,50.0,177.0,8.0,56.0,962.0,16.0,51.0,454.0,11.0,"Medicine, Psychology"
230,"© 2020Empirical evidences linking users’ psychological features such as personality traits and cybercrimes such as cyberbullying are many. This study deals with automatic cyberbullying detection mechanism tapping into Twitter users’ psychological features including personalities, sentiment and emotion. User personalities were determined using Big Five and Dark Triad models, whereas machine learning classifiers namely, Naïve Bayes, Random Forest and J48 were used to classify the tweets into one of four categories: bully, aggressor, spammer and normal. The Twitter dataset contained 5453 tweets gathered using the hashtag #Gamergate, and manually annotated by human experts. Selected Twitter-based features namely text, user and network-based features were used as the baseline algorithm. Results show that cyberbullying detection improved when personalities and sentiments were used, however, a similar effect was not observed for emotion. A further analysis on the personalities revealed extraversion, agreeableness, neuroticism and psychopathy to have greater impacts in detecting online bullying compared to other traits. Key features were identified using the dimension reduction technique, and integrated into a single model, which produced the best detection accuracy. The paper describes suggestions and recommendations as to how the findings can be applied to mitigate cyberbullying.",2020-03-01,Journal,Article,Computers and Security,28898,84,90,Improving cyberbullying detection using Twitter users’ psychological features and machine learning,0,false,10.1016/j.cose.2019.101710,Elsevier Ltd,230,Computers & security,2020.0,76.0,4.0,"{'model': 'tldr@v2.0.0', 'text': 'Suggestions and recommendations are described as to how the findings can be applied to mitigate cyberbullying.'}",50549561,V. Balakrishnan,2111267139,Shahzaib Khan,144211100,H. Arabnia,,,,,,,92.0,1665.0,22.0,6.0,154.0,2.0,464.0,4545.0,33.0,,,,,,,,,,"Computer Science, Psychology"
231,"© 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.There has been growing public attention around the abuse of MPs online including criminal convictions for violent threats, regular coverage of racist and misogynistic language directed at representatives. Yet, the extent of the problem and patterns of abuse remain relatively under-researched. So far, much of coverage of the problem is anecdotal or based on self-reporting from MPs. This research sets out to provide a more rigorous benchmark measure of abuse. It also examines targets and triggers for social media abuse–how far is abuse connected to contentious debates such as Brexit or targeted at specific groups of MPs (e.g. female representatives)? Our results indicate that whilst the overall volume of abuse appears low, social media abuse has become ubiquitous and is highly public. Furthermore, whilst some abuse is undoubtedly targeted and gendered, the biggest proportion of abuse follows a reactive response to political discussions and public interventions of MPs.",2020-01-02,Journal,Article,Journal of Legislative Studies,5600156029,18,26,"Turds, traitors and tossers: the abuse of UK MPs via Twitter",2,,10.1080/13572334.2020.1730502,Routledgeinfo@tandf.co.uk,231,Journal of Legislative Studies,2020.0,134.0,3.0,,145799536,S. Ward,51059811,L. McLoughlin,,,,,,,,,9.0,76.0,4.0,8.0,74.0,4.0,,,,,,,,,,,,,Political Science
232,"© 2013 IEEE.During the last decade, hateful and sexist content towards women is being increasingly spread on social networks. The exposure to sexist speech has serious consequences to women's life and limits their freedom of speech. Previous studies have focused on identifying hatred or violence towards women. However, sexism is expressed in very different forms: it includes subtle stereotypes and attitudes that, although frequently unnoticed, are extremely harmful for both women and society. In this work, we propose a new task that aims to understand and analyze how sexism, from explicit hate or violence to subtle expressions, is expressed in online conversations. To this end, we have developed and released the first dataset of sexist expressions and attitudes in Twitter in Spanish (MeTwo) and investigate the feasibility of using machine learning techniques (both traditional and novel deep learning models) for automatically detecting different types of sexist behaviours. Our results show that sexism is frequently found in many forms in social networks, that it includes a wide range of behaviours, and that it is possible to detect them using deep learning approaches. We discuss the performance of automatic classification methods to deal with different types of sexism and the generalizability of our task to other subdomains, such as misogyny.",2020-01-01,Journal,Article,IEEE Access,21100374601,42,8,Automatic Classification of Sexism in Social Networks: An Empirical Study on Twitter Data,1,true,10.1109/ACCESS.2020.3042604,Institute of Electrical and Electronics Engineers Inc.,232,IEEE Access,2020.0,76.0,12.0,"{'model': 'tldr@v2.0.0', 'text': 'The results show that sexism is frequently found in many forms in social networks, that it includes a wide range of behaviours, and that it is possible to detect them using deep learning approaches.'}",1403518310,F. Rodríguez‐Sánchez,1410230608,Jorge Carrillo-de-Albornoz,145377713,Laura Plaza,,,,,,,44.0,2701.0,19.0,15.0,218.0,7.0,58.0,1060.0,20.0,,,,,,,,,,Computer Science
233,"© 2020 Clare S. Allely.Featuring a unique overview of the different forms of extreme violence, this book considers the psychology of extreme violence alongside a variety of contributing factors, such as brain abnormalities in homicide offenders. Featuring several contemporary real-world case studies, this book offers insight into the psychology of serial homicide offenders, mass shooters, school shooters and lone-actor terrorists. The main purpose of this book is not to glorify or condemn the actions of these individuals, but to attempt to explain the motivations and circumstances that inspire such acts of extreme violence. By adopting a detailed case study approach, it aims to increase our understanding of the specific motivations and psychological factors underlying extreme violence. Using nontechnical language, this book is the ideal companion for students, researchers, and forensic practitioners interested in the multidisciplinary nature of extreme violence. This book will also be of interest to students taking courses on homicide, mass shooting, school shooting, terrorism, forensic psychology and criminology and criminal justice.",2020-01-01,Book,Book,"The Psychology of Extreme Violence: A Case Study Approach to Serial Homicide, Mass Shooting, School Shooting and Lone-actor Terrorism",21101063496,1,,"The psychology of extreme violence: A case study approach to serial homicide, mass shooting, school shooting and lone-actor terrorism",0,false,10.4324/9781003037965,Taylor and Francis,233,,2020.0,0.0,0.0,,48263975,C. Allely,,,,,,,,,,,118.0,1080.0,18.0,,,,,,,,,,,,,,,,Psychology
235,"© Oxford University Press 2020.The book explores how personal hatred can foster domestic violence and emotional abuse; how hate-proneness is a main contributor to the aggressive tendencies of borderlines, narcissists, psychopaths, and hatemongers; how seemingly ordinary people embark on some of history’s worst hate crimes; and how cohesive groups can develop extremist viewpoints that motivate hate crimes, mass shootings, and genocide. The book’s first part explores hate in personal relationships, looking for an answer to the question of why our personal relationships can survive hate and resentment but not disrespect or contempt. It shows that where contempt creates an irreparable power imbalance, hate is tied to fear, which our brains may reinterpret as thrill, attraction, and arousal. But this can also make hate a dangerous emotion that convinces people to hang on to abusive relationships. When tied to vengeance and the dark triad of personality, hate is not only dangerous but also dehumanizing. Vengeance and the dark personalities are not essential to hate, however. Without them, hate can have more admirable ends. The book’s second part explores the polarizing forces that can bias cohesive groups of like-minded individuals and contribute to what is effectively a hate crisis. Drawing on history, politics, legal theory, philosophy, and psychology, it shows how cultural myths about femininity, ethnic groups, and the land of opportunity perpetuate misogyny, racism, white supremacy, and anti-Semitism. But politicians and policymakers have it in their power to address the hate crisis through legislation that preserves the original incentive behind our constitutional rights.",2020-01-01,Book,Book,Hatred: Understanding Our Most Dangerous Emotion,21101054979,7,,Hatred: Understanding our most dangerous emotion,0,false,10.1093/oso/9780190084448.001.0001,Oxford University Press,235,,2020.0,0.0,0.0,,48678884,B. Brogaard,,,,,,,,,,,203.0,2391.0,28.0,,,,,,,,,,,,,,,,
239,"© 2020, Springer Nature Switzerland AG.Sexism, a pervasive form of oppression, causes profound suffering through various manifestations. Given the rising number of experiences of sexism reported online, categorizing these recollections automatically can aid the fight against sexism, as it can facilitate effective analyses by gender studies researchers and government officials involved in policy making. In this paper, we explore the fine-grained, multi-label classification of accounts (reports) of sexism. To the best of our knowledge, we consider substantially more categories of sexism than any related prior work through our 23-class problem formulation. Moreover, we present the first semi-supervised work for the multi-label classification of accounts describing any type(s) of sexism wherein the approach goes beyond merely fine-tuning pre-trained models using unlabeled data. We devise self-training based techniques tailor-made for the multi-label nature of the problem to utilize unlabeled samples for augmenting the labeled set. We identify high textual diversity with respect to the existing labeled set as a desirable quality for candidate unlabeled instances and develop methods for incorporating it into our approach. We also explore ways of infusing class imbalance alleviation for multi-label classification into our semi-supervised learning, independently and in conjunction with the method involving diversity. Several proposed methods outperform a variety of baselines on a recently released dataset for multi-label sexism categorization across several standard metrics.",2020-01-01,Book Series,Conference Paper,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),25674,1,12343 LNCS,Fine-grained Multi-label Sexism Classification Using Semi-supervised Learning,0,false,10.1007/978-3-030-62008-0_37,Springer Science and Business Media Deutschland GmbH,239,WISE,2020.0,28.0,0.0,,3442296,Harika Abburi,36328737,Pulkit Parikh,2954043,Niyati Chhaya,1704709,Vasudeva Varma,,,,,15.0,118.0,5.0,21.0,96.0,5.0,63.0,633.0,10.0,296.0,4835.0,34.0,,,,,,,Computer Science
241,"© 2020, Springer Nature Switzerland AG.Infodemiology consists in the extraction and analysis of data compiled on the Internet regarding public health. Among other applications, Infodemiology can be used to analyse trends on social networks in order to determine the prevalence of outbreaks of infectious diseases in certain regions. This valuable data provides better understanding of the spread of infectious diseases as well as a vision about social perception of citizens towards the strategies carried out by public healthcare institutions. In this work, we apply Natural Language Processing techniques to determine the impact of outbreaks of infectious diseases such as Zika, Dengue or Chikungunya from a compiled dataset with tweets written in Spanish.",2020-01-01,Book Series,Conference Paper,Communications in Computer and Information Science,17700155007,0,1309,Knowledge Extraction from Twitter Towards Infectious Diseases in Spanish,0,false,10.1007/978-3-030-62015-8_4,Springer Science and Business Media Deutschland GmbH,241,Congreso Internacional de Tecnologías e Innovación,2020.0,44.0,0.0,,1410329617,Óscar Apolinario-Arzube,1409250207,J. García-Díaz,1405074054,Harry Luna-Aveiga,1405074061,José Medina-Moreira,1398759108,R. Valencia-García,,,10.0,26.0,4.0,53.0,294.0,9.0,15.0,168.0,5.0,25.0,216.0,7.0,208.0,3480.0,32.0,,,,"Computer Science, Sociology"
242,"© 2020, Springer Nature Switzerland AG.Social media allows many people to keep in touch and get updated of their surroundings, but these positive features do not bury the fact that another large portion of the users employ this tool with the intention of harassing people under anonymity. Due to the amount of content created on these platforms, spotting hate comments individually becomes an impossible task, and automatic hate speech detectors take place on those tasks. Furthermore, identifying hate speech towards women is specially complex due to the cultural background and the subtlety that characterizes it, which makes it interesting to consider it as a phenomenon by itself, differentiating it from traditional hate speech. Our contribution to automatic misogyny identification entails the creation of a machine-learning model based on linguistic and morphological features, applied to the training set of corpus developed at the Automatic Misogyny Evaluation task which contains 3307 tweets written in Spanish. We evaluate our proposal with different machine-learning classifiers achieving the best accuracy of 77% applying Support Vector Machines.",2020-01-01,Book Series,Conference Paper,Communications in Computer and Information Science,17700155007,1,1309,Automatic Misogyny Detection with Linguistic and Morphological Features in Spanish,0,false,10.1007/978-3-030-62015-8_3,Springer Science and Business Media Deutschland GmbH,242,Congreso Internacional de Tecnologías e Innovación,2020.0,32.0,0.0,,1752477854,Mar Cánovas-García,1409250207,J. García-Díaz,1398759108,R. Valencia-García,,,,,,,3.0,102.0,2.0,53.0,294.0,9.0,208.0,3480.0,32.0,,,,,,,,,,Computer Science
244,,2020-01-01,Journal,Article,Medien und Kommunikationswissenschaft,21101021173,1,68,"Technology - Media - Gender revisited: Gender in the context of datafication, algorithms, and digital media technologies - A critical stocktaking Technik – medien – geschlecht revisited gender im kontext von datafizierung, algorithmen und digitalen medientechnologien – eine kritische bestandsaufnahme",1,true,10.5771/1615-634X-2020-3-211,Nomos Verlagsgesellschaft mbH und Cohohmann@nomos.de,244,Medien & Kommunikationswissenschaft,2020.0,94.0,0.0,,103835404,Corinna Peil,153553638,K. Müller,2475299,Ricarda Drüeke,119803721,Stephan Niemand,2015392167,Raik Roth,,,45.0,139.0,6.0,67.0,91.0,6.0,103.0,132.0,7.0,28.0,14.0,2.0,1.0,0.0,0.0,,,,
245,"© Copyright 2020 Springer Publishing Company, LLC.Using data from a nationally representative sample of school-aged teens (n = 795), this study examined covariates associated with three subtypes of dating violence victimization (physical violence, emotional abuse, and imposed isolation). We asked the research questions: What were the family factors, dating attitudes, and risky behaviors associated with three subtypes of dating violence victimization across two time points? Second, were these relationships moderated by gender? Overall, we found widespread co-occurrence of victimization. Contrary to our predictions, not all earlier experiences with dating violence victimization worsened or persisted overtime. Regarding family factors, we did not find substantial statistically significant effects on victimization, with the exception that greater openness with parents was associated with increased occurrence of emotional abuse at Wave 1. In terms of dating attitudes, we found that when respondents condoned violence against a girlfriend, they were more likely to experience physical violence victimization at both waves. Respondents who believed that it is okay to use violence to control a boyfriend's behavior were more likely to report emotional abuse at Wave 1. Similarly, respondents who believed that it is okay to date more than one person, as well as those who condoned sexual intercourse outside of a romantic relationship, were more susceptible to emotional abuse. Regarding risky behaviors, we found that the respondents' victimization experience did not increase with a greater sexual partner acquisition; rather, it exerted the opposite effect on their experience with physical violence victimization. These risky behaviors, however, were only statistically significant at Wave 1. Finally, the moderating effect of gender is noted in the study. Implications from the study are discussed.",2020-01-01,Journal,Article,Violence and Victims,18778,1,35,"Co-occurrence of Dating Violence Victimization Subtypes: Assessing the Influence of Family Factors, Dating Attitudes, Risky Behaviors, and the Moderating Effect of Gender Among School-Aged Teens",0,false,10.1891/VV-D-18-00159,Springer Publishing Companycontactus@springerpub.com,245,Violence and Victims,2020.0,99.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'It is found that the moderating effect of gender is noted in the study, and widespread co-occurrence of victimization is found.'}",93287099,Y. Paat,2697392,C. Markham,34752935,Melissa F. Peskin,,,,,,,52.0,350.0,9.0,212.0,6233.0,42.0,130.0,3063.0,26.0,,,,,,,,,,"Medicine, Psychology"
249,"© American Marketing Association 2019.Words are part of almost every marketplace interaction. Online reviews, customer service calls, press releases, marketing communications, and other interactions create a wealth of textual data. But how can marketers best use such data? This article provides an overview of automated textual analysis and details how it can be used to generate marketing insights. The authors discuss how text reflects qualities of the text producer (and the context in which the text was produced) and impacts the audience or text recipient. Next, they discuss how text can be a powerful tool both for prediction and for understanding (i.e., insights). Then, the authors overview methodologies and metrics used in text analysis, providing a set of guidelines and procedures. Finally, they further highlight some common metrics and challenges and discuss how researchers can address issues of internal and external validity. They conclude with a discussion of potential areas for future work. Along the way, the authors note how textual analysis can unite the tribes of marketing. While most marketing problems are interdisciplinary, the field is often fragmented. By involving skills and ideas from each of the subareas of marketing, text analysis has the potential to help unite the field with a common set of tools and approaches.",2020-01-01,Journal,Article,Journal of Marketing,22951,222,84,Uniting the Tribes: Using Text for Marketing Insight,0,false,10.1177/0022242919873106,SAGE Publications Ltdinfo@sagepub.co.uk,249,Journal of Marketing,2019.0,168.0,12.0,,40066064,Jonah A. Berger,31789780,Ashlee Humphreys,143876868,S. Ludwig,1821717,Wendy W. Moe,1692988,O. Netzer,3114879,David A. Schweidel,144.0,11816.0,41.0,54.0,2407.0,18.0,29.0,1502.0,11.0,62.0,5109.0,24.0,70.0,3378.0,26.0,81.0,2270.0,22.0,Business
250,"© The Author(s) 2019.Cultural consumption and production are both characterised by multiple dimensions of inequality. Research in cultural stratification has highlighted the links between the exclusivity of cultural production, the type of cultural works created, and the audiences and public receptions for culture. We contribute to this agenda by examining a hitherto unexplored area: the cultural values and political identities of workers in the creative industries and cultural sector. Analysis of the British Social Attitudes (2010–2015) surveys and British Election Study Internet Panel (2016–2017) surveys demonstrates that creative and cultural workers have distinct cultural values. They are among the most left-wing, liberal and pro-welfare of any occupations and industries. This sets them apart from the average respondent who is relatively more right-wing, authoritarian and more in favour of welfare control. When examining their non-electoral participation, we also find they are highly civically engaged in terms of contacting elected representatives and government officials, signing petitions, political volunteering, political donations, participating in demonstrations, ethical consumption and boycotts, and industrial action. Moreover, they are more likely to report that they supported Remain in the 2016 EU ‘Brexit’ Referendum, to report unhappiness with the Leave result, and to identify with Remain voters. We conclude that distinct occupational cultures are particularly significant in the case of the cultural and creative sector, given creative workers’ role in representing society and the civic realm via the products of their work. We also argue that occupational cultures constitute an important, under-recognised source of social and cultural division.",2020-01-01,Journal,Article,Sociological Review,18106,14,68,"The values of culture? Social closure in the political identities, policy preferences, and social attitudes of cultural and creative workers",1,true,10.1177/0038026119871401,SAGE Publications Ltdinfo@sagepub.co.uk,250,Sociology Review,2019.0,86.0,0.0,,100683617,Siobhan McAndrew,1400961610,D. O’Brien,144451577,Mark Taylor,,,,,,,42.0,528.0,11.0,97.0,1233.0,19.0,36.0,1880.0,14.0,,,,,,,,,,Sociology
251,"© 2020 Jemma Tosh.This groundbreaking text interrogates the constructed boundary between therapy and violence, by examining therapeutic practice and discourse through the lens of a psychologist and a survivor of sexual abuse. It asks, what happens when those we approach for help cause further harm? Can we identify coercive practices and stop sexual abuse in psychology, psychiatry, and medicine? Tosh explores these questions and more to illustrate that many of the therapies considered fundamental to clinical practice are deeply problematic when issues of consent and sexual abuse are considered. The book examines a range of situations where medical power and authority produces a context where the refusals and non-consent of oppressed groups are denied, dismissed, or ignored, arguing that key concepts and discourses have resulted in the production and standardisation of a therapeutic rape culture in the helping professions. Tosh uses critical intersectionality theory and discourse analysis to expertly highlight the complex interrelationships between race, class, gender, sexuality, and disability in our understanding of abuse and how we define survivors. Drawing on a wide range of comprehensive examples, including experiences and perspectives from cisgender and transgender men and women, as well as nonbinary and intersex people, this is essential reading for students and researchers of critical and queer psychology, gender studies, as well as mental health practitioners and social workers.",2019-11-27,Book,Book,"The Body and Consent in Psychology, Psychiatry, and Medicine: A Therapeutic Rape Culture",21101048814,0,,"The body and consent in psychology, psychiatry, and medicine: A therapeutic rape culture",0,false,10.4324/9781315114484,Taylor and Francis,251,,2019.0,0.0,1.0,,116155021,Jemma Tosh,,,,,,,,,,,31.0,220.0,6.0,,,,,,,,,,,,,,,,Psychology
252,"© 2019 IEEE.In recent years, it is evident the interest in the role of women within society and, in particular, the way we approach and refer to them. However, sexism as a form of discrimination towards women spread exponentially through the web and at a very high frequency, especially in the form of memes. Memes, which are typically composed of pictorial and textual components, can convey messages ranging from women stereotype, shaming, objectification to violence. In order to counterattack this phenomenon, in this paper we give a first insight in the field of automatic detection of sexist memes, by investigating both unimodal and multimodal approaches to understand the contribution of textual and visual cues.",2019-09-01,Conference Proceeding,Conference Paper,"2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2019",21100941911,14,,Detecting Sexist MEME on the Web: A Study on Textual and Visual Cues,0,false,10.1109/ACIIW.2019.8925199,Institute of Electrical and Electronics Engineers Inc.,252,2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),2019.0,25.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'A first insight is given in the field of automatic detection of sexist memes, by investigating both unimodal and multimodal approaches to understand the contribution of textual and visual cues.'}",1847803,E. Fersini,2032578,F. Gasparini,3204928,S. Corchs,,,,,,,110.0,2476.0,23.0,181.0,5035.0,38.0,68.0,1324.0,16.0,,,,,,,,,,"Computer Science, Psychology"
253,"© The Author(s) 2019.This article presents the findings of a corpus linguistic analysis of the hashtags #mansplaining, #manspreading, and #manterruption, three lexical blends which have recently found widespread use across a variety of online media platforms. Focusing on the social media and microblogging site Twitter, we analyze a corpus of over 20,000 tweets containing these hashtags to examine how discourses of gender politics and gender relations are represented on the site. More specifically, our analysis suggests that users include these hashtags in tweets to index their individual evaluations of, and assumptions about, “proper” gendered behavior. Consequently, their metadiscursive references to the respective phenomena reflect their beliefs of what constitutes appropriate (verbal) behavior and the extent to which gender is appropriated as a variable dictating this behavior. As such, this article adds to our knowledge of the ways in which gendered social practices become sites of contestation and how contemporary gender politics play out in social media sites.",2019-07-01,Journal,Article,Social Media and Society,21100837352,11,5,"Gender Politics and Discourses of #mansplaining, #manspreading, and #manterruption on Twitter",1,true,10.1177/2056305119861807,SAGE Publications Ltd,253,Social Media + Society,2019.0,60.0,1.0,,72103816,Ursula Lutzky,101140635,R. Lawson,,,,,,,,,33.0,167.0,7.0,29.0,409.0,9.0,,,,,,,,,,,,,Sociology
254,"© 2019 IEEE.Recent moves to consider misogyny as a hate crime have refocused efforts for owners of web properties to detect and remove misogynistic speech. This paper considers the use of deep learning techniques for detection of misogyny in Urban Dictionary, a crowdsourced online dictionary for slang words and phrases. We compare the performance of two deep learning techniques, Bi-LSTM and Bi-GRU, to detect misogynistic speech with the performance of more conventional machine learning techniques, logistic regression, Naive-Bayes classification, and Random Forest classification. We find that both deep learning techniques examined have greater accuracy in detecting misogyny in the Urban Dictionary than the other techniques examined.",2019-06-01,Conference Proceeding,Conference Paper,"2019 International Conference on Cyber Situational Awareness, Data Analytics and Assessment, Cyber SA 2019",21100937412,16,,A comparison of machine learning approaches for detecting misogynistic speech in urban dictionary,2,,10.1109/CyberSA.2019.8899669,Institute of Electrical and Electronics Engineers Inc.,254,"2019 International Conference on Cyber Situational Awareness, Data Analytics And Assessment (Cyber SA)",2019.0,23.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'It is found that both deep learning techniques examined have greater accuracy in detecting misogyny in the Urban Dictionary than the other techniques examined.'}",143927736,Theo Lynn,1704130,P. Endo,32572828,P. Rosati,8773853,I. Silva,24302859,Guto Leoni Santos,40953860,Debbie Ging,172.0,1703.0,19.0,162.0,1464.0,16.0,81.0,554.0,12.0,82.0,1100.0,18.0,57.0,473.0,11.0,52.0,723.0,10.0,Computer Science
255,"Copyright © 2020 by Annual Reviews.Racism. Sexism. Heterosexism. Gender binarism. Together, they comprise intimately harmful, distinct, and entangled societal systems of self-serving domination and privilege that structure the embodiment of health inequities. Guided by the ecosocial theory of disease distribution, I synthesize key features of the specified ""isms"" and provide a measurement schema, informed by research from both the Global North and the Global South. Metrics discussed include (a) structural, including explicit rules and laws, nonexplicit rules and laws, and area-based or institutional nonrule measures; and (b) individual-level (exposures and internalized) measures, including explicit self-report, implicit, and experimental. Recommendations include (a) expanding the use of structural measures to extend beyond the current primary emphasis on psychosocial individual-level measures; (b) analyzing exposure in relation to both life course and historical generation; (c) developing measures of anti-isms; and (d) developing terrestrially grounded measures that can reveal links between the structural drivers of unjust isms and their toll on environmental degradation, climate change, and health inequities.",2019-04-01,Book Series,Review,Annual Review of Public Health,19584,124,41,"Measures of racism, sexism, heterosexism, and gender binarism for health equity research: From structural injustice to embodied harm-an ecosocial analysis",1,true,10.1146/annurev-publhealth-040119-094017,"Annual Reviews Inc.4139 El Camino Way, P.O. Box 10139Palo AltoCA 94306",255,Annual Review of Public Health,2019.0,202.0,7.0,"{'model': 'tldr@v2.0.0', 'text': 'Guided by the ecosocial theory of disease distribution, key features of the specified ""isms"" are synthesized and a measurement schema is provided, informed by research from both the Global North and the Global South.'}",144810681,N. Krieger,,,,,,,,,,,379.0,40368.0,94.0,,,,,,,,,,,,,,,,"Medicine, Sociology"
256,"© Inter-Disciplinary Press 2014.Explanations of eating disorders continue to draw on beauty ideals of thinness and perfection, regulated by the power of the male gaze. Sustained by larger beauty discourses and the diet industry, these ideals emphasise that thinness equals perfection, whereas fat equals ugly and uncontrollable. The circulation of such ideals excludes aspects of female subjectivity and provides little room to explore other explanations of women’s experiences of eating disorders. In response, I argue that women make decisions and experience eating disorders beyond wanting to be perfected for the male gaze. I draw on in-depth interviews, artwork, poetry and journals obtained from seven women and take a Bakhtinian sociolinguistic approach to construct fuller answers to questions that cannot always be asked in straightforward ways. I examine how the women’s bodies are disciplined through the following discursive subthemes: trying to reach beauty and fat versus thin. While acknowledging that beauty ideals contribute to eating disorders, I demonstrate how the women’s voices and sexual trauma constitute their experiences of eating disorders.",2019-01-01,Book,Book Chapter,"(Re)Possessing Beauty: Politics, Poetics, Change",21101120059,2,,"How Far to Beautiful? Thinness, Eating Disorders and Sexual Trauma",0,false,10.1163/9781848881259_006,Brill,256,,2014.0,0.0,0.0,,2104105732,Lisa Hodge,,,,,,,,,,,19.0,20.0,3.0,,,,,,,,,,,,,,,,Psychology
257,"© Oxford University Press 2019. All rights reservedIn recent years, feminists have turned to digital technologies and social media platforms to dialogue, network, and organize against contemporary sexism, misogyny, and rape culture. The emergence of feminist campaigns such as #MeToo, #BeenRapedNeverReported, and Everyday Sexism are part of a growing trend of digital resistances and challenges to sexism, patriarchy, and other forms of oppression. Although recent scholarship has documented the ways digital spaces are often highly creative sites where the public can learn about and intervene in rape culture, little research has explored girls’ and women’s experiences of using digital platforms to challenge misogynistic practices. This is therefore the first book-length study to interrogate how girls and women negotiate rape culture through digital platforms, including blogs, Twitter, Facebook, Tumblr, and mobile apps. Through an analysis of high-profile campaigns such as Hollaback!, Everyday Sexism, and the everyday activism of Twitter feminists, this book presents findings of over 800 pieces of digital content, and semi-structured interviews with 82 girls, women, and some men around the world, including organizers of various feminist campaigns and those who have contributed to them. As our study shows, digital feminist activism is far more complex and nuanced than one might initially expect, and a variety of digital platforms are used in a multitude of ways, for many purposes. Furthermore, although it may be technologically easy for many groups to engage in digital feminist activism, there remain emotional, mental, or practical barriers that create different experiences, and legitimate some feminist voices, perspectives, and experiences over others.",2019-01-01,Book,Book,Digital Feminist Activism: Girls and Women Fight Back Against Rape Culture,21101100707,113,,Digital Feminist Activism: Girls and Women Fight Back Against Rape Culture,0,false,10.1093/oso/9780190697846.001.0001,Oxford University Press,257,,2019.0,2.0,4.0,,40059516,Kaitlynn Mendes,73456815,J. Ringrose,114503603,Jessalynn Keller,,,,,,,113.0,1124.0,13.0,126.0,5820.0,40.0,37.0,1123.0,14.0,,,,,,,,,,Political Science
261,"© 2020 Sonja Erikainen.This book critically explores the history of gender verification in international sport, to show how culture, politics, and science come together to produce ""femaleness"" and, consequently, the female body as we know it. Tracing gender verification policies and practices in sport since the 1930s till the present, the book shows how and why medical ""sex tests"" have been used to ""verify"" women athletes’ femaleness, in ways that both reflect and have shaped broader social and scientific ideas about femaleness in the process. Exploring how geopolitics, gender, class and race relations intertwined with scientific ideas about femaleness and womanhood to shape gender verification, the book shows how sports competitions became a battleground where new and old ideas about sex difference collided. By mapping the social, historical, and material instability of sex and gender, it shows why so much investment has been placed in distinguishing femaleness from maleness in sport and beyond. The book will be of interest to researchers, later-year undergraduate and graduate students in a broad range of areas including gender studies, sports studies, social and historical studies of science and medicine. It will also be relevant to sports policy as it historically and conceptually contextualises gender verification policies.",2019-01-01,Book,Book,Gender Verification and the Making of the Female Body in Sport: A History of the Present,21101027883,5,,Gender verification and the making of the female body in sport: A history of the present,0,false,10.4324/9780429316159,Taylor and Francis,261,,2019.0,0.0,2.0,,40866783,Sonja Erikainen,,,,,,,,,,,31.0,208.0,7.0,,,,,,,,,,,,,,,,Psychology
264,"© 2019, Springer Nature Switzerland AG.The number of social media users is ever-increasing. Unfortunately, this has also resulted in the massive rise of uncensored online hate against vulnerable communities such as immigrants, LGBT and women. Current work on the automatic detection of various forms of hate speech (HS) typically employs supervised learning, requiring manually annotated data. The highly polarizing nature of the topics involved raises concerns about the quality of annotations these systems rely on, because not all the annotators are equally sensitive to different kinds of hate speech. We propose an approach to leverage the fine-grained knowledge expressed by individual annotators, before their subjectivity is averaged out by the gold standard creation process. This helps us to refine the quality of training sets for hate speech detection. We introduce a measure of polarization at the level of single instances in the data to manipulate the training set and reduce the impact of most polarizing text on the learning process. We test our approach on three datasets, in English and Italian, annotated by experts and workers hired on a crowdsourcing platform. We classify instances of sexist, racist, and homophobic hate speech in tweets and show how our approach improves the prediction performance of a supervised classifier. Moreover, the proposed polarization measure helps towards the manual exploration of the individual instances of tweets in our datasets.",2019-01-01,Book Series,Conference Paper,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),25674,15,11946 LNAI,A New Measure of Polarization in the Annotation of Hate Speech,0,false,10.1007/978-3-030-35166-3_41,Springer,264,International Conference of the Italian Association for Artificial Intelligence,2019.0,31.0,4.0,"{'model': 'tldr@v2.0.0', 'text': 'An approach to leverage the fine-grained knowledge expressed by individual annotators, before their subjectivity is averaged out by the gold standard creation process is proposed, to refine the quality of training sets for hate speech detection.'}",49181304,S. Akhtar,3101511,Valerio Basile,1787198,V. Patti,,,,,,,156.0,1683.0,25.0,123.0,2883.0,25.0,220.0,4576.0,36.0,,,,,,,,,,Computer Science
265,"© First Monday, 1995-2019.Online anonymous forums are valued as spaces of open participation which facilitate multiple expressions of identity. In this paper I unmask how memes perpetuate existing gender power structures in spaces where users are only known by pseudonyms. The site of study is the r/AdviceAnimals forum of Reddit, in which a popular genre of memes known as Advice Animals are shared by users. Using a cross-section of Advice Animal memes submitted to this forum, the study examines the uneven distribution of power in representations of gender and feminists. I find that while women are highly sexualised, obsessive, and clingy, male characters are a default central character, used to express non-specific ideals of behaivour. As feminists, men are portrayed as legitimate, whilst women-feminists are epitomised as hypocritical, demanding, ""Nazis"". The main contribution of the article is highlighting the gendered nature of memes, and call attention to the unequal representation in pseudonymous space.",2019-01-01,Journal,Article,First Monday,200147134,7,24,There are no girls on the Internet: Gender performances in Advice Animal memes,1,true,10.5210/fm.v24i10.9593,First Mondayejv@uic.edu,265,First Monday,2019.0,0.0,1.0,"{'model': 'tldr@v2.0.0', 'text': 'It is found that while women are highly sexualised, obsessive, and clingy, male characters are a default central character, used to express non-specific ideals of behaviour in memes.'}",151201979,S. Brooke,,,,,,,,,,,6.0,38.0,4.0,,,,,,,,,,,,,,,,"Computer Science, Sociology"
266,"© Sarah Creighton and Lih-Mei Liao 2019.An analysis of the cultural and economic drivers of the growing phenomenon of FGCS, written by cross-disciplinary experts, this book challenges the concept of individual consumer choice in FGCS: A decision that is rarely exercised in a socio-cultural vacuum. Four distinct aspects of FGCS are covered: Variations in female genital anatomy; surgical techniques and evidence; historical contexts and ethical dilemmas; norm-critical understandings to inform professional responses. Rendering philosophical critiques accessible, and exposing dubious social values that underpin the practice, this text is crucial in driving a broader understanding of FGCS as a cultural phenomenon of our times. Only with a fuller understanding of the multiple perspectives of FGCS, can there be sensible alternatives for women and girls psychologically troubled by their natural, healthy form. Offering explanations and interventions at individual, institutional and societal levels, this text will be valued by both professional and non-professional audiences.",2019-01-01,Book,Book,Female Genital Cosmetic Surgery: Solution to What Problem?,21101095725,5,,Female Genital Cosmetic Surgery: Solution to What Problem?,0,false,10.1017/9781108394673,Cambridge University Press,266,Female Genital Cosmetic Surgery,2019.0,130.0,0.0,,11807047,A. Shahvisi,5400392,B. Earp,,,,,,,,,77.0,348.0,10.0,206.0,3733.0,33.0,,,,,,,,,,,,,Medicine
267,"© 2019 - IOS Press and the authors.Patriarchal behavior, such as other social habits, has been transferred online, appearing as misogynistic and sexist comments, posts or tweets. This online hate speech against women has serious consequences in real life, and recently, various legal cases have arisen against social platforms that scarcely block the spread of hate messages towards individuals. In this difficult context, this paper presents an approach that is able to detect the two sides of patriarchal behavior, misogyny and sexism, analyzing three collections of English tweets, and obtaining promising results.",2019-01-01,Journal,Article,Journal of Intelligent and Fuzzy Systems,23917,52,36,Online hate speech against women: Automatic identification of misogyny and sexism on twitter,2,,10.3233/JIFS-179023,IOS PressNieuwe Hemweg 6BAmsterdam1013 BG,267,Journal of Intelligent & Fuzzy Systems,2019.0,21.0,6.0,,7675229,Simona Frenda,46188821,Bilal Ghanem,1389780530,M. Montes-y-Gómez,143752702,Paolo Rosso,,,,,19.0,265.0,8.0,39.0,762.0,15.0,281.0,4851.0,36.0,646.0,16149.0,63.0,,,,,,,"Computer Science, Psychology"
268,"© First Monday.This article contributes to understanding the phenomenon of online abuse and harassment toward women scholars. We draw on data collected from 14 interviews with women scholars from the United States, Canada, and the United Kingdom, and report on the types of supports they sought during and after their experience with online abuse and harassment. We found that women scholars rely on three levels of support: the first level includes personal and social support (such as encouragement from friends and family and outsourcing comment reading to others); the second includes organizational (such as university or institutional policy), technological (such as reporting tools on Twitter or Facebook), and sectoral (such as law enforcement) support; and, the third includes larger cultural and social attitudes and discourses (such as attitudes around gendered harassment and perceptions of the online/offline divide). While participants relied on social and personal support most frequently, they commonly reported relying on multiple supports across all three levels. We use an ecological model as our framework to demonstrate how different types of support are interconnected, and recommend that support for targets of online abuse must integrate aspects of all three levels.",2018-08-01,Journal,Article,First Monday,200147134,15,23,I get by with a little help from my friends: The ecological model and support for women scholars experiencing online harassment,0,false,10.5210/fm.v23i8.9136,First Mondayejv@uic.edu,268,First Monday,2018.0,0.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'It is recommended that support for targets of online abuse must integrate aspects of all three levels of support, and an ecological model is used as a framework to demonstrate how different types of support are interconnected.'}",3139980,Jaigris Hodson,51148754,Chandell Gosse,1785760,G. Veletsianos,51147481,Shandell Houlden,,,,,54.0,301.0,7.0,16.0,139.0,5.0,189.0,5384.0,40.0,22.0,251.0,7.0,,,,,,,"Computer Science, Sociology"
269,"© 2018 Informa UK Limited, trading as Taylor & Francis Group.In this point of departure, I discuss using an intersectional feminist lens to explore Twitter traffic around Donald Trump’s 2016 US election win in an MA module Sociology of Education. Next I reflect upon my experience of having the feminist content of my public Twitter account trolled during the election period. I argue Twitter provides a new mediated space for teaching and learning but feminist academics also face risks in the form of misogyny both online and off.",2018-07-04,Journal,Article,Teaching in Higher Education,200147112,27,23,Digital feminist pedagogy and post-truth misogyny,2,,10.1080/13562517.2018.1467162,Routledgeinfo@tandf.co.uk,269,,2018.0,51.0,3.0,,73456815,J. Ringrose,,,,,,,,,,,126.0,5820.0,40.0,,,,,,,,,,,,,,,,Sociology
270,"© 2018 ACM.The scientific study of hate speech, from a computer science point of view, is recent. This survey organizes and describes the current state of the field, providing a structured overview of previous approaches, including core algorithms, methods, and main features used. This work also discusses the complexity of the concept of hate speech, defined in many platforms and contexts, and provides a unifying definition. This area has an unquestionable potential for societal impact, particularly in online communities and digital media platforms. The development and systematization of shared resources, such as guidelines, annotated datasets in multiple languages, and algorithms, is a crucial step in advancing the automatic detection of hate speech.",2018-07-01,Journal,Review,ACM Computing Surveys,23038,444,51,A survey on automatic detection of hate speech in text,2,,10.1145/3232676,Association for Computing Machineryacmhelp@acm.org,270,ACM Computing Surveys,2018.0,76.0,57.0,"{'model': 'tldr@v2.0.0', 'text': 'This survey organizes and describes the current state of the field, providing a structured overview of previous approaches, including core algorithms, methods, and main features used, and provides a unifying definition of hate speech.'}",33621471,Paula Fortuna,144979724,Sérgio Nunes,,,,,,,,,16.0,916.0,8.0,66.0,1121.0,11.0,,,,,,,,,,,,,Computer Science
271,"© The Editor(s) (if applicable) and The Author(s) 2018. All rights reserved.This book examines the effects of faith schools on social cohesion and inter-ethnic relations. Faith schools constitute approximately one third of all state-maintained schools and two fifths of the independent schools in England. Nevertheless, they have historically been, and remain, controversial. In the current social climate, questions have been raised about the ability of faith schools to promote Community Cohesion and, included within that, their ability to promote tolerance. This book explores one aspect of the debate by examining the effect that faith schools have on their students' attitudes of tolerance. As well as asking what differences exist between students in faith and non-faith schools, it also looks at which aspects of the schools might be affecting the students and their attitudes towards different minorities. The book is a must-read for students and researchers in the fields of education and religious studies, as well as anyone with an interest in the place of faith schools in a modern multicultural society.",2018-03-28,Book,Book,"Faith Schools, Tolerance and Diversity: Exploring the Influence of Education on Students' Attitudes of Tolerance",21100858016,0,,"Faith schools, tolerance and diversity: Exploring the influence of education on students' attitudes of tolerance",2,,10.1007/978-3-319-69566-2,Springer International Publishing,271,,2018.0,0.0,0.0,,2071355520,H. Everett,,,,,,,,,,,3.0,9.0,2.0,,,,,,,,,,,,,,,,Psychology
272,"© 2018 by the authors.The Men's Rights Activism (MRA) movement and its sub-movement The Red Pill (TRP), has flourished online, offering support and advice to men who feel their masculinity is being challenged by societal shifts. Whilst some insightful studies have been carried out, the small samples analysed by researchers limits the scope of studies, which is small compared to the large amounts of data that TRP produces. By extracting a significant quantity of content from a prominent MRA website, ReturnOfKings.com (RoK), whose creator is one of the most prominent figures in the manosphere and who has been featured in multiple studies. Research already completed can be expanded upon with topic modelling and neural networked machine learning, computational analysis that is proposed to augment methodologies of open coding by automatically and unbiasedly analysing conceptual clusters. The successes and limitations of this computational methodology shed light on its further uses in sociological research and has answered the question: What can topic modeling demonstrate about the men's rights activism movement's prescriptive masculinity? This methodology not only proved that it could replicate the results of a previous study, but also delivered insights into an increasingly political focus within TRP, and deeper perspectives into the concepts identified within the movement.",2018-03-09,Journal,Article,Social Sciences,21100810500,12,7,Topic modeling the Red Pill,1,true,10.3390/socsci7030042,MDPI AGPostfachBaselCH-4005,272,,2018.0,38.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This methodology not only proved that it could replicate the results of a previous study, but also delivered insights into an increasingly political focus within TRP, and deeper perspectives into the concepts identified within the movement.'}",145455196,J. Mountford,,,,,,,,,,,2.0,19.0,1.0,,,,,,,,,,,,,,,,Economics
273,"© Springer International Publishing AG 2018. All rights reserved.The book aims to revitalise the interdisciplinary debate about evolutionary ethics and substantiate the idea that evolution science can provide a rational and robust framework for understanding morality. It also traces pathways for knowledge-based choices to be made about directions for future long-term biological evolution and cultural development in view of adaptation to the expected, probable and possible future and the ecological sustainability of our planetary environment The authors discuss ethical challenges associated with the major biosocial sources of human variation: individual variation, inter-personal variation, inter-group variation, and inter-generational variation. This book approaches the long-term challenges of the human species in a holistic way. Researchers will find an extensive discussion of the key theoretical scientific aspects of the relationship between evolution and morality. Policy makers will find information that can help them better understand from where we are coming and inspire them to make choices and take actions in a longer-term perspective. The general public will find food for thoughts.",2018-01-10,Book,Book,Evolution Science and Ethics in the Third Millennium: Challenges and Choices for Humankind,21100857332,11,,Evolution science and ethics in the third millennium: Challenges and choices for humankind,2,,10.1007/978-3-319-73090-5,Springer International Publishing,273,"Religion, Brain & Behavior",2018.0,1.0,0.0,,15365233,R. Cliquet,16997088,D. Avramov,,,,,,,,,86.0,559.0,10.0,54.0,355.0,8.0,,,,,,,,,,,,,Political Science
274,"© 2017 Taylor and Francis.This book provides a path-breaking study of the genesis, growth, gains, and dilemmas of women’s movements in countries throughout the world. Its focus is on the global South, where women’s movements have engaged in complex negotiations with national and international forces. It challenges widely held assumptions about the Western origins and character of local feminisms. The authors locate women’s movements within the terrain from which they emerged by exploring their relationships with the state, civil society, and other social movements. This fully revised second edition contains six new chapters by leading scholars of women and gender studies, on both individual countries and on several major regions of the world? Europe, Africa, Latin America, and the Maghreb. This balanced coverage enables readers to identify regional patterns and also learn from in-depth case studies. Women’s Movements in the Global Era is essential reading for anyone interested in the global scope and implications of feminism.",2018-01-01,Book,Book,Women’s Movements in the Global Era: The Power of Local Feminisms,21101103329,0,,Women’s Movements in the Global Era: The Power of Local Feminisms,0,false,10.4324/9780429495557,Taylor and Francis,274,,2019.0,0.0,4.0,,48142114,Amrita Basu,,,,,,,,,,,79.0,1250.0,19.0,,,,,,,,,,,,,,,,Geography
275,"© 2019 Emma WhiteWidely popularized images of unobtainable and damaging feminine ideals can be a cause of profound disjunction between women and their bodies. A consequence of this dissonance is an embodied performance of these ideals with the potential development of disordered eating practices, such as anorexia nervosa. This book develops a spirituality of anorexia by suggesting that these eating disorders are physical symptoms of the general repression of feminine nature in our culture. Furthermore, it puts forward Goddess feminism as a framework for a healing therapeutic model to address anorexia and more broadly, the –slender ideal— touted by society. The book focuses on the female body in contemporary society, specifically the development of anorexia nervosa, and what this expression communicates about female embodiment. Drawing upon the work of a variety of theorists, social commentators, liberation theologians and thealogians, it discusses the benefits of adopting female-focused myths, symbols and rituals, drawing upon the work of Marion Woodman and Naomi Goldenberg. Ultimately, it theorises a thealogical approach to anorexia aimed at displacing the damaging discourses that undermine women in the twenty-first century. Offering an alternative model of spirituality and embodiment for contemporary women, this book will be of keen interest to scholars of theology, religious studies, gender studies and psychology.",2018-01-01,Book,Book,The Spirituality of Anorexia: A Goddess Feminist Thealogy,21101048768,0,,The spirituality of anorexia,0,false,10.4324/9781351103367,Taylor and Francis,275,,2018.0,0.0,0.0,,2053441697,E. White,,,,,,,,,,,8.0,10.0,2.0,,,,,,,,,,,,,,,,Psychology
276,"© The Editor(s) (if applicable) and The Author(s) 2018.This book explores the meanings, experiences, and challenges faced by Black women faculty that are either on the tenure track or have earned tenure. The authors advance the notion of comparative inter sectionality to tease through the contextual peculiarities and commonalities that define their identities as Black women and their experiences with tenure and promotion across the two geographical spaces. By so doing, it works through a comparative treatment of existing social inequalities, educational disparities, and injustices in the promotion and retention of Black women academics. Such interpretative examinations offer important insights into how Black women’s subjugated knowledge and experiences continue to be suppressed within mainstream structures of power and how they are negotiated across contexts.",2018-01-01,Book,Book,"Black Women, Academe, and the Tenure Process in the United States and the Caribbean",21100903151,9,,"Black women, academe, and the tenure process in the United States and the Caribbean",2,,10.1007/978-3-319-89686-1,Palgrave Macmillan,276,,2019.0,0.0,2.0,,83528971,T. Esnard,1403703045,Deirdre Cobb-Roberts,,,,,,,,,65.0,116.0,5.0,47.0,424.0,9.0,,,,,,,,,,,,,Political Science
278,"© 2018 CEUR-WS. All Rights Reserved.We present our systems for misogyny identification on Twitter, for Italian and English. The models are based on a Support Vector Machine and they use n-grams as features. Our solution is very simple and yet we achieve top results on Italian Tweets and excellent results on English Tweets. Furthermore, we experiment with a single model that works across languages by leveraging abstract features. We show that a single multilingual system yields performances comparable to two independently trained systems. We achieve accuracy results ranging from 45% to 85%. Our system is ranked first out of twelve submissions for sub-task B on Italian and second for sub-task A.",2018-01-01,Conference Proceeding,Conference Paper,CEUR Workshop Proceedings,21100218356,2,2263,"Crotonemilano for AMI at evalita2018. A performant, cross-lingual misogyny detection system.",1,true,10.4000/books.aaccademia.4734,CEUR-WSceurws@sunsite.informatik.rwth-aachen.de,278,EVALITA@CLiC-it,2018.0,11.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'It is shown that a single multilingual system yields performances comparable to two independently trained systems, and a single model that works across languages by leveraging abstract features is experiment with.'}",144607761,A. Basile,52325748,Chiara Rubagotti,,,,,,,,,40.0,245.0,7.0,6.0,23.0,2.0,,,,,,,,,,,,,"Sociology, Computer Science"
280,"© 2018 CEUR-WS. All Rights Reserved.The automatic misogyny identification (AMI) task proposed at IberEval and EVALITA 2018 is an example of the active involvement of scientific Research to face up the online spread of hate contents against women. Considering the encouraging results obtained for Spanish and English in the precedent edition of AMI, in the EVALITA framework we tested the robustness of a similar approach based on topic and stylistic information on a new collection of Italian and English tweets. Moreover, to deal with the dynamism of the language on social platforms, we also propose an approach based on automatically-enriched lexica. Despite resources like the lexica prove to be useful for a specific domain like misogyny, the analysis of the results reveals the limitations of the proposed approaches.",2018-01-01,Conference Proceeding,Conference Paper,CEUR Workshop Proceedings,21100218356,2,2263,Automatic expansion of lexicons for multilingual misogyny detection,1,true,10.4000/books.aaccademia.4680,CEUR-WSceurws@sunsite.informatik.rwth-aachen.de,280,EVALITA@CLiC-it,2018.0,22.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'In the EVALITA framework, the robustness of a similar approach based on topic and stylistic information on a new collection of Italian and English tweets is tested based on automatically-enriched lexica to deal with the dynamism of the language on social platforms.'}",7675229,Simona Frenda,46188821,Bilal Ghanem,1422530663,Estefanía Guzmán-Falcón,1389780530,M. Montes-y-Gómez,2112901874,Luis Villaseñor-Pineda,,,19.0,265.0,8.0,39.0,762.0,15.0,2.0,110.0,2.0,281.0,4851.0,36.0,202.0,2490.0,26.0,,,,Computer Science
282,"© 2018 CEUR-WS. All Rights Reserved.Automatic Misogyny Identification (AMI) is a new shared task proposed for the first time at the Evalita 2018 evaluation campaign. The AMI challenge, based on both Italian and English tweets, is distinguished into two subtasks, i.e. Subtask A on misogyny identification and Subtask B about misogynistic behaviour categorization and target classification. Regarding the Italian language, we have received a total of 13 runs for Subtask A and 11 runs for Subtask B. Concerning the English language, we received 26 submissions for Subtask A and 23 runs for Subtask B. The participating systems have been distinguished according to the language, counting 6 teams for Italian and 10 teams for English. We present here an overview of the AMI shared task, the datasets, the evaluation methodology, the results obtained by the participants and a discussion of the methodology adopted by the teams. Finally, we draw some conclusions and discuss future work.",2018-01-01,Conference Proceeding,Conference Paper,CEUR Workshop Proceedings,21100218356,104,2263,Overview of the EVALITa 2018 task on automatic misogyny identification (AMI),1,true,10.4000/books.aaccademia.4497,CEUR-WSceurws@sunsite.informatik.rwth-aachen.de,282,EVALITA@CLiC-it,2018.0,21.0,29.0,"{'model': 'tldr@v2.0.0', 'text': 'An overview of the AMI shared task, the datasets, the evaluation methodology, the results obtained by the participants and a discussion of the methodology adopted by the teams is presented.'}",1847803,E. Fersini,2177867,Debora Nozza,143752702,Paolo Rosso,,,,,,,110.0,2476.0,23.0,25.0,1129.0,13.0,646.0,16149.0,63.0,,,,,,,,,,"Sociology, Computer Science"
288,,2017-10-26,Book Series,Review,Zeitschrift fur Celtische Philologie,21100199520,0,64,The Irish proverbial comparison 'chomh + Adj + le + Np',2,,10.1515/zcph-2017-0006,Walter de Gruyter GmbHinfo@degruyter.com,288,,2017.0,75.0,0.0,,151464612,Marcas Mac Coinnigh,,,,,,,,,,,2.0,1.0,1.0,,,,,,,,,,,,,,,,
289,"© The Editor(s) (if applicable) and The Author(s) 2018. All rights reserved.This book explains the subtle maneuvers of what researchers call �facework� and demonstrates the vital role it plays in the success or failure of cross-cultural interactions. Building on Geert Hofstede�s seminal research on cultural dimensions, Merkin synthesizes more recent research in business, communication, cross-cultural psychology and sociology to offer a model for better understanding facework. Additionally, Merkin�s model shows how particular communication strategies can facilitate more successful cross-cultural interactions. The first book of its kind to focus on the practical aspects of employing face-saving, it is a needed text for academics, students, and business professionals negotiating with organizations from different cultures.",2017-09-14,Book,Book,Saving Face in Business: Managing Cross-Cultural Interactions,21100838495,9,,Saving Face in Business: Managing Cross-Cultural Interactions,2,,10.1057/978-1-137-59174-6,Palgrave Macmillan,289,,2018.0,0.0,1.0,,5745475,R. Merkin,,,,,,,,,,,35.0,557.0,12.0,,,,,,,,,,,,,,,,Psychology
290,"© The Editor(s) (if applicable) and The Author(s) 2017. All rights reserved.This book provides a thorough and novel examination of the gendered nature of innovations in the new economy. It tracks the contemporary shift from heavy industry to game industry and how this has altered relationships between gender, identity, corporate culture, creative work, and the future of business. Through empirical research and theoretical analysis, the authors present their own carefully contextualized cases and conceptual frameworks relating themes of innovation and gender to recent theories concerning globalization and transnationalism. This wide-ranging and interdisciplinary text provides readers with insightful entries on what innovations are and the ways innovation processes become gendered. It explores the business landscape based on creative work and offers a wealth of information for scholars of entrepreneurship, management, sociology, cultural studies, and communication.",2017-06-05,Book,Book,"Gender and Innovation in the New Economy: Women, Identity, and Creative Work",21100835843,12,,"Gender and innovation in the new economy: Women, identity, and creative work",2,,10.1057/978-1-137-52702-8,Palgrave Macmillan,290,,2017.0,0.0,0.0,,87805847,Seppo Poutanen,2024266,Anne Kovalainen,,,,,,,,,31.0,98.0,5.0,73.0,2128.0,13.0,,,,,,,,,,,,,Economics
291,"© 1998 Rob Gilbert and Pam Gilbert. All rights reserved.Originally published in 1998. This book offers a balanced overview of the issues surrounding boys and education. It looks beyond the often hysterical debate in the popular media to analyse what is happening with boys in the school system and how this can be understood. The authors argue that popular constructions of masculinity affect boys in all parts of their lives: in families, peer groups and work cultures - at home, at school, at work and at leisure. Offering insight into key issues such as literacy, sport, bad behaviour, sexuality, race and ethnicity, and popular culture, this book also looks at programs and approaches to working with boys which have been successful.",2017-05-18,Book,Book,Masculinity Goes to School,21100923897,3,19,Masculinity goes to school,0,false,10.4324/9781315166025,Taylor and Francis,291,,2016.0,0.0,0.0,,144155890,J. Fuerst,,,,,,,,,,,356.0,3093.0,21.0,,,,,,,,,,,,,,,,Sociology
292,"© Mary Bosworth 1999. All rights reserved.This book explores how power is negotiated in women's prisons. Drawing on fieldwork conducted in three penal establishments in England, it analyses how women manage the restrictions of imprisonment and the manner in which they attempt to resist institutional control. It is proposed that power is negotiated on a private, individual level, as women often resist the institution simply by trying to maintain an image of control over their own lives. However, their image of themselves as active, reasoning agents is undermined by institutional regimes which encourage traditional, passive, feminine behaviour at the same time as they deny the women their identities and responsibilities as mothers, wives, girlfriends and sisters. Femininity is, therefore, both the form and the goal of women's imprisonment. Yet paradoxically, femininity also offers the possibility of resistance, because women manage to rebel by appropriating and changing aspects of it.",2017-03-02,Book,Book,Engendering Resistance: Agency and Power in Women's Prisons,21100925128,4,,Engendering Resistance: Agency and power in women's prisons,0,false,10.4324/9781315256498,Taylor and Francis,292,,1999.0,0.0,39.0,,14523412,M. Bosworth,,,,,,,,,,,144.0,3220.0,28.0,,,,,,,,,,,,,,,,Political Science
293,"© 2016 Wiley Periodicals, Inc.Although independent lines of research have identified misogynistic lyrical content and traditional gender role beliefs as reliable predictors of men's female-directed aggression, more research is needed to understand the extent to which these variables may function in synthesis to potentiate aggression. In the current study, men (N = 193), who completed questionnaires relevant to their conformity to masculine norms and level of hostile and benevolent sexism, were exposed to either misogynistic or neutral lyrics before having the opportunity to shock an ostensible female confederate in a bogus reaction time task that, in effect, measured aggression. Results indicated that misogynistic lyrics and hostile sexism significantly predicted both unprovoked and provoked aggression against a female target. Contrary to expectations, moderating effects of gender role beliefs on the relationship between misogynistic lyrics and men's aggression were not found. Implications are discussed in terms of the costs of misogyny in media for women's lives. Aggr. Behav. 43:123–132, 2017. © 2016 Wiley Periodicals, Inc.",2017-03-01,Journal,Article,Aggressive Behavior,29452,6,43,Do beliefs about gender roles moderate the relationship between exposure to misogynistic song lyrics and men's female-directed aggression?,0,false,10.1002/ab.21668,Wiley-Liss Inc.info@wiley.com,293,Aggressive Behavior,2017.0,35.0,0.0,"{'model': 'tldr@v2.0.0', 'text': ""Results indicated that misogynistic lyrics and hostile sexism significantly predicted both unprovoked and provoked aggression against a female target, and moderating effects of gender role beliefs on the relationship between misogynisticyrics and men's aggression were not found.""}",4033643,Courtland S. Hyatt,5776505,Danielle S. Berke,2116335445,Joshua D. Miller,5107783,A. Zeichner,,,,,48.0,1080.0,16.0,49.0,718.0,17.0,392.0,21994.0,80.0,140.0,6038.0,45.0,,,,,,,"Psychology, Medicine"
294,"© 2017, Universidad Nacional de Colombia. All rights reserved.Introduction: Assessing the severity of the injuries suffered by victims may contribute to prevent femicide more effectively. Objective: To establish whether the amount of wounds recorded in femicides by stabbing vary according to the age of the victim and the victim-offender relationship. Materials and methods: Cases of Colombian women who were stabbed to death between 2011 and 2013 (n=331; age: 14-91 years) were included in the study. They were classified according to age ranges and the type of relationship with the offender. Descriptive analyses were conducted. Two one-way ANOVAs and a factorial ANOVA were performed to assess the differences in the mean number of the stab wounds received by the victim, and to determine the effects of interaction among the established categories. Results: The pattern of injury severity was higher in women aged 22 to 40 years than in those aged 41 to 55 years, and in women attacked by their intimate partners than in those attacked by strangers and acquaintances. Age ranges and types of relationship had an interaction effect on the dimension of the sustained wound. Conclusion: The age of the victims and the types of relationship they had with the offender are variables that should be considered to propose preventive policies on femicide since both are correlated to violent acts with greater injury patterns.",2017-01-01,Journal,Article,Revista Facultad de Medicina,20265,1,65,The magnitude of the injury pattern in femicides by stabbing in Colombian women La magnitud del patrón de lesión en los feminicidios con arma cortopunzante en mujeres colombianas,1,true,10.15446/revfacmed.v65n4.61615,Universidad Nacional de Colombia,294,,2017.0,30.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'The age of the victims and the types of relationship they had with the offender are variables that should be considered to propose preventive policies on femicide since both are correlated to violent acts with greater injury patterns.'}",2090721311,J. Vergel,1422867306,Andrea-Catalina Trompetero-González,,,,,,,,,10.0,105.0,3.0,2.0,5.0,2.0,,,,,,,,,,,,,Medicine
295,"© 2015, The Author(s) 2015.We report a meta-analytic review of studies examining the relations among harmful workplace experiences and women’s occupational well-being. Based on previous research, a classification of harmful workplace experiences affecting women is proposed and then used in the analysis of 88 studies with 93 independent samples, containing 73,877 working women. We compare the associations of different harmful workplace experiences and job stressors with women’s work attitudes and health. Random-effects meta-analysis and path analysis showed that more intense yet less frequent harmful experiences (e.g., sexual coercion and unwanted sexual attention) and less intense but more frequent harmful experiences (e.g., sexist organizational climate and gender harassment) had similar negative effects on women’s well-being. Harmful workplace experiences were independent from and as negative as job stressors in their impact on women’s occupational well-being. The power imbalance between the target and the perpetrator appeared as a potential factor to explain the type and impact of harmful workplace experiences affecting women’s occupational well-being. In the discussion, we identify several gaps in the literature, suggest directions for future research, and suggest organizational policy changes and interventions that could be effective at reducing the incidence of harmful workplace experiences. Additional online materials for this article are available to PWQ subscribers on PWQ's website at http://pwq.sagepub.com/supplemental.",2016-03-01,Journal,Article,Psychology of Women Quarterly,14035,135,40,Harmful Workplace Experiences and Women’s Occupational Well-Being: A Meta-Analysis,2,,10.1177/0361684315599346,SAGE Publications Ltdinfo@sagepub.co.uk,295,,2016.0,203.0,6.0,,1693665245,V. Sojo,144864639,R. Wood,101436148,Anna E. Genat,,,,,,,23.0,732.0,11.0,113.0,11812.0,34.0,6.0,230.0,3.0,,,,,,,,,,Psychology
296,"© Faculty of Classics, University of Cambridge 2016.Aristotle’s account of female nature has received mostly negative treatment, emphasising what he says females cannot do. Building on recent research, this book comprehensively revises such readings, setting out the complex and positive role played by the female in Aristotle’s thought with a particular focus on the longest surviving treatise on reproduction in the ancient corpus, the Generation of Animals. It provides new interpretations of the nature of Aristotle’s sexism, his theory of male and female interaction in generation, and his account of inherited features. It also discusses a range of more general issues which can and should be re-examined in light of Aristotle’s account of female animals: his methodology, hylomorphism, teleology and psychology. Aristotle on Female Animals will be valuable to all those interested in Aristotle’s philosophy and the history of gender.",2016-01-01,Book,Book,Aristotle on Female Animals: A Study of the Generation of Animals,21100863455,51,,Aristotle on female animals: A study of the generation of animals,0,false,10.1017/CBO9781316479766,Cambridge University Press,296,,2016.0,312.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'Aristotle on sexual differentiation, feminism, sexism and Aristotle, Teleology and necessity in the Generation of Animals and Interpretations of Aristotle on the male role in generation are presented.'}",90492940,S. Connell,,,,,,,,,,,39.0,100.0,5.0,,,,,,,,,,,,,,,,Biology
297,"© The Editor(s) (if applicable) and The Author(s) 2017.Japanese Robot Culture examines social robots in Japan, those in public, domestic, and artistic contexts. Unlike other studies, this book sees the robot in relation to Japanese popular culture, and argues that the Japanese ‘affinity’ for robots is the outcome of a complex loop of representation and social expectation in the context of Japan’s continuing struggle with modernity. Considering Japanese robot culture from the critical perspectives afforded by theatre and performance studies, this book is concerned with representations of robots and their inclusion in social and cultural contexts, which science and engineering studies do not address. The robot as a performing object generates meaning in staged events and situations that make sense for its Japanese observers and participants. This book examines how specific modes of encounter with robots in carefully constructed mises en scène can trigger reflexive, culturally specific, and often ideologically-inflected responses.",2016-01-01,Book,Book,"Japanese Robot Culture: Performance, Imagination, and Modernity",21100829582,17,,"Japanese Robot culture: Performance, imagination, and modernity",0,false,10.1057/978-1-137-52527-7,Palgrave Macmillan,297,,2016.0,0.0,0.0,,70369378,Y. Sone,,,,,,,,,,,56.0,289.0,5.0,,,,,,,,,,,,,,,,Engineering
298,"© 2016 Jemma Tosh.Psychiatry and psychology have a long and highly debated history in relation to gender. In particular, they have attracted criticism for policing the boundaries of ŉormal’ gender expression through gender identity diagnoses, such as transvestism, transsexualism, gender identity disorder and gender dysphoria. Drawing on discursive psychology, this book traces the historical development of psychiatric constructions of ŉormal’ and ‘abnormal’ gender expression. It contextualizes the recent reconstruction of gender in the 5th edition of the Diagnostic and Statistical Manual of Mental Disorders (DSM-5) and its criteria for gender dysphoria. This latest diagnosis illustrates the continued disagreement and debate within the profession surrounding gender identity as ‘disordered’. It also provides an opportunity to reflect on the conflicted history between feminist and transgender communities in the changing context of a more trans-positive feminism, and the implications of these diagnoses for these distinct but linked communities. Psychology and Gender Dysphoria examines debates and controversies surrounding psychiatric diagnoses and theories related to gender and gender nonconformity by exploring recent research, examples of collaborative perspectives, and existing feminist and trans texts. As such, the book is relevant for postgraduate and postdoctoral researchers of gender, feminism, and critical psychology as well as historical issues within psychiatry.",2016-01-01,Book,Book,Psychology and Gender Dysphoria: Feminist and Transgender Perspectives,21101053878,17,,Psychology and gender dysphoria: Feminist and transgender perspectives,0,false,10.4324/9781315794938,Taylor and Francis,298,Psychology of Sexualities Review,2016.0,0.0,2.0,,116155021,Jemma Tosh,,,,,,,,,,,31.0,220.0,6.0,,,,,,,,,,,,,,,,Psychology
299,"© 2016 The Editor(s)(if applicable) and The Author(s).This book explores the experiences of lesbian, gay, bisexual and trans (LGBT) communities as victims, offenders and staff within the criminal justice system. It draws on both emerging and existing LGBT research and campaigns to identify and explore issues relevant to the criminal justice system, including: agencies of the criminal justice system, victimisation, domestic violence and abuse, transgender experiences, LGBT people as offenders, international perspectives and the personal experiences of LGBT people.",2016-01-01,Book,Book,"Lesbian, Gay, Bisexual and Trans People (LGBT) and the Criminal Justice System",21100778249,12,,"Lesbian, gay, bisexual and trans people (LGBT) and the criminal justice system",,,10.1057/9781137496980,Palgrave Macmillan UK,299,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
300,"© 2015, Springer Science+Business Media New York.We conducted a content analysis of children’s products in U.S. popular culture that depict male and female characters to determine the extent to which gender stereotypes were portrayed. We examined popular Halloween costumes (90 female costumes and 90 male costumes) from popular retail websites, 79 popular dolls and 71 popular action figures from national store websites, and Valentines found at two national stores (portraying 54 female and 59 male characters). The coding system was adapted from several different studies. Female characters were far more likely than male characters to be depicted with traditional feminine stereotyped cues (e.g., decorative clothing) and sexually submissive, hyper-feminine cues (e.g., revealing clothing). Male characters were far more likely to be portrayed with traditional masculine characteristics like functional clothing and the body-in-motion, and they were often depicted with hyper-masculine accessories such as having a weapon. Implications for children’s gender-role development and the perpetuation of patriarchy are discussed.",2016-01-01,Journal,Article,Sex Roles,14798,50,74,Boys Act and Girls Appear: A Content Analysis of Gender Stereotypes Associated with Characters in Children’s Popular Culture,0,false,10.1007/s11199-015-0558-x,Springer New York LLCbarbara.b.bertram@gsk.com,300,Sex Roles,2015.0,61.0,0.0,,6473723,S. Murnen,2080974980,Claire Greenfield,2074801494,Abigail Younger,145164379,Hope K Boyd,,,,,78.0,6989.0,35.0,3.0,64.0,1.0,2.0,64.0,1.0,11.0,168.0,6.0,,,,,,,
302,"© 2016 E. Brodersen. All rights reserved.Instilled in interdisciplinary cross-cultural perspectives of mythical, socio-economic, literary, pedagogic and psychoanalytic representations, two archetypal, creative inheritance laws interact as 'twins': Eros (fusion/containment/safety) and Thanatos (division/separation/risk). Hypothesising these 'twin' laws as matrilineal (Eros) and patrilineal (Thanatos), this book explores why cross-cultural forms, including gender traits, are not fixed but are instead influenced by earlier flexible matrilineal forms. Through a study of 'twins' on macro and micro levels, Elizabeth Brodersen argues that a psychological 'twin' dilemma is implicit in inheritance laws and offers a unique forum to show how each law competes for primacy as the 'first' and 'other'. Chapters begin by looking at 'twins' in creation myths and the historical background to the laws of inheritance, as well as literary representations. The book then moves on to the developmental structures imbued in twin research and educational systems to explore how past cultural forms have been re-defined to fit a modern landscape and the subsequent movement away from the importance of patrilineal primogeniture. Laws of Inheritance will be of key value to academics, researchers and postgraduate students in the fields of psychoanalysis, psychotherapy, archetypal theory, cross-cultural depth psychology, cultural anthropology, sociology, gender studies and twin research. The book will also be of interest to practicing psychoanalysts and psychotherapists.",2015-08-14,Book,Book,Laws of Inheritance: A Post-Jungian Study of Twins and the Relationship Between the First and Other(s),21100420787,2,,Laws of inheritance: A post-Jungian study of twins and the relationship between the first and other(s),0,false,10.4324/9781315696843,Taylor and Francis Inc.,302,,2015.0,0.0,0.0,,116729741,E. Brodersen,,,,,,,,,,,18.0,4.0,1.0,,,,,,,,,,,,,,,,Psychology
303,"© 2015 Taylor & Francis. All rights reserved.This innovative text's critical examination foregrounds the prime reason why so many people participate in or watch sport - pleasure. Although there has been a ""turn"" to emotions and affect within academia over the last two decades, it has been somewhat remiss that pleasure, as an integral aspect of human life, has not received greater attention from sociologists of sport, exercise and physical education. This book addresses this issue via an unabashed examination of sport and the moving body via a ""pleasure lens."" It provides new insights about the production of various identities, power relations and social issues, and the dialectical links between the socio-cultural and the body. Taking a wide-sweeping view of pleasure - dignified and debauched, distinguished and mundane - it examines topics as diverse as aging, health, fandom, running, extreme sports, biopolitics, consumerism, feminism, sex and sexuality. In drawing from diverse theoretical approaches and original empirical research, the text reveals the social and political significance of pleasure and provides a more rounded, dynamic and sensual account of sport.",2015-06-05,Book,Book,Sport and the Social Significance of Pleasure,21100411407,19,,Sport and the Social Significance of Pleasure,0,false,10.4324/9781315719634,Taylor and Francis Inc.,303,,2015.0,0.0,0.0,,50000230,R. Pringle,29943864,R. Rinehart,11336153,Jayne Caudwell,,,,,,,102.0,1537.0,19.0,100.0,1400.0,19.0,98.0,1381.0,18.0,,,,,,,,,,Sociology
304,"© Oxford University Press 2014. All rights reserved.This volume unites research on the problem of gender and magic in three ancient Mediterranean societies: early Judaism, Christianity, and Greco-Roman culture. The book brings together diverse critical methodologies derived from research carried out in ancient fields. It is divided into three sections that reflect distinct perspectives. This interdisciplinary approach challenges presumed associations of women and magic by probing the foundations and processes of, and motivations behind, gendered stereotypes, beginning with Western culture's earliest associations of women and magic in the Bible and Homer's Odyssey. The book interrogates gendered stereotypes that are as relevant now, for understanding contemporary popular culture, as for understanding antiquity or the early modern witch hunts. The chapters in this volume collectively illuminate the reality as well as ideology and fantasy behind ancient constructions of the ""witch.""",2014-10-23,Book,Book,Daughters of Hecate: Women and Magic in the Ancient World,21100405442,9,,Daughters of Hecate: Women and Magic in the Ancient World,0,false,10.1093/acprof:oso/9780195342703.001.0001,Oxford University Press,304,,2014.0,0.0,1.0,,81117375,Kimberly B. Stratton,114972238,Dayna S. Kalleres,,,,,,,,,33.0,117.0,5.0,21.0,66.0,3.0,,,,,,,,,,,,,Art
305,"Alternative (or ""underground"") rap music proves a worthy site for applying ideas associated with Bourdieu's field of cultural production. I examine how underground rap music blurs the boundaries of restricted and large-scale production, as represented by noncommercial and commercial rap respectively. Artists identified as ""underground"" deploy anti-corporate, politically-charged, and socially-conscious lyrics, which can be viewed as restricted production. However, these lyrical themes are relatively scarce compared to themes of misogyny and hyper-masculinity found in this sub-genre and predominately found in commercial rap. This study thus reveals that large-scale and restricted fields of production may intersect (Craig and Dubois, 2010; Elafros, 2013; Hitters and van de Kamp, 2010; Sapiro, 2010). In this case, a symbiotic relationship may exist between major record companies and underground artists (Lena, 2006; Watkins, 2005; Watts, 2012) that demands further analysis. Rappers' habitus may inform and interact with rap music production, especially for ""second-go-round"" artists, compelling them to cooperate with commercial rap market imperatives (i.e., by using misogynistic and violent lyrics, as well as politically-oriented and socially-conscious rhymes) to maximize their appeal to both alternative rap consumers and large, mainstream record labels. © 2013 Elsevier B.V.",2014-02-01,Journal,Article,Poetics,17409,17,42,(Un)conscious (popular) underground: Restricted cultural production and underground rap music,0,false,10.1016/j.poetic.2013.12.001,,305,,2014.0,53.0,3.0,,113847353,Matthew Oware,,,,,,,,,,,24.0,261.0,8.0,,,,,,,,,,,,,,,,Psychology
306,"© 2000 Dora Kohen, editorial matter and selection.The question of bias Feminists have been most assiduous in their observation and discussion of the issue of bias in social research on gender differences and women, pointing to the various threats to the validity of research findings (see Jacklin, 1981). Biases occur both when differences are exaggerated or when they are minimized because assumptions of gender neutrality are made. Specific biases have been highlighted in studies of gender and mental disorder which question the validity of observed differences in rates of mental illnesses.",2014-01-01,Book,Book Chapter,Women and Mental Health,21100918393,4,,Psychological perspectives on women’s vulnerability to mental illness,,,10.4324/9781315812335-11,Taylor and Francis,306,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
307,"© 2014 Sheila Jeffreys.It is only recently that transgenderism has been accepted as a disorder for which treatment is available. In the 1990s, a political movement of transgender activism coalesced to campaign for transgender rights. Considerable social, political and legal changes are occurring in response and there is increasing acceptance by governments and many other organisations and actors of the legitimacy of these rights. This provocative and controversial book explores the consequences of these changes and offers a feminist perspective on the ideology and practice of transgenderism, which the author sees as harmful. It explores the effects of transgenderism on the lesbian and gay community, the partners of people who transgender, children who are identified as transgender and the people who transgender themselves, and argues that these are negative. In doing so the book contends that the phenomenon is based upon sex stereotyping, referred to as 'gender'-a conservative ideology that forms the foundation for women's subordination. Gender Hurts argues for the abolition of ‘gender’, which would remove the rationale for transgenderism. This book will be of interest to scholars and students of political science, feminism and feminist theory and gender studies.",2014-01-01,Book,Book,Gender Hurts: A Feminist Analysis of the Politics of Transgenderism,21100439056,100,,Gender hurts: A feminist analysis of the politics of transgenderism,0,false,10.4324/9781315778266,Taylor and Francis,307,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
308,"© 2014 Barrie Gunter.Media and the Sexualization of Childhood examines the on-going debates surrounding the prominence of sexual themes in children’s lives, from clothes and accessories, toys and games, to music, entertainment media, advertising, and new media platforms. Parents, educators and politicians around the developed world have raised concerns about the effects all these experiences can have on the socialisation and psychological development of children and the extent to which the premature introduction of sexuality into their lives can place them at risk of unwanted attention. This book explores these issues using an evidence based approach that draws on research findings from around the world, representing the most comprehensive single account of the field. The book will be invaluable to students studying topics surrounding children and the media and childhood studies, as well as students of communication, media, cultural studies, sociology, psychology and health science.",2014-01-01,Book,Book,Media and the Sexualization of Childhood,21100438491,15,,Media and the Sexualization of Childhood,,,10.1017/9781315774305,Taylor and Francis,308,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
309,"© 2014 Jennifer Marchbank and Gayle Letherby.Thoroughly updated in this second edition, Introduction to Gender offers an interdisciplinary approach to the main themes and debates in gender studies. This comprehensive and contemporary text explores the idea of gender from the perspectives of history, sociology, social policy, anthropology, psychology, politics, pedagogy and geography and considers issues such as health and illness, work, family, crime and violence, and culture and media. Throughout the text, studies on masculinity are highlighted alongside essential feminist work, producing an integrated investigation of the field. Key features: • A thematic structure provides a clear exploration of each debate without losing sight of the interconnections between disciplines. • World in focus boxes and international case studies offer a broad global perspective on gender studies. • In-text features and student exercises, including Controversy, A critical look and Stop and think boxes, allow the reader to engage in the debates and revise the material covered. • Hotlinks throughout the text make connections between chapters, allowing the reader to follow the path of particular issues and debates between topics and disciplines. New to the second edition: • A new chapter explores gender through the discipline of philosophy. • A new section on international relations brings this relevant topic into focus. •Current discussion on the language of gender across Europe is brought in to Chapter 1. • A focus on Europe and Scandinavia as well as the UK gives the text a broader scope. • Examples are updated throughout to ensure the text is cutting-edge and relevant. Introduction to Gender, second edition is highly relevant to today's students across the social sciences and is an essential introduction for students of sociology, women's studies and men's studies.",2014-01-01,Book,Book,"Introduction to Gender: Social Science Perspectives, Second Edition",21100438087,17,,"Introduction to gender: Social science perspectives, second edition",0,false,10.4324/9781315797236,Taylor and Francis,309,,2007.0,19.0,0.0,,82023287,Stephan F. Miescher,74177545,T. Manuh,49981977,Catherine M. Cole,,,,,,,30.0,554.0,10.0,46.0,646.0,15.0,74.0,419.0,11.0,,,,,,,,,,Sociology
311,"© Oxford University Press 2012. All rights reserved.Contemporary theorists use the term ""social construction"" with the aim of exposing how what's purportedly ""natural"" is often at least partly social and, more specifically, how this masking of the social is politically significant. The chapters in this book draw on insights from feminist and critical race theory to develop the idea that gender and race are positions within a structure of social relations. On this interpretation, the point of saying that gender and race are socially constructed is not to make a causal claim about the origins of our concepts of gender and race, or to take a stand in the nature/nurture debate, but to locate these categories within a realist social ontology. This is politically important, for by theorizing how gender and race fit within different structures of social relations we are better able to identify and combat forms of systematic injustice. The central chapters of the book offer critical social realist accounts of gender and race. These accounts function as case studies for a broader approach that draws upon notions of ideology, practice, and social structure developed through interdisciplinary engagement with research in social science. Ideology, on the proposed view, is a relatively stable set of shared dispositions to respond to the world, often in ways that also shape the world to evoke those very dispositions. This looping of our dispositions through the material world enables the social to appear natural. Additional chapters in the book situate a critical realist approach in relation to philosophical methodology, and to debates in analytic metaphysics, epistemology, and philosophy of language.",2013-01-24,Book,Book,Resisting Reality: Social Construction and Social Critique,21100372359,437,,Resisting Reality: Social Construction and Social Critique,0,false,10.1093/acprof:oso/9780199892631.001.0001,Oxford University Press,311,,2012.0,51.0,48.0,,15165355,S. Haslanger,,,,,,,,,,,97.0,5932.0,31.0,,,,,,,,,,,,,,,,Sociology
312,"© 2012 Athina Karatzogianni.It has been noted by numerous commentators that a significant element of contemporary popular culture has been the apparent ‘mainstreaming’ of explicit sexual imagery and discourse. An integral element within this development is the popular proliferation of imagery using the motifs of Bondage Domination Sadism and Masochism (BDSM). Fashion, advertising, music and the movies have all brought into the cultural mainstream a kind of aestheticised recoding of sex, in which the play of domination and submission take a key role. This would suggest, prima facie, that a previously marginalised and stigmatised form of sexual practice has been ‘rehabilitated’ and brought into the cultural mainstream. However, through an analysis of recent media imagery, it is argued that these popular representations risk blurring the normative boundaries between consensual BDSM ‘play’ and coercive violence/violation. For example, Vogue Italia’s controversial 2006 photospread entitled ‘State of Emergency’ combines ‘BDSM chic’ with post 9/11 signifiers of terror and torture, thereby potentially reinscribing BDSM as a socially and morally dangerous activity. Mainstream imagery therefore tends to consistently gloss over the centrality of consent in BDSM culture, thereby reinforcing negative stereotypes about the practices and their practitioners. Moreover, we hold that these media representations cannot be understood in isolation. Rather, they inter-connect in a relation of reciprocal influence with other discourses around ‘deviant’ sexuality, especially the medico-moral and legal discourses. Working together, they perpetuate a confusion of sexual consent and violence, which serves to fuel wider public anxieties about SM as ‘deviant’ and ‘perverted’, and supports moves to censor BDSM imagery, such as the recent prohibition on the possession of ‘extreme violent pornography’ introduced by the UK government. In the first part of this chapter, we consider the ways in which popular media has of late mobilised SM imagery, across diverse field including film, fashion photography, advertising and music. In the second part, we explore how these media representations intersect with medico-moral and legal discourses, and might thereby work in concert to reproduce the supposed ‘deviance’ (and, indeed, ‘criminality’) of BDSM practitioners. However, we also note the ways certain practitioners actively embrace the status and symbolism associated with deviance, as an integral element in the production of a desired social and sexual identity.",2013-01-01,Book,Book Chapter,Violence and War in Culture and the Media: Five Disciplinary Lenses,21101072630,0,,Loving violence? The ambiguities of SM imagery in contemporary popular culture,0,false,10.4324/9780203143308-13,Taylor and Francis,312,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
313,"© 1990 Liz Stanley and Sue Wise.Introduction This chapter discusses six closely related aspects of recent feminist debates concerning method, methodology and epistemology in the social sciences and humanities. The first section, ‘Feminist consciousness and feminist research’, reviews the main relevant arguments and ideas in Breaking Out, a book we wrote together, published in 1983. This is followed, in ‘Feminist method, methodology or epistemology?', by a discussion of Sandra Harding’s account of feminist epistemological positions and in particular the ‘successor science’ and ‘feminist standpoint’ positions. Other feminist standpoint epistemologies are discussed in the third section, on ‘Silenced feminist standpoints’, while the fourth, ‘The feminist standpoint revisited’, looks at complexities in the work of one of the ‘successor science’ writers, Dorothy Smith.",2013-01-01,Book,Book Chapter,"Feminist Praxis (RLE Feminist Theory): Research, Theory and Epistemology in Feminist Sociology",21101006782,175,,"Method, methodology and epistemology in feminist research processes",0,false,10.4324/9780203094020-9,Taylor and Francis,313,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
314,,2013-01-01,Book,Book Chapter,Violence and War in Culture and the Media: Five Disciplinary Lenses,21100356202,1,,Loving violence?: The ambiguities of SM imagery in contemporary popular culture,0,false,10.4324/9780203143308,Taylor and Francis,314,,2012.0,0.0,0.0,,66825750,Athina Karatzogianni,,,,,,,,,,,162.0,568.0,13.0,,,,,,,,,,,,,,,,Sociology
315,"The present study tested the hypothesis, derived from feminist perspectives on body image, that men's greater endorsement of sexist attitudes and objectification of women would be associated with their own drive for muscularity. A total of 327 British men completed scales measuring their drive for muscularity, sexist attitudes, hostility toward women, objectification of women, and key demographics. Results showed that greater drive for muscularity was significantly predicted by stronger objectification of women, hostility toward women, and sexist attitudes, once men's age and body mass index had been taken into account. These results suggest that oppressive beliefs held by men are associated with a desire for a more muscular physique. Implications for theoretical models seeking to explain drive for muscularity among men are discussed in conclusion © 2012 American Psychological Association.",2013-01-01,Journal,Article,Psychology of Men and Masculinity,14031,43,14,"Associations among men's sexist attitudes, objectification of women, and their own drive for muscularity",0,false,10.1037/a0028437,American Psychological Association Inc.journals@apa.org,315,,2013.0,82.0,5.0,,3298993,V. Swami,2176390,M. Voracek,,,,,,,,,448.0,14657.0,65.0,445.0,19995.0,56.0,,,,,,,,,,,,,Psychology
318,"© 2012 - John Benjamins B.V.This comprehensive, state-of-the-art bibliography documents the most recent research activity in the vibrant field of language, gender and sexuality. It provides experts in the field and students in tertiary education with access to language-centred resources on gender and sexuality and is, therefore, an ideal research companion. The main part of the bibliography lists 3,454 relevant publications (monographs, edited volumes, journal articles and contributions to edited volumes) that have been published within the period from 2000 to 2011. It unites work done in linguistics with that of neighbouring disciplines, covering studies dealing with a broad range of languages and cultures around the globe. Alphabetical listing and a keyword index facilitate finding relevant work by author and subject matter. The e-book version additionally enables users to search the entire document for specific terms. Sections on earlier bibliographies and general reference works on language, gender and sexuality complete the compilation.",2012-09-11,Book,Book,"An Interdisciplinary Bibliography on Language, Gender and Sexuality (2000-2011)",21100420846,8,,"An interdisciplinary bibliography on language, gender, and sexuality (2000-2011)",0,false,10.1075/z.177,John Benjamins Publishing Company,318,,2012.0,0.0,0.0,"{'model': 'tldr@v2.0.0', 'text': 'This comprehensive, state-of-the-art bibliography documents the most recent research activity in the vibrant field of language, gender and sexuality and provides experts in the field and students in tertiary education with access to language-centred resources on gender andsexuality and is, therefore, an ideal research companion.'}",69405544,Heiko Motschenbacher,,,,,,,,,,,100.0,1000.0,15.0,,,,,,,,,,,,,,,,Computer Science
319,"© 2012 by Oxford University Press, Inc. All rights reserved.This is a study of South African literature through the prism of narratives of sexual violence. While most incidents of sexual assault in South Africa are interracial, narratives of interracial rape have dominated the national imaginary. South African literature has again and again circled back to images of ""black peril"" (representations of the rape of white women by black men) and ""white peril"" representations that show the rape of colonised women by colonising men. Taking an historical and comparative perspective, the book uses as theoretical underpinning Michel Foucault's ideas on sexuality and biopolitics and Judith Butler's speculations on race and cultural melancholia. Avoiding a simplistic feminist perspective, the book examines the complex ways in which race, gender and class work together in the literary texts under examination. Where relevant, it examines the production, dissemination and reception of the selected texts. The books argues for an ethically responsible and dialectical approach that recognises high levels of sexual violence in South Africa, but also examines the racialised inferences and assumptions implicit in representations of bodily violation.",2012-05-24,Book,Book,State of Peril: Race and Rape in South African Literature,21100373304,46,,State of Peril: Race and Rape in South African Literature,2,,10.1093/acprof:oso/9780199796373.001.0001,Oxford University Press,319,,2012.0,0.0,2.0,,104954883,L. Graham,,,,,,,,,,,42.0,235.0,7.0,,,,,,,,,,,,,,,,History
320,"© 2005 by Lawrence Erlbaum Associates, Inc.This book explores, for the first time in an edited collection, the intersection of three key research areas women, madness and the law and advances the debates on how law and the psy sciences play a critical role in regulating and controlling womens lives.",2012-01-01,Book,Book,"Women, Madness and the Law: A Feminist Reader",21100382236,0,,"Women, madness and the law: A feminist reader",0,false,10.4324/9781843146063,Taylor and Francis,320,,2012.0,0.0,0.0,,143965359,Wendy Chan,8394097,D. Chunn,48014805,R. Menzies,,,,,,,22.0,320.0,7.0,40.0,521.0,14.0,157.0,2736.0,28.0,,,,,,,,,,Sociology
